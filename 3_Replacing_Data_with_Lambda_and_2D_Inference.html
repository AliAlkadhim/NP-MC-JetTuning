
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>3 - 2-Dimensional Inference in \(\theta - \nu\) Space and Replacing Observed Data with Test Statistics &#8212; Pivotal Likelihood-Free Inference for Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="4 - Mapping Confidence Sets to Confidence Intervals" href="4_Mapping_Confidence_Sets_to_Confidence_Intervals.html" />
    <link rel="prev" title="2 - Two-Parameter Problem and Pivotal Likelihood-Free p-Values" href="2_Two_Parameter_Problem_and_Pivotal_p_Value.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Pivotal Likelihood-Free Inference for Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the Likelihood-Free Inference for Particle Physics Jupyter book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1_Intro_and_One_Parameter_Problem.html">
   1 - Pivotal LFI for Count Data in Particle Physics: Background and one-parameter Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_Two_Parameter_Problem_and_Pivotal_p_Value.html">
   2 - Two-Parameter Problem and Pivotal Likelihood-Free p-Values
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   3 -  2-Dimensional Inference in
   <span class="math notranslate nohighlight">
    \(\theta - \nu\)
   </span>
   Space and Replacing Observed Data with Test Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="4_Mapping_Confidence_Sets_to_Confidence_Intervals.html">
   4 - Mapping Confidence Sets to Confidence Intervals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="5_Imposing_Pivotal_Conditions_on_Lambda.html">
   5. Imposing Pivotal Conditions on
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="6_More_Ideas.html">
   More Discussions
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AliAlkadhim/LFI_HEP/master?urlpath=tree/JupyterBook/3_Replacing_Data_with_Lambda_and_2D_Inference.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/3_Replacing_Data_with_Lambda_and_2D_Inference.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   3 -  2-Dimensional Inference in
   <span class="math notranslate nohighlight">
    \(\theta - \nu\)
   </span>
   Space and Replacing Observed Data with Test Statistics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-inference-on-theta-and-nu">
   2D inference on
   <span class="math notranslate nohighlight">
    \(\theta\)
   </span>
   and
   <span class="math notranslate nohighlight">
    \(\nu\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-utils">
     import utils
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall-that-when-we-wanted-to-make-inference-on-theta-alone">
     Recall that when we wanted to make inference on
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
     alone,
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml">
   ML
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-n-m-with-mle-true">
   3.1: Train on
   <span class="math notranslate nohighlight">
    \(N,M\)
   </span>
   with MLE=True
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-training-data">
     Generate Training Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-1-modelnm-is-trained-on-n-m-hat-theta-as-data">
     model 1 (“modelNM”) is trained on
     <span class="math notranslate nohighlight">
      \(N,M,\hat{\theta}\)
     </span>
     as data:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-data-with-mle-true">
     Generate Data with MLE=True
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-data-with-mle-false">
     Generate Data with MLE=False
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#retrieve-n-m-data-with-lambda-d-false-with-and-mle-true">
     Retrieve
     <span class="math notranslate nohighlight">
      \(\{ N,M \}\)
     </span>
     data (with lambda_D=False) with and MLE=True
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-you-haven-t-already">
     Save Trained model if you haven’t already
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-trained-model-on-n-m">
     Load trained model on (N,M)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-out-eval-data-with-n-m">
       Check out eval data with N,M
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-out-model-trained-on-nm-prediction">
       Check out model trained on NM prediction
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot">
       Plot
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#grenoble-data-n-3-m-7">
       Grenoble Data:
       <span class="math notranslate nohighlight">
        \(N=3, M=7\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-n-m-with-mle-false">
   3.2 Train on
   <span class="math notranslate nohighlight">
    \(N,M\)
   </span>
   with MLE=False
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-lambda-d-with-mle-true">
   3.3 Train on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
   with MLE=True
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-2-model-lambda-d-is-trained-on-lambda-d-as-data">
     model 2 (“model_lambda_D”) is trained on
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
     as data:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-mle-model-on-lambda-d">
   Train MLE Model on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-out-eval-data-with-lambda-d">
     Check out eval data with
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-out-model-trained-on-lambda-d-prediction">
     Check out model trained on
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
     prediction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-lambda-d-with-mle-false">
   3.4 Train on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
   with MLE=False
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-coverage">
     Compute Coverage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coverage-algorithm">
       Coverage algorithm:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping-confidence-regions-sets-to-confidence-intervals">
   Mapping Confidence Regions (Sets) to Confidence intervals
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-coverage-of-the-set-at-several-tau-values-and-observe-that-for-the-1d-case-using-our-2d-algorithm-the-coverage-is-not-exact">
     Check coverage of the set at several
     <span class="math notranslate nohighlight">
      \(\tau\)
     </span>
     values and observe that for the 1D case, using our 2D algorithm the coverage is not exact
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#only-1d-inference-on-theta-independently-of-nu">
   Only 1D inference on
   <span class="math notranslate nohighlight">
    \(\theta\)
   </span>
   (independently of
   <span class="math notranslate nohighlight">
    \(\nu\)
   </span>
   )
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   ML
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-load-the-training-data-we-used-previously-in-notebook-2">
     First load the training data we used previously (in notebook 2)
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>3 -  2-Dimensional Inference in \theta - \nu Space and Replacing Observed Data with Test Statistics</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   3 -  2-Dimensional Inference in
   <span class="math notranslate nohighlight">
    \(\theta - \nu\)
   </span>
   Space and Replacing Observed Data with Test Statistics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#d-inference-on-theta-and-nu">
   2D inference on
   <span class="math notranslate nohighlight">
    \(\theta\)
   </span>
   and
   <span class="math notranslate nohighlight">
    \(\nu\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#import-utils">
     import utils
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#recall-that-when-we-wanted-to-make-inference-on-theta-alone">
     Recall that when we wanted to make inference on
     <span class="math notranslate nohighlight">
      \(\theta\)
     </span>
     alone,
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml">
   ML
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-n-m-with-mle-true">
   3.1: Train on
   <span class="math notranslate nohighlight">
    \(N,M\)
   </span>
   with MLE=True
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-training-data">
     Generate Training Data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-1-modelnm-is-trained-on-n-m-hat-theta-as-data">
     model 1 (“modelNM”) is trained on
     <span class="math notranslate nohighlight">
      \(N,M,\hat{\theta}\)
     </span>
     as data:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-data-with-mle-true">
     Generate Data with MLE=True
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-data-with-mle-false">
     Generate Data with MLE=False
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#retrieve-n-m-data-with-lambda-d-false-with-and-mle-true">
     Retrieve
     <span class="math notranslate nohighlight">
      \(\{ N,M \}\)
     </span>
     data (with lambda_D=False) with and MLE=True
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-you-haven-t-already">
     Save Trained model if you haven’t already
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#load-trained-model-on-n-m">
     Load trained model on (N,M)
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-out-eval-data-with-n-m">
       Check out eval data with N,M
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#check-out-model-trained-on-nm-prediction">
       Check out model trained on NM prediction
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#plot">
       Plot
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#grenoble-data-n-3-m-7">
       Grenoble Data:
       <span class="math notranslate nohighlight">
        \(N=3, M=7\)
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-n-m-with-mle-false">
   3.2 Train on
   <span class="math notranslate nohighlight">
    \(N,M\)
   </span>
   with MLE=False
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-lambda-d-with-mle-true">
   3.3 Train on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
   with MLE=True
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#model-2-model-lambda-d-is-trained-on-lambda-d-as-data">
     model 2 (“model_lambda_D”) is trained on
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
     as data:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-mle-model-on-lambda-d">
   Train MLE Model on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-out-eval-data-with-lambda-d">
     Check out eval data with
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-out-model-trained-on-lambda-d-prediction">
     Check out model trained on
     <span class="math notranslate nohighlight">
      \(\lambda_D\)
     </span>
     prediction
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#train-on-lambda-d-with-mle-false">
   3.4 Train on
   <span class="math notranslate nohighlight">
    \(\lambda_D\)
   </span>
   with MLE=False
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#compute-coverage">
     Compute Coverage
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#coverage-algorithm">
       Coverage algorithm:
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#mapping-confidence-regions-sets-to-confidence-intervals">
   Mapping Confidence Regions (Sets) to Confidence intervals
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#check-coverage-of-the-set-at-several-tau-values-and-observe-that-for-the-1d-case-using-our-2d-algorithm-the-coverage-is-not-exact">
     Check coverage of the set at several
     <span class="math notranslate nohighlight">
      \(\tau\)
     </span>
     values and observe that for the 1D case, using our 2D algorithm the coverage is not exact
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     Algorithm
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#only-1d-inference-on-theta-independently-of-nu">
   Only 1D inference on
   <span class="math notranslate nohighlight">
    \(\theta\)
   </span>
   (independently of
   <span class="math notranslate nohighlight">
    \(\nu\)
   </span>
   )
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   ML
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#first-load-the-training-data-we-used-previously-in-notebook-2">
     First load the training data we used previously (in notebook 2)
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="dimensional-inference-in-theta-nu-space-and-replacing-observed-data-with-test-statistics">
<h1>3 -  2-Dimensional Inference in <span class="math notranslate nohighlight">\(\theta - \nu\)</span> Space and Replacing Observed Data with Test Statistics<a class="headerlink" href="#dimensional-inference-in-theta-nu-space-and-replacing-observed-data-with-test-statistics" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="d-inference-on-theta-and-nu">
<h1>2D inference on <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\nu\)</span><a class="headerlink" href="#d-inference-on-theta-and-nu" title="Permalink to this headline">#</a></h1>
<p>Ali Al Kadhim and Harrison B. Prosper <br>
Department of Physics, Florida State University <br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1">#use numba&#39;s just-in-time compiler to speed things up</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="p">;</span> 
<span class="c1">#reset matplotlib stle/parameters</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-deep&#39;</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;agg.path.chunksize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">font_legend</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">font_axes</span><span class="o">=</span><span class="mi">15</span>
<span class="c1"># %matplotlib inline</span>
<span class="c1">#Harrison fonts</span>
<span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">18</span>
<span class="n">font</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;family&#39;</span><span class="p">:</span> <span class="s1">&#39;serif&#39;</span><span class="p">,</span> <span class="s1">&#39;weight&#39;</span><span class="p">:</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="s1">&#39;size&#39;</span><span class="p">:</span><span class="n">FONTSIZE</span><span class="p">}</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;font&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">font</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">&#39;text&#39;</span><span class="p">,</span><span class="n">usetex</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">copy</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">sys</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">optuna</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optuna is only used for hyperparameter tuning, not critical!&#39;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="c1"># import sympy as sy</span>
<span class="c1">#sometimes jupyter doesnt initialize MathJax automatically for latex, so do this</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">wid</span><span class="p">;</span> <span class="n">wid</span><span class="o">.</span><span class="n">HTMLMath</span><span class="p">(</span><span class="s1">&#39;$\LaTeX$&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
<section id="import-utils">
<h2>import utils<a class="headerlink" href="#import-utils" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">LFI_PIVOT_BASE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BASE directoy properly set = &#39;</span><span class="p">,</span> <span class="n">LFI_PIVOT_BASE</span><span class="p">)</span>
    <span class="n">utils_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils_dir</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">utils</span>
    <span class="c1">#usually its not recommended to import everything from a module, but we know</span>
    <span class="c1">#whats in it so its fine</span>
    <span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;BASE directory not properly set. Read repo README.</span><span class="se">\</span>
<span class="s2">    If you need a function from utils, use the decorator below, or add utils to sys.path&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/LFI_HEP
</pre></div>
</div>
</div>
</div>
</section>
<section id="recall-that-when-we-wanted-to-make-inference-on-theta-alone">
<h2>Recall that when we wanted to make inference on <span class="math notranslate nohighlight">\(\theta\)</span> alone,<a class="headerlink" href="#recall-that-when-we-wanted-to-make-inference-on-theta-alone" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[ \lambda(\theta) \equiv - 2 \log{\frac{p(n,m|\theta, \hat{\nu}(\theta) )}{ p(n,m|\hat{\theta}, \hat{\nu}(\theta) )}} = -2 \log \frac{L_{\text{prof}} \big(\theta \big) }{L_{\text{prof}} \big( \hat{\theta} \big)}, \tag{4}\]</div>
<p>where <span class="math notranslate nohighlight">\(L_{\text{prof}} \big( n, m, \theta, \hat{\nu}(\theta) \big)\)</span> is the profiled likelihood - that is - the likelihood function when the nuissance parameters are replaced by their maximum likelihood estimates (MLE) for a given value of the parameter of interest.</p>
<div class="math notranslate nohighlight">
\[
L_{\text{prof}}(\theta) \equiv \frac{e^{-(\theta+\hat{\nu})} (\theta+\hat{\nu})^N }{N !} \ \frac{e^{-\hat{\nu}} \hat{\nu}^M}{M !} \tag{5}.
\]</div>
<p>The MLE estimate <span class="math notranslate nohighlight">\(\hat{\nu}(\theta)\)</span> is attained by minimizing the conditional likelihood</p>
<div class="math notranslate nohighlight">
\[\frac{\partial \log{p(n,m|\theta,\nu)}}{ \partial \nu} =0\]</div>
<p>whilst keeping <span class="math notranslate nohighlight">\(\theta\)</span> constant, leading to</p>
<div class="math notranslate nohighlight">
\[\log{p(n,m|\theta,\nu)} = -(\theta+\nu)+n\log{(\theta+\nu)|-\nu+m\log{\nu}} + \text{constants}\]</div>
<div class="math notranslate nohighlight">
\[\hat{\nu}(\theta)=\left(g+\sqrt{g^2 + 8 m \theta} \right)/4,\]</div>
<p>where <span class="math notranslate nohighlight">\(g \equiv n+m-2 \theta\)</span>.</p>
<p>or equivalently</p>
<div class="math notranslate nohighlight">
\[\frac{\partial \log{L(\theta)}}{ \partial \nu}|_{\nu=\hat{\nu}} =0,\]</div>
<p>leading to</p>
<div class="math notranslate nohighlight">
\[\log{L(\theta)} = -(\theta+\nu)+n\log{(\theta+\nu)|-\nu+m\log{\nu}} + \text{constants}\]</div>
<p>We have a nice functional form for <span class="math notranslate nohighlight">\(\lambda\)</span>, where The MLE of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\hat{\theta}^{\text{(MLE)}}=n-m.\]</div>
<p>Low-count data can sometimes yield spurious results, where the MLE of a parameter of interest <span class="math notranslate nohighlight">\(\theta\)</span>, could yield a negative result. In the case that <span class="math notranslate nohighlight">\(\theta\)</span> is the cross section, yielding a negative result is non-physical, which leads to the ad-hoc fix: taking ignoring the MLE solution and taking <span class="math notranslate nohighlight">\(\hat{\theta}=0\)</span> when <span class="math notranslate nohighlight">\(n&lt;m\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\theta}^{\text{(non-MLE)}} =\left\{
\begin{array}{ll}
    n-m &amp; \quad  n&gt;m \\
    0 &amp; \quad n \le m
\end{array}
\right.
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
L_{\text{prof}}(\theta,\nu) \equiv \frac{e^{-(\hat{\theta}+\hat{\nu})} (\hat{\theta}+\hat{\nu})^N }{N !} \ \frac{e^{-\hat{\nu}} \hat{\nu}^M}{M !}.
\]</div>
<p>If we want to do inference on <span class="math notranslate nohighlight">\((\theta,\nu)\)</span> simultaneously, we use a different test statistic, since in this case <span class="math notranslate nohighlight">\(\nu\)</span> is not known, and hence <span class="math notranslate nohighlight">\(\nu\)</span> is needed in the training as well as the evaluation of the model. (recal that for <span class="math notranslate nohighlight">\(\lambda_{NP,\theta}\)</span> we had <span class="math notranslate nohighlight">\(\nu\)</span> fixed for the training and evaluation, but <span class="math notranslate nohighlight">\(\nu\)</span> was also generated in the algorithm internally. Not a good explanation but this is jut informal notes.)</p>
<div class="math notranslate nohighlight">
\[ \lambda_{2D} (\theta,\nu)= -2 \log \frac{L_{\text{prof}} \big(\theta,\nu \big) }{L_{\text{prof}} \big( \hat{\hat{\theta}},\hat{\hat{\nu}} \big)}, \tag{4}\]</div>
<p>Where <span class="math notranslate nohighlight">\(\hat{\hat{\theta}},\hat{\hat{\nu}}\)</span> are the global maxima.</p>
<p>Just like in the 1D case <span class="math notranslate nohighlight">\(\lambda_{NP,1D} \rightarrow \chi^2_1\)</span> so that the confidence interval can be found by <span class="math notranslate nohighlight">\(\Delta \lambda_{NP,1} \le \chi^2_{1,1-\alpha}\)</span>, in 2D we have the same situation, where now it approaches a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution with 2 free parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">theta_hat_</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">n</span><span class="o">-</span><span class="n">m</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">theta_hat</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta_hat</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta_hat</span>

<span class="k">def</span> <span class="nf">L_prof_global</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="c1"># theta_hat = n-m</span>
    <span class="n">theta_hat</span><span class="o">=</span><span class="n">theta_hat_</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">MLE</span><span class="p">)</span>
    <span class="n">nu_hat</span> <span class="o">=</span> <span class="n">m</span>
    <span class="n">p1</span><span class="o">=</span><span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">theta_hat</span><span class="o">+</span><span class="n">nu_hat</span><span class="p">)</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nu_hat</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p1</span><span class="o">*</span><span class="n">p2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">L_theta_nu</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">theta</span><span class="p">,</span><span class="n">nu</span><span class="p">):</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">)</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">p1</span><span class="o">*</span><span class="n">p2</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">Ln</span><span class="o">=</span> <span class="n">L_theta_nu</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">theta</span><span class="p">,</span><span class="n">nu</span><span class="p">)</span>
    
    <span class="n">Ld</span><span class="o">=</span> <span class="n">L_prof_global</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-14</span>
    <span class="n">Ld</span><span class="o">=</span><span class="n">Ld</span><span class="o">+</span><span class="n">eps</span>
    <span class="n">lambda_</span>  <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Ln</span><span class="o">/</span><span class="n">Ld</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi2_exp_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">run_sim_2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample n ~ Pois(theta+nu), </span>
<span class="sd">              m ~ Pois(nu), </span>
<span class="sd">    and compute </span>
<span class="sd">              lambda(theta, n, m)</span>
<span class="sd">              </span>
<span class="sd">    return: (n, m, lambda_), where each are np arrays of length lambda_size</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">run_sims</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run an entire simulation, that is, generate n and m from </span>
<span class="sd">    run_sim above, and calculate lambda, for</span>
<span class="sd">    </span>
<span class="sd">    input: a tuple of (theta, nu) scalars</span>
<span class="sd">    </span>
<span class="sd">    Reurns:df, lambda_results</span>
<span class="sd">    </span>
<span class="sd">    where lambda_results is a list of tuples </span>
<span class="sd">        (n, m, lambda_, theta, nu)</span>
<span class="sd">    and df is just a dataframe of [n,m,lambda,theta,nu]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lambda_results</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">p</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">theta</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">nu</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="n">run_sim_2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span> <span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">lambda_</span>
        <span class="n">lambda_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">))</span>
    
        <span class="nb">print</span><span class="p">(</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> (theta, nu) =  (%.f, %.f) </span><span class="se">\n</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span> <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> with associated n =  </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">, </span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> m = </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">, </span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> lambda = </span><span class="si">{</span><span class="n">lambda_</span><span class="si">}</span><span class="s1">&#39;</span>  <span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">lambda_results</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_hist_2d_data_2d_inference</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">):</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#lambda_test_2d(n,m, theta, nu)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span><span class="o">&lt;</span> 
         <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    <span class="c1"># bins = binsize(Bprime)</span>

    <span class="c1"># Z-weighted histogram   (count the number of ones per bin)</span>
    <span class="c1">#theta will be on axis and nu on y axis</span>
    <span class="n">y_theta_nu_w</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span>
                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span> 
                          <span class="n">weights</span><span class="o">=</span><span class="n">Z</span><span class="p">)</span>
    
    <span class="c1"># unweighted histogram (count number of ones and zeros per bin)</span>
    <span class="n">y_theta_nu_uw</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span>
                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">))</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-15</span>
    <span class="n">P_theta_nu</span> <span class="o">=</span>  <span class="n">y_theta_nu_w</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_theta_nu_uw</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>    
    <span class="c1">#P_theta_nu approximates E[Z]</span>
    <span class="k">return</span> <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span>
</pre></div>
</div>
</div>
</div>
<p>As we know, the p-value is the probability under the null hypothesis <span class="math notranslate nohighlight">\(H_{null}\)</span> (which is in this case parameterized by <span class="math notranslate nohighlight">\(\theta\)</span>) of finding data of equal or greater <em>incompatibility</em> with the predictions of <span class="math notranslate nohighlight">\(H_{null}\)</span>. Therefore, in our case, the p-value under the null hypothesis (defined by <span class="math notranslate nohighlight">\(\theta\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p_\theta (\nu) &amp;=\int_{\lambda_D}^\infty f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid H_{null} \big) \ d \lambda_{gen} \\
 &amp;= 1- \text{Prob} \big(\lambda_{gen}(n,m;\theta,\nu) \le \lambda_D(N,M;\theta,\nu) \big), \tag{2}
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is the PDF of <span class="math notranslate nohighlight">\(\lambda\)</span>. In the strict frequentist approach, <span class="math notranslate nohighlight">\(\theta\)</span> is rejected only if the <span class="math notranslate nohighlight">\(p\)</span>-value is less than the significance level of a hypothesis test <span class="math notranslate nohighlight">\(\alpha\)</span> (i.e. accepeted if <span class="math notranslate nohighlight">\(p_\theta (\nu) \le \alpha\)</span>). So we were estimaing the <span class="math notranslate nohighlight">\(p-\)</span>-value of <span class="math notranslate nohighlight">\(\theta\)</span> in the presence of nuissance parameter <span class="math notranslate nohighlight">\(\nu\)</span></p>
<div class="math notranslate nohighlight">
\[p_\theta(\nu) \approx E[Z \mid \theta, \nu]\]</div>
<p>\footnote{Note that this is one advantage of LFI, where one can always generate more synthetic data (for training as well as evaluation), whereas in traditinoal ML, the raining and evaluation data sets are fixed. Here, we generate binned <span class="math notranslate nohighlight">\(\theta\)</span> with the same ranges as those of the training set, and constants for <span class="math notranslate nohighlight">\(\{ \nu, N, M \}\)</span>.}</p>
<p>But obviously the hypothesis is one that concerns the whole hypothesis for a <span class="math notranslate nohighlight">\((\theta,\nu)\)</span> observaion, i.e. the logic in the hypothesis testing in <span class="math notranslate nohighlight">\(\theta\)</span> clearly applies in 2D ( in (<span class="math notranslate nohighlight">\(\theta-\nu\)</span>) space) which is what the plots below show by 2d histogramming:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_P_byhist_2d</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">,</span>
                 <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">make_hist_2d_data_2d_inference</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                  <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                  <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                          <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                   <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                          <span class="n">MLE</span><span class="p">)</span>
    
    <span class="n">bin_centers_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_theta_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_theta_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">bin_centers_nu</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nu_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nu_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1">#WHOLE RANGE</span>
    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    <span class="c1"># thetarange = (thetamin, 10)</span>
    <span class="c1"># nurange = (numin, 10)</span>
    

    <span class="c1">#Remember theta is on x and nu on y axes, so next line, each will be 2d</span>
    <span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">bin_centers_theta</span><span class="p">,</span> <span class="n">bin_centers_nu</span><span class="p">)</span>
    
    <span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span> <span class="o">=</span> <span class="n">THETA</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">NU</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">P_theta_nu</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">T</span>
    <span class="n">P_theta_nu_byhist</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
               <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span>
               <span class="n">weights</span><span class="o">=</span><span class="n">P_theta_nu_byhist</span><span class="p">,</span>
             <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues_r&#39;</span>
             <span class="p">)</span>
    
    <span class="n">CLs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.683</span><span class="p">,</span><span class="mf">0.90</span><span class="p">,</span><span class="mf">0.95</span><span class="p">])</span>
    
    <span class="c1">#To draw contours, the intensity (the p-value) must be 2D again</span>
    <span class="n">P_theta_nu_byhist_2d</span> <span class="o">=</span> <span class="n">P_theta_nu_byhist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1">#for contours everything has to be 2d</span>
    <span class="n">contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span><span class="p">,</span> <span class="n">P_theta_nu_byhist_2d</span><span class="p">,</span>
              <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
              <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">,</span>
                        <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gist_earth_r&#39;</span>
                       <span class="p">)</span>
    
<span class="c1">#     #label the contours</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">contours</span><span class="p">,</span> <span class="n">contours</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%4.2f</span><span class="s1">&#39;</span><span class="p">,</span> 
              <span class="c1"># colors=&#39;black&#39;,</span>
              <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\nu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p$-value by $\mathbf</span><span class="si">{h}</span><span class="s1">$: $N = </span><span class="si">%s</span><span class="s1">$ , $M  = </span><span class="si">%s</span><span class="s1">$, MLE = </span><span class="si">%s</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">N</span><span class="p">),</span><span class="nb">str</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1">#add contour color bar</span>
    <span class="c1"># cbar = fig.colorbar(contours, ax=ax)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">save_plot</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">],</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;2D_Hist_thetamin_</span><span class="si">{</span><span class="n">thetamin</span><span class="si">}</span><span class="s2">_thetamax_</span><span class="si">{</span><span class="n">thetamax</span><span class="si">}</span><span class="s2">_numin_</span><span class="si">{</span><span class="n">numin</span><span class="si">}</span><span class="s2">_numax_</span><span class="si">{</span><span class="n">numax</span><span class="si">}</span><span class="s2">_2D_INFERENCE.png&quot;</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># mpl.rcParams.update(mpl.rcParamsDefault)</span>

<span class="n">figwidth_by_height_ratio</span><span class="o">=</span><span class="mf">1.33</span>
<span class="n">height</span><span class="o">=</span><span class="mi">6</span>
<span class="n">width</span><span class="o">=</span><span class="n">figwidth_by_height_ratio</span><span class="o">*</span><span class="n">height</span>
<span class="n">width</span><span class="o">=</span><span class="mi">6</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span><span class="n">height</span><span class="p">),</span>
                     <span class="p">)</span>

<span class="n">plot_P_byhist_2d</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_17_0.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_17_0.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ml">
<h1>ML<a class="headerlink" href="#ml" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="train-on-n-m-with-mle-true">
<h1>3.1: Train on <span class="math notranslate nohighlight">\(N,M\)</span> with MLE=True<a class="headerlink" href="#train-on-n-m-with-mle-true" title="Permalink to this headline">#</a></h1>
<section id="generate-training-data">
<h2>Generate Training Data<a class="headerlink" href="#generate-training-data" title="Permalink to this headline">#</a></h2>
<p>Generate <span class="math notranslate nohighlight">\(\{\theta_i, \nu_i, N_i, M_i, Z_i \}\)</span>  data according to the following, and according to whether MLE=True, and save as dataframes</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\theta &amp; \sim \textrm{uniform}(0, 20), \\
\nu &amp; \sim \textrm{uniform}(0, 20), \\
\end{align}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
n &amp; \sim \textrm{poisson}(\theta + \nu),\\
m &amp; \sim \textrm{poisson}(\nu),\\
\end{align}
\right\} \rightarrow \lambda_\text{gen}(n, m \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
N &amp; \sim \textrm{uniform}(0,10),\\
M &amp; \sim \textrm{uniform}(0, 10), \\
\end{align}
\right\} \rightarrow \lambda_D(N, M \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
Z_{(\theta,\nu)}  = \mathbb{I}
\left[ \lambda_\text{gen}(n, m \mid \theta,\nu) \leq \lambda_D(N, M \mid \theta,\nu) \right].
\]</div>
</section>
<section id="model-1-modelnm-is-trained-on-n-m-hat-theta-as-data">
<h2>model 1 (“modelNM”) is trained on <span class="math notranslate nohighlight">\(N,M,\hat{\theta}\)</span> as data:<a class="headerlink" href="#model-1-modelnm-is-trained-on-n-m-hat-theta-as-data" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[ X_{train} = (\theta_{\text{continuous}}, \nu_{\text{continuous}}, \hat{\theta}_{fixed}, N_{fixed}, M_{fixed} )\]</div>
<div class="math notranslate nohighlight">
\[t_{train} = Z_{(\theta,\nu)} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetaMin</span><span class="p">,</span> <span class="n">thetaMax</span> <span class="o">=</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">numin</span><span class="p">,</span> <span class="n">numax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">Nmin</span><span class="p">,</span> <span class="n">Nmax</span> <span class="o">=</span>  <span class="mi">1</span><span class="p">,</span><span class="mi">10</span>
<span class="n">Mmin</span><span class="p">,</span> <span class="n">Mmax</span> <span class="o">=</span>  <span class="mi">1</span> <span class="p">,</span> <span class="mi">10</span>

<span class="k">def</span> <span class="nf">generate_training_data_2d</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">save_data</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate the training data, that is, features=[theta, nu, N, M], targets=Z&quot;&quot;&quot;</span>
    <span class="c1">#sample theta and nu from uniform(0,20)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetaMin</span><span class="p">,</span> <span class="n">thetaMax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1"># nu = st.uniform.rvs(nuMin, nuMax, size=Bprime)</span>
    <span class="n">nu</span><span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#n,m ~ F_{\theta,\nu}, ie our simulator. sample n from a Poisson with mean theta+nu </span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#sample m from a poisson with mean nu</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#sample our observed counts (N,M), which take the place of D</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">Nmin</span><span class="p">,</span> <span class="n">Nmax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">Mmin</span><span class="p">,</span> <span class="n">Mmax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">theta_hat_</span> <span class="o">=</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="n">SUBSAMPLE</span><span class="o">=</span><span class="mi">10</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;n=&#39;</span><span class="p">,</span> <span class="n">n</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;m=&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;N=&#39;</span><span class="p">,</span> <span class="n">N</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;M=&#39;</span><span class="p">,</span> <span class="n">M</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="n">lambda_gen</span> <span class="o">=</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_gen= &#39;</span><span class="p">,</span> <span class="n">lambda_gen</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_D= &#39;</span><span class="p">,</span> <span class="n">lambda_D</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="c1">#if lambda_gen &lt;= lambda_D: Z=1, else Z=0</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_gen</span> <span class="o">&lt;=</span> <span class="n">lambda_D</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="n">data_2_param</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Z&#39;</span> <span class="p">:</span> <span class="n">Z</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span> <span class="p">:</span> <span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">:</span> <span class="n">nu</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">:</span> <span class="n">theta_hat_</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span><span class="n">N</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span><span class="n">M</span><span class="p">,</span> <span class="s1">&#39;lambda_D&#39;</span><span class="p">:</span> <span class="n">lambda_D</span><span class="p">}</span>

    <span class="n">data_2_param</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data_2_param</span><span class="p">)</span>
    <span class="n">PATH</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;TWO_PARAMETERS_WITH_LAMBDA_D_theta_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">k_Examples_MLE_</span><span class="si">%s</span><span class="s1">.csv&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">thetaMin</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">thetaMax</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">Bprime</span><span class="o">/</span><span class="mi">1000</span><span class="p">)),</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">))</span> <span class="p">)</span>
    <span class="k">if</span> <span class="n">save_data</span><span class="p">:</span>
        <span class="n">data_2_param</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data_2_param</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">data_2_param</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#inital layer has to have size of input features as its input layer</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="c1">#ReLU activation </span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
                <span class="c1">#output layer:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">))</span> 

        <span class="c1"># ONLY IF ITS A CLASSIFICATION, ADD SIGMOID</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">average_quadratic_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">average_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_features_training_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># the numpy function choice(length, number)</span>
    <span class="c1"># selects at random &quot;batch_size&quot; integers from </span>
    <span class="c1"># the range [0, length-1] corresponding to the</span>
    <span class="c1"># row indices.</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="n">batch_t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="p">,</span> 
          <span class="n">n_iterations</span><span class="p">,</span> <span class="n">traces</span><span class="p">,</span> 
          <span class="n">step</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="p">):</span>
    
    <span class="c1"># to keep track of average losses</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    

    
    <span class="k">if</span> <span class="n">MLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata_2d</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="n">with_lambda_D</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata_2d</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="n">with_lambda_D</span><span class="p">)</span>
        
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration vs average loss&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="s2">&quot;</span> <span class="o">%</span> \
          <span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">,</span> <span class="s1">&#39;train-set&#39;</span><span class="p">,</span> <span class="s1">&#39;valid-set&#39;</span><span class="p">))</span>
    
    <span class="c1"># training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = get_data_sets(simulate_data=False, batchsize=batch_size)</span>
    
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>

        <span class="c1"># set mode to training so that training specific </span>
        <span class="c1"># operations such as dropout are enabled.</span>

        
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># get a random sample (a batch) of data (as numpy arrays)</span>
        
        <span class="c1">#Harrison-like Loader</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_features_training_batch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1">#Or Ali&#39;s Loader</span>
        <span class="c1"># batch_x, batch_t = next(training_set_features()), next(training_set_targets())</span>
        <span class="c1"># batch_x_eval, batch_t_eval = next(evaluation_set_features()), next(evaluation_set_targets())</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients </span>
            <span class="c1"># wrt. x and t</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>      


        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
   
        <span class="c1"># compute a noisy approximation to the average loss</span>
        <span class="n">empirical_risk</span> <span class="o">=</span> <span class="n">avloss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># use automatic differentiation to compute a </span>
        <span class="c1"># noisy approximation of the local gradient</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>       <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>   <span class="c1"># compute gradients</span>
        
        <span class="c1"># finally, advance one step in the direction of steepest </span>
        <span class="c1"># descent, using the noisy local gradient. </span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># move one step</span>
        
        <span class="k">if</span> <span class="n">ii</span> <span class="o">%</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            
            
            <span class="c1">#using Harrison-like loader</span>
            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">train_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span> 
            <span class="n">acc_v</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">test_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">test_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
            
            <span class="c1">#using Ali&#39;s loader</span>
            <span class="c1"># acc_t = validate(model, avloss, batch_x, batch_t) </span>
            <span class="c1"># acc_v = validate(model, avloss, batch_x_eval, batch_t_eval)</span>
            

            <span class="n">yy_t</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_t</span><span class="p">)</span>
            <span class="n">yy_v</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v</span><span class="p">)</span>
            
            <span class="c1"># compute running average for validation data</span>
            <span class="n">len_yy_v</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span>
            <span class="k">if</span>   <span class="n">len_yy_v</span> <span class="o">&lt;</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
            <span class="k">elif</span> <span class="n">len_yy_v</span> <span class="o">==</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="nb">sum</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span> <span class="o">/</span> <span class="n">window</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">acc_v_avg</span>  <span class="o">=</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">window</span>
                <span class="n">acc_v_avg</span> <span class="o">+=</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v_avg</span> <span class="o">/</span> <span class="n">window</span><span class="p">)</span>
                        
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                      <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">step</span><span class="p">)</span>
                    
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                          <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
                      <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            
    <span class="nb">print</span><span class="p">()</span>      
    <span class="k">return</span> <span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_average_loss</span><span class="p">(</span><span class="n">traces</span><span class="p">,</span> <span class="n">ftsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span><span class="n">save_loss_plots</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    
    <span class="c1"># create an empty figure</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    
    <span class="c1"># add a subplot to it</span>
    <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span>
    <span class="n">ax</span>  <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="n">ncols</span><span class="p">,</span><span class="n">index</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Average loss&quot;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
    <span class="c1">#ax.plot(xx, yy_v_avg, &#39;g&#39;, lw=2, label=&#39;Running average&#39;)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;average loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">save_loss_plots</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/loss_curves/IQN_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;_Consecutive_2.png&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">loss curve saved in images/loss_curves/IQN_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="n">target</span><span class="o">+</span><span class="s1">&#39;_Consecutive.png&#39;</span><span class="p">)</span>
    <span class="c1"># if show_loss_plots:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-data-with-mle-true">
<h2>Generate Data with MLE=True<a class="headerlink" href="#generate-data-with-mle-true" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Train_data_2d_MLE_True</span> <span class="o">=</span> <span class="n">generate_training_data_2d</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">save_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">Train_data_2d_MLE_True</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Train_data_2d_MLE_True</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n= [15 10 28 15 15  6 27 23  5 19]
m= [ 5  4 16  7  8  8 17  5  0  6]
N= [4 1 3 5 7 8 1 3 3 9]
M= [4 5 5 2 4 5 6 6 1 3]
lambda_gen=  [1.7199225  0.01397284 0.93508981 2.51459769 0.03337954 1.1675325
 0.93404024 4.60289917 2.22998823 0.21721402]
lambda_D=  [16.26721146 14.08301658 38.52050598 23.72261752  8.45256333  1.42624124
 66.53328335 32.87443368  2.6761389   7.61306384]


                    Z           theta              nu       theta_hat  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean         0.961022       10.001202        9.999901       -0.006042   
std          0.193543        5.774584        5.775469        3.649301   
min          0.000000        0.000033        0.000002       -8.000000   
25%          1.000000        4.996771        4.993422       -3.000000   
50%          1.000000        9.998035        9.990127        0.000000   
75%          1.000000       15.007757       15.003738        3.000000   
max          1.000000       19.999979       19.999992        8.000000   

                    N               M        lambda_D  
count  1000000.000000  1000000.000000  1000000.000000  
mean         4.999908        5.005950       26.348822  
std          2.580398        2.581412       17.674733  
min          1.000000        1.000000        0.000057  
25%          3.000000        3.000000       12.261644  
50%          5.000000        5.000000       23.668409  
75%          7.000000        7.000000       37.635887  
max          9.000000        9.000000      227.778150  
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
      <th>lambda_D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>7.935242</td>
      <td>8.395492</td>
      <td>0</td>
      <td>4</td>
      <td>4</td>
      <td>16.267211</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>6.139615</td>
      <td>4.151977</td>
      <td>-4</td>
      <td>1</td>
      <td>5</td>
      <td>14.083017</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>12.672168</td>
      <td>12.870366</td>
      <td>-2</td>
      <td>3</td>
      <td>5</td>
      <td>38.520506</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>4.584800</td>
      <td>11.905427</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
      <td>23.722618</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>7.804724</td>
      <td>7.900182</td>
      <td>3</td>
      <td>7</td>
      <td>4</td>
      <td>8.452563</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="generate-data-with-mle-false">
<h2>Generate Data with MLE=False<a class="headerlink" href="#generate-data-with-mle-false" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Train_data_2d_MLE_False</span> <span class="o">=</span> <span class="n">generate_training_data_2d</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">save_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">n_features</span> <span class="o">=</span> <span class="n">Train_data_2d_MLE_False</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">Train_data_2d_MLE_False</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n= [27 42 26 22  6  9 22 22 22 14]
m= [ 9 20 23 14  1 16 17  9  5  3]
N= [3 4 7 8 6 5 6 8 6 5]
M= [6 3 7 6 9 7 4 4 8 8]
lambda_gen=  [0.57942709 4.59530814 2.20474197 2.19861713 0.24518166 6.54306519
 0.28426637 1.0382217  0.04817305 0.33928235]
lambda_D=  [37.49840734 53.11704047 27.78523853 12.87753094 28.9668399  15.49837515
 30.33713294 14.84041271 19.20120081 17.38347775]


                    Z           theta            nu       theta_hat  \
count  1000000.000000  1000000.000000  1.000000e+06  1000000.000000   
mean         0.961167       10.004196  1.000016e+01        1.477720   
std          0.193197        5.774554  5.772514e+00        2.113194   
min          0.000000        0.000012  7.698232e-07        0.000000   
25%          1.000000        5.002446  5.003870e+00        0.000000   
50%          1.000000       10.002092  1.000167e+01        0.000000   
75%          1.000000       15.014330  1.499668e+01        3.000000   
max          1.000000       19.999972  1.999996e+01        8.000000   

                    N               M        lambda_D  
count  1000000.000000  1000000.000000  1000000.000000  
mean         4.994989        5.003844       26.375624  
std          2.582361        2.583059       17.672070  
min          1.000000        1.000000        0.000084  
25%          3.000000        3.000000       12.309590  
50%          5.000000        5.000000       23.664126  
75%          7.000000        7.000000       37.659922  
max          9.000000        9.000000      194.701742  
</pre></div>
</div>
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
      <th>lambda_D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15.251919</td>
      <td>11.474215</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
      <td>37.498407</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>15.086652</td>
      <td>15.819146</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
      <td>53.117040</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>10.079228</td>
      <td>16.617979</td>
      <td>0</td>
      <td>7</td>
      <td>7</td>
      <td>27.785239</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>12.698148</td>
      <td>9.160200</td>
      <td>2</td>
      <td>8</td>
      <td>6</td>
      <td>12.877531</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>6.279396</td>
      <td>0.723810</td>
      <td>0</td>
      <td>6</td>
      <td>9</td>
      <td>28.966840</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
    <span class="c1"># change from pandas dataframe format to a numpy </span>
    <span class="c1"># array of the specified types</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">source</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># the numpy function choice(length, number)</span>
    <span class="c1"># selects at random &quot;batch_size&quot; integers from </span>
    <span class="c1"># the range [0, length-1] corresponding to the</span>
    <span class="c1"># row indices.</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="n">batch_x</span>


<span class="k">def</span> <span class="nf">getwholedata_2d</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">USECOLS</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;lambda_D&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">USECOLS</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
            
    <span class="k">if</span> <span class="n">MLE_or_nonMLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">)</span>

        
        <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_WITH_LAMBDA_D_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="n">USECOLS</span>
                    <span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        
        <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_WITH_LAMBDA_D_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="n">USECOLS</span>
                    <span class="p">)</span>
        
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>
    

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span>
    <span class="c1"># source = [&#39;theta&#39;,&#39;nu&#39;,&#39;theta_hat&#39;,&#39;N&#39;,&#39;M&#39;]</span>
    <span class="n">USECOLS</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">source</span> <span class="o">=</span> <span class="n">USECOLS</span>

    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>  <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_t shape = &#39;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_x shape = &#39;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">valid</span><span class="p">:</span>
        <span class="c1">#if you want to also make a validation data set</span>
        <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">valid_data</span> <span class="o">=</span> <span class="n">valid_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>

        
    <span class="k">return</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data_sets</span><span class="p">(</span><span class="n">simulate_data</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;write custom data generator because who wants to read pytorch&#39;s DataLoader source code</span>
<span class="sd">    (and its sometimes slow for some reason)&quot;&quot;&quot;</span>
    <span class="c1"># if simulate_data:</span>
    <span class="c1">#     Train_data_MLE_True = generate_training_data(Bprime=100000, MLE=True, save_data=False)</span>
        
    <span class="c1"># if SUBSAMPLE:</span>
    <span class="c1">#     data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;, SUBSAMPLE=10000)#This is MLE DATA!</span>
    <span class="c1"># else:</span>
    <span class="c1">#     data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;)</span>
    <span class="c1"># data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;)</span>
    <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                    <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> 
                 <span class="c1"># nrows=SUBSAMPLE,</span>
                 <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> 
                                         <span class="n">test_size</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>
    <span class="c1"># train_data, valid_data = train_test_split(train_data, test_size=0.2)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># valid_data = valid_data.reset_index(drop=True)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;M&#39;</span><span class="p">]</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="c1"># valid_t, valid_x = split_t_x(valid_data, target=target, source=source)</span>
    <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>  <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">training_set_features</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">def</span> <span class="nf">evaluation_set_features</span><span class="p">():</span>
        <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span><span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>


    <span class="k">def</span> <span class="nf">training_set_targets</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">def</span> <span class="nf">evaluation_set_targets</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">test_t</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">return</span> <span class="n">training_set_features</span><span class="p">,</span> <span class="n">training_set_targets</span><span class="p">,</span> <span class="n">evaluation_set_features</span><span class="p">,</span> <span class="n">evaluation_set_targets</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="retrieve-n-m-data-with-lambda-d-false-with-and-mle-true">
<h2>Retrieve <span class="math notranslate nohighlight">\(\{ N,M \}\)</span>  data (with lambda_D=False) with and MLE=True<a class="headerlink" href="#retrieve-n-m-data-with-lambda-d-false-with-and-mle-true" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata_2d</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train_t shape =  (800000,) 

train_x shape =  (800000, 5) 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># BATCHSIZE=batch_size</span>
<span class="c1"># training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = \</span>
<span class="c1"># get_data_sets(simulate_data=False, batchsize=BATCHSIZE)</span>

<span class="c1"># sample_x=next(training_set_features())#this is just to get the dimenstions of one batch</span>
<span class="c1"># sample_y=next(training_set_targets())</span>
<span class="c1"># #(batchsize,5) for mass</span>
<span class="c1"># print(&#39;sample x shape&#39;, sample_x.shape)</span>
<span class="c1"># print(&#39;sample t shape&#39;, sample_y.shape)</span>

<span class="c1"># n_features = sample_x.shape[1]</span>
<span class="c1"># print(&#39;\n&#39;)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BEST_PARAMS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                                       <span class="s1">&#39;best_params&#39;</span><span class="p">,</span>
                                       <span class="s1">&#39;best_params_Test_Trials.csv&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Unnamed: 0  n_layers  hidden_size  dropout optimizer_name  learning_rate  \
0           0         4           11  0.13208        RMSprop       0.006398   

   batch_size  
0        1000  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">initiate_whose_model</span><span class="p">(</span><span class="n">Ali_or_Harrison</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    <span class="n">whose_model</span><span class="o">=</span><span class="s1">&#39;Ali&#39;</span>

    <span class="k">if</span> <span class="n">whose_model</span><span class="o">==</span><span class="s1">&#39;Harrison&#39;</span><span class="p">:</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">5</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span>
        <span class="n">optimizer</span>     <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">))</span> 
        <span class="n">model</span><span class="o">=</span><span class="n">Model</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">whose_model</span><span class="o">==</span><span class="s1">&#39;Ali&#39;</span><span class="p">:</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
        <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
            <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
            <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
            <span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>
    
<span class="n">model_NM_MLE</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model_NM_MLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#initiate MLE model </span>
<span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_NM_MLE</span><span class="p">,</span> <span class="n">optimizer_NM_MLE</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_NM_MLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_NM_MLE</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">200</span>


<span class="n">n_iterations</span><span class="o">=</span><span class="mi">100000</span>
<span class="c1">#train</span>
<span class="n">traces_MLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_NM_MLE</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_NM_MLE</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.0063975512794992
    maximize: False
    momentum: 0
    weight_decay: 0
)



RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
train_t shape =  (800000,) 

train_x shape =  (800000, 5) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.069141	  0.069284
     99800	  0.020469	  0.020443	  0.020632
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># n_layers, hidden_size, dropout, optimizer_name, learning_rate, batch_size, model_MLE, optimizer_MLE = initiate_whose_model(&#39;Ali&#39;, MLE=True)</span>
<span class="c1"># print(optimizer_MLE)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>
<span class="c1"># print(model_MLE)</span>

<span class="c1"># #also initiate non-MLE model</span>
<span class="c1"># # n_layers, hidden_size, dropout, optimizer_name, learning_rate, batch_size, model_nonMLE, optimizer_nonMLE = initiate_whose_model(&#39;Ali&#39;, MLE=False)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># n_layers, hidden_size, dropout, optimizer_name, learning_rate, batch_size, model_MLE_with_lambda, optimizer_MLE_with_lambda = initiate_whose_model(&#39;Ali&#39;, MLE=True)</span>
<span class="c1"># print(optimizer_MLE)</span>
<span class="c1"># print(&#39;\n\n&#39;)</span>
<span class="c1"># print(model_MLE)</span>

<span class="c1"># #also initiate non-MLE model</span>
<span class="c1"># # n_layers, hidden_size, dropout, optimizer_name, learning_rate, batch_size, model_nonMLE, optimizer_nonMLE = initiate_whose_model(&#39;Ali&#39;, MLE=False)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="save-trained-model-if-you-haven-t-already">
<h2>Save Trained model if you haven’t already<a class="headerlink" href="#save-trained-model-if-you-haven-t-already" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
            <span class="c1"># model=model_MLE_with_lambda</span>
            <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># model=model_MLE_with_lambda</span>
            <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
            <span class="c1"># model=model_MLE_with_lambda</span>
            <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># model=model_MLE_with_lambda</span>
            <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;saving model with name &#39;</span><span class="p">,</span> <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>
    <span class="n">models_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">)</span>
    
<span class="c1">#     PATH= os.path.join(models_path, </span>
<span class="c1">#     &#39;2D_MLE_%s_Regressor_%sK_training_iter.pt&#39; % ( str(MLE), str(n_iterations/1000) ))</span>
<span class="c1">#     with_theta_hat=True</span>
<span class="c1">#     if with_theta_hat==True:</span>
<span class="c1">#         PATH=os.path.join(models_path, </span>
<span class="c1">#     &#39;2D_MLE_WITH_LAMBDA_D_%s_Regressor_%sK_training_iter_with_theta_hat.pt&#39; % ( str(MLE), str(n_iterations/1000) ))</span>
    
    <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">models_path</span><span class="p">,</span> <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>
    
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>  <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_NM_MLE</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">51</span><span class="o">-</span><span class="mi">5</span><span class="n">c82e6e23056</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_NM_MLE</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;model_NM_MLE&#39; is not defined
</pre></div>
</div>
</div>
</div>
</section>
<hr class="docutils" />
<section id="load-trained-model-on-n-m">
<h2>Load trained model on (N,M)<a class="headerlink" href="#load-trained-model-on-n-m" title="Permalink to this headline">#</a></h2>
<p>Make sure it’s the correct number of in/out features!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_True_Regressor_1.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>

    
<span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>

<span class="n">model_lambda_D</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">model_lambda_D</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">#OR</span>
<span class="c1">#model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
<span class="n">model_lambda_D</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lambda_D</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=3, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; returns the dataframe, can be used if the dataframe is saved in csv format</span>
<span class="sd">    of if it is already in dataframe format (e.g. generated in this notebook). &quot;&quot;&quot;</span>
    <span class="c1"># SUBSAMPLE=int(1e5)</span>
    <span class="c1"># if isinstance(df_name,str):</span>
    <span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">USECOLS</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;lambda_D&#39;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">USECOLS</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
            
    <span class="k">if</span> <span class="n">MLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="c1"># data_path=os.path.join(LFI_PIVOT_BASE, </span>
        <span class="c1">#                 &#39;data&#39;,&#39;TWO_PARAMETERS_theta_0_20_1000k_Examples_MLE_True.csv&#39;)</span>

        
        <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_WITH_LAMBDA_D_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">)</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="n">USECOLS</span>
                    <span class="p">)</span>
    

    <span class="k">else</span><span class="p">:</span>
        <span class="n">data_path</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                        <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;TWO_PARAMETERS_WITH_LAMBDA_D_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">)</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="n">USECOLS</span>
                    <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>lambda_D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>7.935242</td>
      <td>8.395492</td>
      <td>16.267211</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>6.139615</td>
      <td>4.151977</td>
      <td>14.083017</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>12.672168</td>
      <td>12.870366</td>
      <td>38.520506</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>4.584800</td>
      <td>11.905427</td>
      <td>23.722618</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>7.804724</td>
      <td>7.900182</td>
      <td>8.452563</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>7.935242</td>
      <td>8.395492</td>
      <td>0</td>
      <td>4</td>
      <td>4</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>6.139615</td>
      <td>4.151977</td>
      <td>-4</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>12.672168</td>
      <td>12.870366</td>
      <td>-2</td>
      <td>3</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>4.584800</td>
      <td>11.905427</td>
      <td>3</td>
      <td>5</td>
      <td>2</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>7.804724</td>
      <td>7.900182</td>
      <td>3</td>
      <td>7</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_binned_X</span><span class="p">(</span><span class="n">X_min</span><span class="p">,</span> <span class="n">X_max</span><span class="p">,</span> <span class="n">Nbins</span><span class="p">):</span>
    <span class="n">X_step</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_max</span><span class="o">-</span><span class="n">X_min</span><span class="p">)</span> <span class="o">/</span> <span class="n">Nbins</span>
    <span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X_min</span><span class="p">,</span> <span class="n">X_max</span><span class="o">+</span><span class="n">X_step</span><span class="p">,</span> <span class="n">X_step</span><span class="p">)</span>
    <span class="n">bin_centers</span> <span class="o">=</span> <span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">bin_centers</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_eval_data_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">nbins_theta</span><span class="p">,</span> <span class="n">nbins_nu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make evaluation data composed of: binned theta and nu, and discrete N and M,</span>
<span class="sd">    and optionally theta_hat. The theta hat argument accpts an MLE boolean, therefore</span>
<span class="sd">    if trained on MLE data, the theta_hat that we use for evaluation is just </span>
<span class="sd">    n-m, including negative values.</span>
<span class="sd">    The return value of this function is used as the &quot;eval_data&quot; tensor below</span>
<span class="sd">    </span>
<span class="sd">    with lambda_D or with NM&quot;&quot;&quot;</span>
    <span class="c1">#if MLE true, load the model that was trained on MLE data and vice versa</span>
    <span class="c1"># N, M = D</span>
    <span class="c1"># nbins=NBINS</span>
    <span class="c1"># thetamin,thetamax=0,20</span>
    <span class="n">train_df</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="n">THETA_bin_centers</span> <span class="o">=</span> <span class="n">make_binned_X</span><span class="p">(</span><span class="n">X_min</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                                      <span class="n">X_max</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> 
                                      <span class="n">Nbins</span><span class="o">=</span><span class="n">nbins_theta</span><span class="p">)</span>
        
    <span class="n">NU_bin_centers</span> <span class="o">=</span> <span class="n">make_binned_X</span><span class="p">(</span><span class="n">X_min</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                                  <span class="n">X_max</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> 
                                  <span class="n">Nbins</span><span class="o">=</span><span class="n">nbins_nu</span><span class="p">)</span>
        
    <span class="c1"># tensor = torch.Tensor([</span>
                           <span class="c1"># [x, y, theta_hat(N, M, MLE=True), N, M] </span>
                           <span class="c1"># for (x,y) in zip(THETA_bin_centers,NU_bin_centers)</span>
                          <span class="c1"># ])</span>

    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span>
                       <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span> 
                       <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">THETA_bin_centers</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">NU_bin_centers</span>
                      <span class="p">])</span>

    <span class="c1">#zip only traverses the lists monotonically, so experiment to use cross to take every combination of the two lists</span>
    
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">THETA_bin_centers</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">NU_bin_centers</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="check-out-eval-data-with-n-m">
<h3>Check out eval data with N,M<a class="headerlink" href="#check-out-eval-data-with-n-m" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span><span class="p">,</span> <span class="n">eval_bins_theta_example</span><span class="p">,</span> <span class="n">eval_bins_nu_example</span> <span class="o">=</span><span class="n">make_eval_data_2d_with_NM</span><span class="p">(</span>
                                                                                    <span class="n">Bprime</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                                                                    <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                                                                                    <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                                                                    <span class="n">nbins_theta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                                                    <span class="n">nbins_nu</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">eval_data_example</span><span class="p">[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.1000,  0.1000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  0.3000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  0.5000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  0.7000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  0.9000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  1.1000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  1.3000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  1.5000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  1.7000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  1.9000, -2.0000,  1.0000,  3.0000]])
</pre></div>
</div>
</div>
</div>
<p>Check out model evaluated at eval data with N,M</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># see if you can evalute a model on theee</span>
<span class="n">model</span><span class="p">(</span><span class="n">eval_data_example</span><span class="p">)[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.9461],
        [0.9166],
        [0.8750],
        [0.8217],
        [0.7587]], grad_fn=&lt;SliceBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_bins_theta_example</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">usemodel_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; make evaluation data and evaluate the model at these data&quot;&quot;&quot;</span>
    <span class="c1">#Generate evaluation data at those fixed nu, N, M values</span>
    <span class="c1"># make_eval_data_2d has the following signature</span>
    <span class="c1">#make_eval_data_2d(Bprime, train_df, N, M, nbins_theta, nbins_nu)</span>
    <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins_theta</span><span class="p">,</span> <span class="n">eval_bins_nu</span> <span class="o">=</span><span class="n">make_eval_data_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="n">Bprime</span><span class="p">,</span> 
                                                                <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> 
                                                                <span class="n">nbins_theta</span><span class="o">=</span><span class="n">nbinstheta</span><span class="p">,</span>
                                                               <span class="n">nbins_nu</span><span class="o">=</span><span class="n">nbinsnu</span><span class="p">)</span><span class="c1">#eval data is indipendent of MLE, since its just constants witha theta variable</span>
    
    <span class="c1"># if MLE==True:</span>
    <span class="c1">#     model=model</span>
    <span class="c1">#else load the model trained on non-MLE data</span>
    <span class="c1"># PATH=&#39;models/MLE_TRUE_Regressor_200.0K_training_iter.pt&#39;</span>
    
    <span class="c1">#LOAD TRAINED MODEL</span>
    <span class="n">with_theta_hat</span><span class="o">=</span><span class="kc">False</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        
        <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span>
                          <span class="s1">&#39;models&#39;</span><span class="p">,</span> 
                          <span class="s1">&#39;2D_MLE_True_Regressor_100.0K_training_iter_with_theta_hat.pt&#39;</span><span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span>
                          <span class="s1">&#39;models&#39;</span><span class="p">,</span> 
                          <span class="s1">&#39;2D_NONMLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span><span class="p">)</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">optimizer_name</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="c1">#EVALUATE AT AT EVAL_DATA</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">eval_bins_theta</span><span class="p">,</span> <span class="n">eval_bins_nu</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-out-model-trained-on-nm-prediction">
<h3>Check out model trained on NM prediction<a class="headerlink" href="#check-out-model-trained-on-nm-prediction" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check it out</span>
<span class="n">usemodel_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                  <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                  <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                  <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">100</span><span class="p">)[</span><span class="mi">0</span><span class="p">][:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.99698144, 0.988837  , 0.9618853 , 0.88093257, 0.71583885],
      dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phat_MLE</span><span class="p">,</span> <span class="n">phatbins_theta</span><span class="p">,</span> <span class="n">phatbins_nu</span> <span class="o">=</span> <span class="n">usemodel_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
                                  <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                  <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                  <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> 
                                <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phatbins_theta</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phat_MLE</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(10100,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tb</span><span class="p">,</span> <span class="n">nb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">phatbins_theta</span><span class="p">,</span> <span class="n">phatbins_nu</span><span class="p">)</span>
<span class="n">tb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(101, 100)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#make sure you can reshape it for the contours!</span>
<span class="n">phat_MLE</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tb</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.9478107 , 0.91915184, 0.8798383 , ..., 1.        , 1.        ,
        1.        ],
       [0.94452024, 0.914003  , 0.8732308 , ..., 1.        , 1.        ,
        1.        ],
       [0.9410352 , 0.9095105 , 0.86712706, ..., 1.        , 1.        ,
        1.        ],
       ...,
       [0.9999999 , 0.9999999 , 0.9999999 , ..., 1.        , 1.        ,
        1.        ],
       [1.        , 0.9999999 , 0.9999999 , ..., 1.        , 1.        ,
        1.        ],
       [1.        , 1.        , 0.9999999 , ..., 1.        , 1.        ,
        1.        ]], dtype=float32)
</pre></div>
</div>
</div>
</div>
</section>
<section id="plot">
<h3>Plot<a class="headerlink" href="#plot" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">,</span>
                <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot histogrammed approximation of p-value as well as model evaluation at eval data &quot;&quot;&quot;</span>
    <span class="c1"># GET PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
    <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">make_hist_2d_data_2d_inference</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                  <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                  <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                          <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                   <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                          <span class="n">MLE</span><span class="p">)</span>
    
    <span class="n">bin_centers_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_theta_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_theta_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">bin_centers_nu</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nu_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nu_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1">#WHOLE RANGE</span>
    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    <span class="c1"># thetarange = (thetamin, 10)</span>
    <span class="c1"># nurange = (numin, 10)</span>
    

    <span class="c1">#Remember theta is on x and nu on y axes, so next line, each will be 2d</span>
    <span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">bin_centers_theta</span><span class="p">,</span> <span class="n">bin_centers_nu</span><span class="p">)</span>
    
    <span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span> <span class="o">=</span> <span class="n">THETA</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">NU</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">P_theta_nu</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">T</span>
    <span class="n">P_theta_nu_byhist</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="c1"># GET MODEL ESTIMATION AT SAME DATA</span>
    <span class="n">phat_MODEL</span><span class="p">,</span> <span class="n">phatbins_theta_MODEL</span><span class="p">,</span> <span class="n">phatbins_nu_MODEL</span> <span class="o">=</span> <span class="n">usemodel_2d_with_NM</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="n">Bprime</span><span class="p">,</span>
                                  <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                  <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> 
                                  <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">,</span> 
                                <span class="n">nbinstheta</span><span class="o">=</span><span class="n">nbinstheta</span><span class="p">,</span> 
                                <span class="n">nbinsnu</span><span class="o">=</span><span class="n">nbinsnu</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plothist</span><span class="p">:</span>
    <span class="c1"># PLOT PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                   <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span>
                   <span class="n">weights</span><span class="o">=</span><span class="n">P_theta_nu_byhist</span><span class="p">,</span>
                 <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues_r&#39;</span>
                 <span class="p">)</span>
    
    <span class="n">CLs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.683</span><span class="p">,</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span><span class="mf">0.95</span><span class="p">])</span>
    
    <span class="c1">#To draw contours, the intensity (the p-value) must be 2D again</span>
    <span class="n">P_theta_nu_byhist_2d</span> <span class="o">=</span> <span class="n">P_theta_nu_byhist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1">#for contours everything has to be 2d</span>
    
   <span class="c1"># CONTOUR LINES FOR PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
   <span class="c1"># AT CHOSEN CLs</span>
    <span class="n">histogram_approx_contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA</span><span class="p">,</span> 
                                         <span class="n">NU</span><span class="p">,</span> 
                                         <span class="n">P_theta_nu_byhist_2d</span><span class="p">,</span>
              <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
              <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">,</span>
                                         <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="c1"># cmap=&#39;gist_earth_r&#39;,</span>
                                         <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span>
                        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;histogram approx&#39;</span><span class="p">,</span>
                                         <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span>
                       <span class="p">)</span>
    
    
    <span class="c1"># CONTOUR LINES FOR PVALUE PREDICTED BY MODEL AT CHOSEN CLs</span>
    <span class="n">THETA_MODEL</span><span class="p">,</span> <span class="n">NU_MODEL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">phatbins_theta_MODEL</span><span class="p">,</span> <span class="n">phatbins_nu_MODEL</span><span class="p">)</span>
    <span class="n">phat_MODEL_CONTOUR</span> <span class="o">=</span> <span class="n">phat_MODEL</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA_MODEL</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">phat_MODEL_CONTOUR</span><span class="o">=</span><span class="n">phat_MODEL_CONTOUR</span><span class="o">.</span><span class="n">T</span>
    <span class="n">model_approx_contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA_MODEL</span><span class="p">,</span> 
                                     <span class="n">NU_MODEL</span><span class="p">,</span> 
                                     <span class="n">phat_MODEL_CONTOUR</span><span class="p">,</span>
          <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
          <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">,</span>
                                     <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model prediction&#39;</span>
                   <span class="p">)</span>

    
<span class="c1">#     #label the contours</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">histogram_approx_contours</span><span class="p">,</span> 
              <span class="n">histogram_approx_contours</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span> 
              <span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%4.2f</span><span class="s1">&#39;</span><span class="p">,</span> 
              <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
              <span class="c1"># manual=True,</span>
              <span class="n">fontsize</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
    <span class="c1"># ax.text(x=0.3, y=4.5, s=&#39;$0.68$&#39;, fontsize=22, rotation=-70)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
    <span class="c1"># ax.text(x=5,y=8, s=&#39;$N= %s$&#39; % str(N), fontsize=19)</span>
    <span class="c1"># ax.text(x=5,y=7, s=&#39;$M=%s$&#39; % str(M), fontsize=19)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;$N= </span><span class="si">%s</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;$M=</span><span class="si">%s</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\nu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
    <span class="c1"># ax.set_title(r&#39;$p$-value by $\mathbf{h}$ (dashed) and $\mathbf{f^{\{N,M\}} }$ (solid): $N = %s$ , $M  = %s$, MLE = %s &#39; % (str(N),str(M), str(MLE)),fontsize=16)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p$-value by $\mathbf</span><span class="si">{h}</span><span class="s1">$ (dashed) and $\mathbf{f^{\{N,M\}} }$ (solid); MLE = </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>  <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)</span> <span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1">#add contour color bar</span>
    <span class="c1"># cbar = fig.colorbar(histogram_approx_contours, ax=ax)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1">#     ax.legend()</span>
    
    <span class="k">if</span> <span class="n">save_plot</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">],</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> 
        <span class="sa">f</span><span class="s2">&quot;2D_Hist_thetamin_</span><span class="si">{</span><span class="n">thetamin</span><span class="si">}</span><span class="s2">_thetamax_</span><span class="si">{</span><span class="n">thetamax</span><span class="si">}</span><span class="s2">_numin_</span><span class="si">{</span><span class="n">numin</span><span class="si">}</span><span class="s2">_numax_</span><span class="si">{</span><span class="n">numax</span><span class="si">}</span><span class="s2">_N_</span><span class="si">{</span><span class="n">N</span><span class="si">}</span><span class="s2">_M_</span><span class="si">{</span><span class="n">M</span><span class="si">}</span><span class="s2">_MLE_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)</span><span class="si">}</span><span class="s2">_2D_INFERENCE.eps&quot;</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">fig_ax</span><span class="p">():</span>
    
    <span class="n">figwidth_by_height_ratio</span><span class="o">=</span><span class="mf">1.33</span>
    <span class="n">height</span><span class="o">=</span><span class="mi">6</span>
    <span class="n">width</span><span class="o">=</span><span class="n">figwidth_by_height_ratio</span><span class="o">*</span><span class="n">height</span>
    <span class="n">width</span><span class="o">=</span><span class="mi">6</span>
    <span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
                          <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span><span class="n">height</span><span class="p">),</span>
                         <span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_65_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_65_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_66_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_66_1.png" />
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_66_2.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_66_2.png" />
</div>
</div>
</section>
<section id="grenoble-data-n-3-m-7">
<h3>Grenoble Data: <span class="math notranslate nohighlight">\(N=3, M=7\)</span><a class="headerlink" href="#grenoble-data-n-3-m-7" title="Permalink to this headline">#</a></h3>
<p><span class="math notranslate nohighlight">\(\mathbf{f^{\{N,M\}} }\)</span>  means the model trained on <span class="math notranslate nohighlight">\(N,M\)</span> as fixed data.
<span class="math notranslate nohighlight">\(\mathbf{f^{\{ \lambda_D \}} }\)</span>  means the model trained on <span class="math notranslate nohighlight">\(\lambda_D\)</span> as fixed data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_69_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_69_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_70_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_70_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_71_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_71_1.png" />
</div>
</div>
<hr class="docutils" />
</section>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="train-on-n-m-with-mle-false">
<h1>3.2 Train on <span class="math notranslate nohighlight">\(N,M\)</span> with MLE=False<a class="headerlink" href="#train-on-n-m-with-mle-false" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_df_nonMLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15.251919</td>
      <td>11.474215</td>
      <td>0</td>
      <td>3</td>
      <td>6</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>15.086652</td>
      <td>15.819146</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>10.079228</td>
      <td>16.617979</td>
      <td>0</td>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>12.698148</td>
      <td>9.160200</td>
      <td>2</td>
      <td>8</td>
      <td>6</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>6.279396</td>
      <td>0.723810</td>
      <td>0</td>
      <td>6</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>
    
<span class="n">model_NM_nonMLE</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model_NM_nonMLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#initiate MLE model </span>
<span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_NM_nonMLE</span><span class="p">,</span> <span class="n">optimizer_NM_nonMLE</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_NM_nonMLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_NM_nonMLE</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">200</span>


<span class="n">n_iterations</span><span class="o">=</span><span class="mi">1000000</span>
<span class="c1">#train</span>
<span class="n">traces_MLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_NM_nonMLE</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_NM_nonMLE</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.0063975512794992
    maximize: False
    momentum: 0
    weight_decay: 0
)



RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
train_t shape =  (800000,) 

train_x shape =  (800000, 5) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.040293	  0.040456
    120600	  0.020755	  0.020779	  0.020748
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">111</span><span class="o">-</span><span class="mi">842</span><span class="n">a64fc8640</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>               <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>                 <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">23</span>                  <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="nn">&lt;ipython-input-12-2392da994e32&gt;</span> in <span class="ni">train</span><span class="nt">(model, optimizer, avloss, batch_size, n_iterations, traces, step, window, MLE, with_lambda_D)</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span> 
<span class="g g-Whitespace">     </span><span class="mi">77</span> 
<span class="ne">---&gt; </span><span class="mi">78</span>         <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span> 
<span class="g g-Whitespace">     </span><span class="mi">80</span>         <span class="c1"># compute a noisy approximation to the average loss</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">&lt;ipython-input-11-34556416fa49&gt;</span> in <span class="ni">forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span> 
<span class="g g-Whitespace">     </span><span class="mi">34</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">35</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">204</span>             <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">205</span>         <span class="k">return</span> <span class="nb">input</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span> 

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/dropout.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> 
<span class="g g-Whitespace">     </span><span class="mi">58</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">59</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span> 
<span class="g g-Whitespace">     </span><span class="mi">61</span> 

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py</span> in <span class="ni">dropout</span><span class="nt">(input, p, training, inplace)</span>
<span class="g g-Whitespace">   </span><span class="mi">1250</span>     <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1251</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dropout probability has to be between 0 and 1, &quot;</span> <span class="s2">&quot;but got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="ne">-&gt; </span><span class="mi">1252</span>     <span class="k">return</span> <span class="n">_VF</span><span class="o">.</span><span class="n">dropout_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span> <span class="k">if</span> <span class="n">inplace</span> <span class="k">else</span> <span class="n">_VF</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1253</span> 
<span class="g g-Whitespace">   </span><span class="mi">1254</span> 

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_NM_nonMLE</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Load model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>

    
<span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>

<span class="n">model_NM_nonMLE</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">model_NM_nonMLE</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">#OR</span>
<span class="c1">#model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
<span class="n">model_NM_nonMLE</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_NM_nonMLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_79_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_79_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_NM</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_80_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_80_1.png" />
</div>
</div>
<hr class="docutils" />
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="train-on-lambda-d-with-mle-true">
<h1>3.3 Train on <span class="math notranslate nohighlight">\(\lambda_D\)</span> with MLE=True<a class="headerlink" href="#train-on-lambda-d-with-mle-true" title="Permalink to this headline">#</a></h1>
<section id="model-2-model-lambda-d-is-trained-on-lambda-d-as-data">
<h2>model 2 (“model_lambda_D”) is trained on <span class="math notranslate nohighlight">\(\lambda_D\)</span> as data:<a class="headerlink" href="#model-2-model-lambda-d-is-trained-on-lambda-d-as-data" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[ X_{train} = (\theta_{\text{continuous}}, \nu_{\text{continuous}}, \lambda_D )\]</div>
<div class="math notranslate nohighlight">
\[t_{train} = Z_{(\theta,\nu)} \]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>lambda_D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>7.935242</td>
      <td>8.395492</td>
      <td>16.267211</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>6.139615</td>
      <td>4.151977</td>
      <td>14.083017</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>12.672168</td>
      <td>12.870366</td>
      <td>38.520506</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>4.584800</td>
      <td>11.905427</td>
      <td>23.722618</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>7.804724</td>
      <td>7.900182</td>
      <td>8.452563</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>
<span class="n">model_lambda_D</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">model_lambda_D</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=3, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="train-mle-model-on-lambda-d">
<h1>Train MLE Model on <span class="math notranslate nohighlight">\(\lambda_D\)</span><a class="headerlink" href="#train-mle-model-on-lambda-d" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#initiate MLE model </span>
<span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_MLE_with_lambda</span><span class="p">,</span> <span class="n">optimizer_MLE_with_lambda</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_MLE_with_lambda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_MLE_with_lambda</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">200</span>


<span class="n">n_iterations</span><span class="o">=</span><span class="mi">100000</span>
<span class="c1">#train</span>
<span class="n">traces_MLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_MLE_with_lambda</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_MLE_with_lambda</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    differentiable: False
    eps: 1e-08
    foreach: None
    lr: 0.0063975512794992
    maximize: False
    momentum: 0
    weight_decay: 0
)



RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=3, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
train_t shape =  (800000,) 

train_x shape =  (800000, 3) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.063917	  0.063403
      3200	  0.020041	  0.020020	  0.020020
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">29</span><span class="o">-</span><span class="mi">96</span><span class="n">ad585eee3d</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">21</span>               <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
<span class="g g-Whitespace">     </span><span class="mi">22</span>                 <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="ne">---&gt; </span><span class="mi">23</span>                  <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="nn">&lt;ipython-input-16-2392da994e32&gt;</span> in <span class="ni">train</span><span class="nt">(model, optimizer, avloss, batch_size, n_iterations, traces, step, window, MLE, with_lambda_D)</span>
<span class="g g-Whitespace">     </span><span class="mi">76</span> 
<span class="g g-Whitespace">     </span><span class="mi">77</span> 
<span class="ne">---&gt; </span><span class="mi">78</span>         <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">79</span> 
<span class="g g-Whitespace">     </span><span class="mi">80</span>         <span class="c1"># compute a noisy approximation to the average loss</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">&lt;ipython-input-15-34556416fa49&gt;</span> in <span class="ni">forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span> 
<span class="g g-Whitespace">     </span><span class="mi">34</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">35</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">204</span>             <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">205</span>         <span class="k">return</span> <span class="nb">input</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span> 

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/dropout.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span> 
<span class="g g-Whitespace">     </span><span class="mi">58</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">---&gt; </span><span class="mi">59</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">inplace</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">60</span> 
<span class="g g-Whitespace">     </span><span class="mi">61</span> 

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py</span> in <span class="ni">dropout</span><span class="nt">(input, p, training, inplace)</span>
<span class="g g-Whitespace">   </span><span class="mi">1250</span>     <span class="k">if</span> <span class="n">p</span> <span class="o">&lt;</span> <span class="mf">0.0</span> <span class="ow">or</span> <span class="n">p</span> <span class="o">&gt;</span> <span class="mf">1.0</span><span class="p">:</span>
<span class="g g-Whitespace">   </span><span class="mi">1251</span>         <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;dropout probability has to be between 0 and 1, &quot;</span> <span class="s2">&quot;but got </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">p</span><span class="p">))</span>
<span class="ne">-&gt; </span><span class="mi">1252</span>     <span class="k">return</span> <span class="n">_VF</span><span class="o">.</span><span class="n">dropout_</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span> <span class="k">if</span> <span class="n">inplace</span> <span class="k">else</span> <span class="n">_VF</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">training</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1253</span> 
<span class="g g-Whitespace">   </span><span class="mi">1254</span> 

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_MLE_with_lambda</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span>
<span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_True_Regressor_1.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>

    
<span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;models&#39;</span><span class="p">,</span> <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>

<span class="n">model_lambda_D</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">model_lambda_D</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">#OR</span>
<span class="c1">#model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
<span class="n">model_lambda_D</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_lambda_D</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=3, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<section id="check-out-eval-data-with-lambda-d">
<h2>Check out eval data with <span class="math notranslate nohighlight">\(\lambda_D\)</span><a class="headerlink" href="#check-out-eval-data-with-lambda-d" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_eval_data_2d_with_lambda_D</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">nbins_theta</span><span class="p">,</span> <span class="n">nbins_nu</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Make evaluation data composed of: binned theta and nu, and discrete N and M,</span>
<span class="sd">    and optionally theta_hat. The theta hat argument accpts an MLE boolean, therefore</span>
<span class="sd">    if trained on MLE data, the theta_hat that we use for evaluation is just </span>
<span class="sd">    n-m, including negative values.</span>
<span class="sd">    The return value of this function is used as the &quot;eval_data&quot; tensor below&quot;&quot;&quot;</span>
    <span class="c1">#if MLE true, load the model that was trained on MLE data and vice versa</span>
    <span class="c1"># N, M = D</span>
    <span class="c1"># nbins=NBINS</span>
    <span class="c1"># thetamin,thetamax=0,20</span>

    <span class="n">THETA_bin_centers</span> <span class="o">=</span> <span class="n">make_binned_X</span><span class="p">(</span><span class="n">X_min</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                                      <span class="n">X_max</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> 
                                      <span class="n">Nbins</span><span class="o">=</span><span class="n">nbins_theta</span><span class="p">)</span>
        
    <span class="n">NU_bin_centers</span> <span class="o">=</span> <span class="n">make_binned_X</span><span class="p">(</span><span class="n">X_min</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span>
                                  <span class="n">X_max</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> 
                                  <span class="n">Nbins</span><span class="o">=</span><span class="n">nbins_nu</span><span class="p">)</span>
        
    <span class="c1"># tensor = torch.Tensor([</span>
                           <span class="c1"># [x, y, theta_hat(N, M, MLE=True), N, M] </span>
                           <span class="c1"># for (x,y) in zip(THETA_bin_centers,NU_bin_centers)</span>
                          <span class="c1"># ])</span>
    <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span><span class="n">m</span><span class="o">=</span><span class="n">M</span><span class="p">,</span><span class="n">theta</span><span class="o">=</span><span class="n">THETA_bin_centers</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">NU_bin_centers</span><span class="p">,</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">lambda_D</span><span class="p">)</span><span class="o">==</span><span class="mi">1</span><span class="p">:</span>
    
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span>
                           <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_D</span><span class="p">]</span> 
                           <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">THETA_bin_centers</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">NU_bin_centers</span>
                          <span class="p">])</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span>
            <span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="n">N</span><span class="p">,</span><span class="n">m</span><span class="o">=</span><span class="n">M</span><span class="p">,</span><span class="n">theta</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="n">y</span><span class="p">,</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">THETA_bin_centers</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">NU_bin_centers</span>
        <span class="p">])</span>
        
    <span class="c1">#zip only traverses the lists monotonically, so experiment to use cross to take every combination of the two lists</span>
    
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">THETA_bin_centers</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">NU_bin_centers</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span><span class="p">,</span> <span class="n">eval_bins_theta_example</span><span class="p">,</span> <span class="n">eval_bins_nu_example</span> <span class="o">=</span><span class="n">make_eval_data_2d_with_lambda_D</span><span class="p">(</span>
                                                                                    <span class="n">Bprime</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                                                                    <span class="n">train_df</span><span class="o">=</span>
                                                                                    <span class="n">train_df_MLE</span><span class="p">,</span> 
                                                                                    <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                                                                                    <span class="n">nbins_theta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>
                                                                                    <span class="n">nbins_nu</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.1000,  0.1000, 47.2960],
        [ 0.1000,  0.3000, 31.3303],
        [ 0.1000,  0.5000, 24.1681],
        ...,
        [19.9000, 19.5000, 80.1094],
        [19.9000, 19.7000, 80.7564],
        [19.9000, 19.9000, 81.4049]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="check-out-model-trained-on-lambda-d-prediction">
<h2>Check out model trained on <span class="math notranslate nohighlight">\(\lambda_D\)</span> prediction<a class="headerlink" href="#check-out-model-trained-on-lambda-d-prediction" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">usemodel_2d_with_lambda_D</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span> <span class="n">PARAMS_DICT</span><span class="o">=</span><span class="n">BEST_PARAMS</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; make evaluation data and evaluate the model at these data&quot;&quot;&quot;</span>
    <span class="c1">#Generate evaluation data at those fixed nu, N, M values</span>
    <span class="c1"># make_eval_data_2d has the following signature</span>
    <span class="c1">#make_eval_data_2d(Bprime, train_df, N, M, nbins_theta, nbins_nu)</span>
    <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins_theta</span><span class="p">,</span> <span class="n">eval_bins_nu</span> <span class="o">=</span><span class="n">make_eval_data_2d_with_lambda_D</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="n">Bprime</span><span class="p">,</span>
                                                                <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span> 
                                                                <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span> 
                                                                <span class="n">nbins_theta</span><span class="o">=</span><span class="n">nbinstheta</span><span class="p">,</span>
                                                               <span class="n">nbins_nu</span><span class="o">=</span><span class="n">nbinsnu</span><span class="p">)</span><span class="c1">#eval data is indipendent of MLE, since its just constants witha theta variable</span>
    
    <span class="c1"># if MLE==True:</span>
    <span class="c1">#     model=model</span>
    <span class="c1">#else load the model trained on non-MLE data</span>
    <span class="c1"># PATH=&#39;models/MLE_TRUE_Regressor_200.0K_training_iter.pt&#39;</span>
    
    <span class="c1">#LOAD TRAINED MODEL</span>
    <span class="n">with_theta_hat</span><span class="o">=</span><span class="kc">False</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span>
                          <span class="s1">&#39;models&#39;</span><span class="p">,</span> 
                          <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span>
                          <span class="s1">&#39;models&#39;</span><span class="p">,</span> 
                          <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>
        
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">str</span><span class="p">:</span>
        <span class="n">optimizer_name</span> <span class="o">=</span><span class="n">optimizer_name</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">PARAMS_DICT</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="c1">#EVALUATE AT AT EVAL_DATA</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;model path = &#39;</span><span class="p">,</span> <span class="n">PATH</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">eval_bins_theta</span><span class="p">,</span> <span class="n">eval_bins_nu</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># check it out</span>
<span class="n">phat</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">usemodel_2d_with_lambda_D</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
                                  <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                  <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
                                  <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> 
                          <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">)</span>
<span class="n">phat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model path =  /home/ali/Desktop/Pulled_Github_Repositories/LFI_HEP/models/2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1.       , 0.9999964, 0.9992188, ..., 1.       , 1.       ,
       1.       ], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">,</span>
                 <span class="n">PARAMS_DICT</span><span class="p">,</span>
                <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Plot histogrammed approximation of p-value as well as model evaluation at eval data &quot;&quot;&quot;</span>
    <span class="c1"># GET PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
    <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">make_hist_2d_data_2d_inference</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                  <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                  <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                          <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                   <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                          <span class="n">MLE</span><span class="p">)</span>
    
    <span class="n">bin_centers_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_theta_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_theta_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">bin_centers_nu</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nu_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nu_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="c1">#WHOLE RANGE</span>
    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    <span class="c1"># thetarange = (thetamin, 10)</span>
    <span class="c1"># nurange = (numin, 10)</span>
    

    <span class="c1">#Remember theta is on x and nu on y axes, so next line, each will be 2d</span>
    <span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">bin_centers_theta</span><span class="p">,</span> <span class="n">bin_centers_nu</span><span class="p">)</span>
    
    <span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span> <span class="o">=</span> <span class="n">THETA</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">NU</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">P_theta_nu</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">T</span>
    <span class="n">P_theta_nu_byhist</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="c1"># GET MODEL ESTIMATION AT SAME DATA</span>
    <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">lambda_test_2d</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="n">phat_MODEL</span><span class="p">,</span> <span class="n">phatbins_theta_MODEL</span><span class="p">,</span> <span class="n">phatbins_nu_MODEL</span> <span class="o">=</span> <span class="n">usemodel_2d_with_lambda_D</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="n">Bprime</span><span class="p">,</span>
                                  <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                  <span class="n">N</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="n">M</span><span class="p">,</span>
                                  <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">,</span> 
                                <span class="n">nbinstheta</span><span class="o">=</span><span class="n">nbinstheta</span><span class="p">,</span> 
                                <span class="n">nbinsnu</span><span class="o">=</span><span class="n">nbinsnu</span><span class="p">,</span>
                                <span class="n">PARAMS_DICT</span><span class="o">=</span><span class="n">PARAMS_DICT</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">plothist</span><span class="p">:</span>
    <span class="c1"># PLOT PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                   <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span>
                   <span class="n">weights</span><span class="o">=</span><span class="n">P_theta_nu_byhist</span><span class="p">,</span>
                 <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues_r&#39;</span>
                 <span class="p">)</span>
    
    <span class="n">CLs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.683</span><span class="p">,</span><span class="mf">0.80</span><span class="p">,</span> <span class="mf">0.90</span><span class="p">,</span><span class="mf">0.95</span><span class="p">])</span>
    
    <span class="c1">#To draw contours, the intensity (the p-value) must be 2D again</span>
    <span class="n">P_theta_nu_byhist_2d</span> <span class="o">=</span> <span class="n">P_theta_nu_byhist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1">#for contours everything has to be 2d</span>
    
   <span class="c1"># CONTOUR LINES FOR PVALUE ESTIMATED BY HISSTOGRAMMING APPROXIMATION</span>
   <span class="c1"># AT CHOSEN CLs</span>
    <span class="n">histogram_approx_contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA</span><span class="p">,</span> 
                                         <span class="n">NU</span><span class="p">,</span> 
                                         <span class="n">P_theta_nu_byhist_2d</span><span class="p">,</span>
              <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
              <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">,</span>
                                         <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                        <span class="c1"># cmap=&#39;gist_earth_r&#39;,</span>
                                         <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span>
                        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;histogram approx&#39;</span><span class="p">,</span>
                                         <span class="n">linestyles</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span>
                       <span class="p">)</span>
    
    
    <span class="c1"># CONTOUR LINES FOR PVALUE PREDICTED BY MODEL AT CHOSEN CLs</span>
    <span class="n">THETA_MODEL</span><span class="p">,</span> <span class="n">NU_MODEL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">phatbins_theta_MODEL</span><span class="p">,</span> <span class="n">phatbins_nu_MODEL</span><span class="p">)</span>
    <span class="n">phat_MODEL_CONTOUR</span> <span class="o">=</span> <span class="n">phat_MODEL</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA_MODEL</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">phat_MODEL_CONTOUR</span><span class="o">=</span><span class="n">phat_MODEL_CONTOUR</span><span class="o">.</span><span class="n">T</span>
    <span class="n">model_approx_contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA_MODEL</span><span class="p">,</span> 
                                     <span class="n">NU_MODEL</span><span class="p">,</span> 
                                     <span class="n">phat_MODEL_CONTOUR</span><span class="p">,</span>
          <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
          <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">,</span>
                                     <span class="n">linewidths</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;rainbow&#39;</span><span class="p">,</span>
                    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Model prediction&#39;</span>
                   <span class="p">)</span>

    
<span class="c1">#     #label the contours</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">histogram_approx_contours</span><span class="p">,</span> 
              <span class="n">histogram_approx_contours</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span> 
              <span class="n">inline</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
              <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%4.2f</span><span class="s1">&#39;</span><span class="p">,</span> 
              <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span>
              <span class="n">fontsize</span><span class="o">=</span><span class="mi">22</span><span class="p">)</span>
    <span class="c1"># ax.text(x=0.3, y=4.5, s=&#39;$0.68$&#39;, fontsize=22, rotation=-70)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;$N= </span><span class="si">%s</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="s1">&#39;$M=</span><span class="si">%s</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">19</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\nu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">24</span><span class="p">)</span>
    <span class="c1"># ax.set_title(r&#39;$p$-value by $\mathbf{h}$ (dashed) and $\mathbf{f^{\{N,M\}} }$ (solid): $N = %s$ , $M  = %s$, MLE = %s &#39; % (str(N),str(M), str(MLE)),fontsize=16)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p$-value by $\mathbf</span><span class="si">{h}</span><span class="s1">$ (dashed) and $\mathbf{f^{\{\lambda_D \}} }$ (solid); MLE = </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span>  <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)</span> <span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>    <span class="c1">#add contour color bar</span>
    <span class="c1"># cbar = fig.colorbar(histogram_approx_contours, ax=ax)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="c1">#     ax.legend()</span>
    
    <span class="k">if</span> <span class="n">save_plot</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">],</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> 
        <span class="sa">f</span><span class="s2">&quot;2D_Hist_LAMBDAD_thetamin_</span><span class="si">{</span><span class="n">thetamin</span><span class="si">}</span><span class="s2">_thetamax_</span><span class="si">{</span><span class="n">thetamax</span><span class="si">}</span><span class="s2">_numin_</span><span class="si">{</span><span class="n">numin</span><span class="si">}</span><span class="s2">_numax_</span><span class="si">{</span><span class="n">numax</span><span class="si">}</span><span class="s2">_N_</span><span class="si">{</span><span class="n">N</span><span class="si">}</span><span class="s2">_M_</span><span class="si">{</span><span class="n">M</span><span class="si">}</span><span class="s2">_MLE_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)</span><span class="si">}</span><span class="s2">_2D_INFERENCE.eps&quot;</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_96_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_96_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_97_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_97_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_1.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_1.png" />
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_2.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_2.png" />
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_3.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_98_3.png" />
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="train-on-lambda-d-with-mle-false">
<h1>3.4 Train on <span class="math notranslate nohighlight">\(\lambda_D\)</span> with MLE=False<a class="headerlink" href="#train-on-lambda-d-with-mle-false" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>lambda_D</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>15.251919</td>
      <td>11.474215</td>
      <td>37.498407</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>15.086652</td>
      <td>15.819146</td>
      <td>53.117040</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>10.079228</td>
      <td>16.617979</td>
      <td>27.785239</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>12.698148</td>
      <td>9.160200</td>
      <td>12.877531</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>6.279396</td>
      <td>0.723810</td>
      <td>28.966840</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BEST_PARAMS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> 
                                    <span class="s1">&#39;best_params&#39;</span><span class="p">,</span>
                                    <span class="s1">&#39;best_params_Test_Trials.csv&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">)</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Unnamed: 0  n_layers  hidden_size  dropout optimizer_name  learning_rate  \
0           0         4           11  0.13208        RMSprop       0.006398   

   batch_size  
0        1000  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#initiate MLE model </span>

    
<span class="n">n_layers</span><span class="o">=</span><span class="mi">20</span>
<span class="n">hidden_size</span><span class="o">=</span><span class="mi">10</span> 
<span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span>
<span class="n">optimizer_name</span><span class="o">=</span><span class="s1">&#39;Adam&#39;</span> 
<span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.006</span>
<span class="n">batch_size</span><span class="o">=</span><span class="mi">132</span> 
<span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
<span class="n">model_nonMLE_with_lambda</span><span class="o">=</span><span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>


<span class="n">optimizer_nonMLE_with_lambda</span><span class="o">=</span><span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="p">)(</span><span class="n">model_nonMLE_with_lambda</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_nonMLE_with_lambda</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_nonMLE_with_lambda</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">200</span>


<span class="n">n_iterations</span><span class="o">=</span><span class="mi">10000</span>
<span class="c1">#train</span>
<span class="n">traces_MLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_nonMLE_with_lambda</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_nonMLE_with_lambda</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: False
    lr: 0.006
    maximize: False
    weight_decay: 0
)



RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=3, out_features=10, bias=True)
    (1): Dropout(p=0.1, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=10, out_features=10, bias=True)
    (4): Dropout(p=0.1, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=10, out_features=10, bias=True)
    (7): Dropout(p=0.1, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=10, out_features=10, bias=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=10, out_features=10, bias=True)
    (13): Dropout(p=0.1, inplace=False)
    (14): ReLU()
    (15): Linear(in_features=10, out_features=10, bias=True)
    (16): Dropout(p=0.1, inplace=False)
    (17): ReLU()
    (18): Linear(in_features=10, out_features=10, bias=True)
    (19): Dropout(p=0.1, inplace=False)
    (20): ReLU()
    (21): Linear(in_features=10, out_features=10, bias=True)
    (22): Dropout(p=0.1, inplace=False)
    (23): ReLU()
    (24): Linear(in_features=10, out_features=10, bias=True)
    (25): Dropout(p=0.1, inplace=False)
    (26): ReLU()
    (27): Linear(in_features=10, out_features=10, bias=True)
    (28): Dropout(p=0.1, inplace=False)
    (29): ReLU()
    (30): Linear(in_features=10, out_features=10, bias=True)
    (31): Dropout(p=0.1, inplace=False)
    (32): ReLU()
    (33): Linear(in_features=10, out_features=10, bias=True)
    (34): Dropout(p=0.1, inplace=False)
    (35): ReLU()
    (36): Linear(in_features=10, out_features=10, bias=True)
    (37): Dropout(p=0.1, inplace=False)
    (38): ReLU()
    (39): Linear(in_features=10, out_features=10, bias=True)
    (40): Dropout(p=0.1, inplace=False)
    (41): ReLU()
    (42): Linear(in_features=10, out_features=10, bias=True)
    (43): Dropout(p=0.1, inplace=False)
    (44): ReLU()
    (45): Linear(in_features=10, out_features=10, bias=True)
    (46): Dropout(p=0.1, inplace=False)
    (47): ReLU()
    (48): Linear(in_features=10, out_features=10, bias=True)
    (49): Dropout(p=0.1, inplace=False)
    (50): ReLU()
    (51): Linear(in_features=10, out_features=10, bias=True)
    (52): Dropout(p=0.1, inplace=False)
    (53): ReLU()
    (54): Linear(in_features=10, out_features=10, bias=True)
    (55): Dropout(p=0.1, inplace=False)
    (56): ReLU()
    (57): Linear(in_features=10, out_features=10, bias=True)
    (58): Dropout(p=0.1, inplace=False)
    (59): ReLU()
    (60): Linear(in_features=10, out_features=1, bias=True)
    (61): Sigmoid()
  )
)
train_t shape =  (800000,) 

train_x shape =  (800000, 3) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.253079	  0.253075
      9800	  0.038560	  0.039085	  0.039085
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model_2D</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_nonMLE_with_lambda</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>saving model with name  2D_NONMLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PARAM_DICT_2</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span>
<span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> 
<span class="s1">&#39;dropout&#39;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">,</span>
<span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="s1">&#39;Adam&#39;</span><span class="p">,</span> 
<span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span><span class="mf">0.006</span><span class="p">,</span>
<span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="mi">132</span> <span class="p">,</span>
<span class="s1">&#39;NFEATURES&#39;</span><span class="p">:</span><span class="mi">3</span>
<span class="p">}</span>
<span class="n">PARAM_DICT_2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{&#39;n_layers&#39;: 20,
 &#39;hidden_size&#39;: 10,
 &#39;dropout&#39;: 0.1,
 &#39;optimizer_name&#39;: &#39;Adam&#39;,
 &#39;learning_rate&#39;: 0.006,
 &#39;batch_size&#39;: 132,
 &#39;NFEATURES&#39;: 3}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
       <span class="c1">#       Bprime=100000000,</span>
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
             <span class="n">PARAMS_DICT</span><span class="o">=</span><span class="n">PARAM_DICT_2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model path =  /home/ali/Desktop/Pulled_Github_Repositories/LFI_HEP/models/2D_NONMLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt
</pre></div>
</div>
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_105_2.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_105_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig_ax</span><span class="p">()</span>
<span class="n">plot_P_byhist_2d_with_model_lambda_D</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">33</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">plothist</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
<section id="compute-coverage">
<h2>Compute Coverage<a class="headerlink" href="#compute-coverage" title="Permalink to this headline">#</a></h2>
<p>Get dataframe with <span class="math notranslate nohighlight">\(\hat{p}\)</span> computed at every point</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_df</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">evaluate_2d_model_on_df</span><span class="p">(</span><span class="n">MLE</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; returns the dataframe, can be used if the dataframe is saved in csv format</span>
<span class="sd">    of if it is already in dataframe format (e.g. generated in this notebook). &quot;&quot;&quot;</span>
    <span class="c1"># SUBSAMPLE=int(1e5)</span>
    <span class="n">eval_df</span> <span class="o">=</span> <span class="n">load_2d_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="p">)</span>
    <span class="c1">#Convert DF to tensor</span>
    <span class="n">eval_tensor</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">eval_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
    <span class="n">eval_tensor</span><span class="o">=</span><span class="n">eval_tensor</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    
    <span class="c1">#load model</span>
    <span class="k">if</span> <span class="n">with_lambda_D</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_MLE_WITH_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">3</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">MODEL_FILE_NAME</span><span class="o">=</span><span class="s1">&#39;2D_NONMLE_WITHOUT_LAMBDA_D_True_Regressor_10.0K_training_iter_with_theta_hat.pt&#39;</span>
        <span class="n">NFEATURES</span><span class="o">=</span><span class="mi">5</span>
    
    <span class="n">PATH</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span>
                  <span class="s1">&#39;models&#39;</span><span class="p">,</span> 
                  <span class="n">MODEL_FILE_NAME</span><span class="p">)</span>
    
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="c1"># instantiate model</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">NFEATURES</span><span class="p">,</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="c1">#EVALUATE AT AT EVAL_DATA</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">phat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;phat&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">phat</span>
    <span class="k">return</span> <span class="n">eval_df</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phat_df</span> <span class="o">=</span> <span class="n">evaluate_2d_model_on_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">phat_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">RuntimeError</span><span class="g g-Whitespace">                              </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">35</span><span class="o">-</span><span class="n">c30ef6cbd50e</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">phat_df</span> <span class="o">=</span> <span class="n">evaluate_2d_model_on_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">with_lambda_D</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">2</span> <span class="n">phat_df</span>

<span class="nn">&lt;ipython-input-34-e742c3449dea&gt;</span> in <span class="ni">evaluate_2d_model_on_df</span><span class="nt">(MLE, with_lambda_D)</span>
<span class="g g-Whitespace">     </span><span class="mi">37</span>     <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">38</span>     <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="ne">---&gt; </span><span class="mi">39</span>     <span class="n">phat</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_tensor</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">40</span>     <span class="n">eval_df</span><span class="p">[</span><span class="s1">&#39;phat&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">phat</span>
<span class="g g-Whitespace">     </span><span class="mi">41</span>     <span class="k">return</span> <span class="n">eval_df</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">&lt;ipython-input-11-34556416fa49&gt;</span> in <span class="ni">forward</span><span class="nt">(self, x)</span>
<span class="g g-Whitespace">     </span><span class="mi">33</span> 
<span class="g g-Whitespace">     </span><span class="mi">34</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
<span class="ne">---&gt; </span><span class="mi">35</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">202</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">203</span>         <span class="k">for</span> <span class="n">module</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">204</span>             <span class="nb">input</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">205</span>         <span class="k">return</span> <span class="nb">input</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span> 

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py</span> in <span class="ni">_call_impl</span><span class="nt">(self, *input, **kwargs)</span>
<span class="g g-Whitespace">   </span><span class="mi">1192</span>         <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_hooks</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pre_hooks</span> <span class="ow">or</span> <span class="n">_global_backward_hooks</span>
<span class="g g-Whitespace">   </span><span class="mi">1193</span>                 <span class="ow">or</span> <span class="n">_global_forward_hooks</span> <span class="ow">or</span> <span class="n">_global_forward_pre_hooks</span><span class="p">):</span>
<span class="ne">-&gt; </span><span class="mi">1194</span>             <span class="k">return</span> <span class="n">forward_call</span><span class="p">(</span><span class="o">*</span><span class="nb">input</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">   </span><span class="mi">1195</span>         <span class="c1"># Do not call functions when jit is used</span>
<span class="g g-Whitespace">   </span><span class="mi">1196</span>         <span class="n">full_backward_hooks</span><span class="p">,</span> <span class="n">non_full_backward_hooks</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="nn">~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py</span> in <span class="ni">forward</span><span class="nt">(self, input)</span>
<span class="g g-Whitespace">    </span><span class="mi">112</span> 
<span class="g g-Whitespace">    </span><span class="mi">113</span>     <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">114</span>         <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">115</span> 
<span class="g g-Whitespace">    </span><span class="mi">116</span>     <span class="k">def</span> <span class="nf">extra_repr</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>

<span class="ne">RuntimeError</span>: mat1 and mat2 shapes cannot be multiplied (1000000x4 and 3x11)
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[
\mathbb{PV} (\theta, \nu) =\int_{\lambda_D}^\infty f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid \theta_{0} \big) \ d \lambda_{gen} 
\]</div>
<p>And since
$<span class="math notranslate nohighlight">\( 
\int_{- \infty}^{\lambda_D} f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid \theta_{0} \big) \ d \lambda_{gen} + \int_{\lambda_D}^\infty f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid \theta_{0} \big) \ d \lambda_{gen} =1
\)</span>$</p>
<p>And
$<span class="math notranslate nohighlight">\( \mathbb{CDF}(\lambda_D; \lambda_{gen}) \equiv \int_{- \infty}^{\lambda_D} f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid \theta_{0} \big) \ d \lambda_{gen} \)</span>$</p>
<p>We can say
$<span class="math notranslate nohighlight">\( \mathbb{PV}(\theta,\nu) = 1 - \mathbb{CDF}(\lambda_D; \lambda_{gen}) \)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># get 68% confidence set</span>
<span class="n">tau</span><span class="o">=</span><span class="mf">0.68</span>
<span class="n">phat_df_068</span> <span class="o">=</span> <span class="n">phat_df</span><span class="p">[</span><span class="n">phat_df</span><span class="p">[</span><span class="s1">&#39;phat&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">tau</span><span class="p">]</span>
<span class="n">phat_df_068</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
      <th>phat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>10</th>
      <td>1.506643</td>
      <td>5.172910</td>
      <td>6</td>
      <td>9</td>
      <td>3</td>
      <td>0.574145</td>
    </tr>
    <tr>
      <th>33</th>
      <td>0.925470</td>
      <td>8.859741</td>
      <td>1</td>
      <td>7</td>
      <td>6</td>
      <td>0.611848</td>
    </tr>
    <tr>
      <th>52</th>
      <td>9.810942</td>
      <td>2.432338</td>
      <td>8</td>
      <td>9</td>
      <td>1</td>
      <td>0.531324</td>
    </tr>
    <tr>
      <th>56</th>
      <td>1.589864</td>
      <td>10.508963</td>
      <td>0</td>
      <td>9</td>
      <td>9</td>
      <td>0.259103</td>
    </tr>
    <tr>
      <th>72</th>
      <td>4.379040</td>
      <td>4.062182</td>
      <td>5</td>
      <td>8</td>
      <td>3</td>
      <td>0.243659</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<section id="coverage-algorithm">
<h3>Coverage algorithm:<a class="headerlink" href="#coverage-algorithm" title="Permalink to this headline">#</a></h3>
<ol>
<li><p>Get confidence set at <span class="math notranslate nohighlight">\(\tau\)</span>, which is the dataframe for which <span class="math notranslate nohighlight">\(\hat{p}&lt;\tau\)</span></p></li>
<li><p>Get the <span class="math notranslate nohighlight">\(\mu,\nu\)</span> from the desired confidence set <span class="math notranslate nohighlight">\(\vec{\theta}_\tau = \{ (\mu,\nu) \}_\tau\)</span></p></li>
<li><p>For i in range(<span class="math notranslate nohighlight">\(\vec{\theta}_\tau\)</span>):</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>     Generate $N_i, M_i$ of size 1000 each

     Calculate $\lambda_{D, \tau} =\lambda_D(\mu_{\tau, i}, \nu_{\tau,i}, N_i, M_i)$

     calculate $\hat{\hat{p}}=\hat{p}(\mu_i, lambda_{D,\tau})$

     calculate $mean(\hat{\hat{p}} &lt; tau)$
</pre></div>
</div>
</li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_param_points</span><span class="p">,</span> <span class="n">n_data_points_coverage</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">coverage</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_param_points_coverage</span>
</pre></div>
</div>
</div>
</div>
<p>What we find is that if we repeat the experiment multiple times at different choices of <span class="math notranslate nohighlight">\(N,M\)</span> is that the confidence sets will jump around (they are not fixed) which means that the intervals for <span class="math notranslate nohighlight">\(\theta,\nu\)</span> also jump around.</p>
<p><strong>What we want to do is to find a confidence interval for <span class="math notranslate nohighlight">\(\theta\)</span> indpendently of <span class="math notranslate nohighlight">\(\nu\)</span>. We do this by extension of the confidence set algorithm for <span class="math notranslate nohighlight">\(\theta,\nu)\)</span> to a confidence interval on <span class="math notranslate nohighlight">\(\theta\)</span> alone.</strong></p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="mapping-confidence-regions-sets-to-confidence-intervals">
<h1>Mapping Confidence Regions (Sets) to Confidence intervals<a class="headerlink" href="#mapping-confidence-regions-sets-to-confidence-intervals" title="Permalink to this headline">#</a></h1>
<p>We would like to extend map confidence region (or set) <span class="math notranslate nohighlight">\(R(D)\)</span> to univariate confidence interval for a particular parameter. What we currently have, is that
$<span class="math notranslate nohighlight">\(\mathbb{P} [ R(D) \text{ will cover the true }\{\theta,\nu\} \text{pair} ] \ge 1-\alpha \)</span>$</p>
<p>Or, in other words,</p>
<div class="math notranslate nohighlight">
\[\mathbb{P}\left( \theta_0 \in [\theta_{lo},\theta^{up} ] \text{ and } \nu_0 \in [\nu_{lo},\nu^{up} ] \right) \ge 1-\alpha \tag{5} \]</div>
<p>We would like to map the statement in Eq 5 to a confidence interval on an individual parameter
$<span class="math notranslate nohighlight">\(\mathbb{P}\left( \theta_0 \in [\theta_{lo},\theta^{up} ] \right) \ge 1-\alpha \tag{5} \)</span>$</p>
<p>(Aside: it is interesting to note that the value <span class="math notranslate nohighlight">\(\theta_0\)</span> is fixed and unknown while the variables <span class="math notranslate nohighlight">\(\theta_{lo},\theta_{up}\)</span> are random variables).</p>
<p>i.e. map The confidence region to a coverage probability of an individual parameter, say parameter of interest</p>
<div class="math notranslate nohighlight">
\[\mathbb{CR}({\theta,\nu}) \rightarrow \mathbb{CPI}(\theta)\]</div>
<p>So the NN is just a function of <span class="math notranslate nohighlight">\(\theta\)</span> and a particular CL <span class="math notranslate nohighlight">\(\tau\)</span> , and gives the coverage probability of an individual parameter <span class="math notranslate nohighlight">\(\mathbb{CPI}(\theta,\tau)\)</span> . Once we have this function, we can say “I would like to have a confidence level on <span class="math notranslate nohighlight">\(\theta\)</span> of 68%, and a way to achieve that is to construct a set whose coverage probability is 73%.</p>
<p>Currently, we can’t do that mapping because we only have the confidence region, i.e. a confidence interval on one parameter only in the existence of the confidence interval on the other parameter. We would like to do it globally, such that if we have confidence region, we can map that to confidence interval of other parameter regardless of the value of the other parameter. We use the Gaussian conffidence ellipse as a heuristic motivation of what we would like to do.</p>
<section id="check-coverage-of-the-set-at-several-tau-values-and-observe-that-for-the-1d-case-using-our-2d-algorithm-the-coverage-is-not-exact">
<h2>Check coverage of the set at several <span class="math notranslate nohighlight">\(\tau\)</span> values and observe that for the 1D case, using our 2D algorithm the coverage is not exact<a class="headerlink" href="#check-coverage-of-the-set-at-several-tau-values-and-observe-that-for-the-1d-case-using-our-2d-algorithm-the-coverage-is-not-exact" title="Permalink to this headline">#</a></h2>
</section>
<section id="algorithm">
<h2>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this headline">#</a></h2>
<p>We want an input being the data <span class="math notranslate nohighlight">\(D\)</span> and paramters <span class="math notranslate nohighlight">\(\theta\)</span> generated on-the-fly, and the output being a CI on a parameter.</p>
<p>Another advantage of this approach is that it can be done in an arbitrary number of dimensions</p>
<p>The essential idea of the algorithm is to simply generate parameter points inside a particular confidence set, and take the minimum and maximum of those points as the upper and lower confidence intervals. Once you have the edges of a parameter at a particular CL, you can map the CS to the CI of that parameter at that CL.</p>
<p>Essentially, for a given CL, we have the contours in the region, so the edges of a parameter at the given CL can be found
$<span class="math notranslate nohighlight">\(\{ \vec{\mu}_{edge}^{CL}, \vec{\nu}_{edge}^{CL} \}=  \{ \vec{\mu}, \vec{\nu} : \hat{p} \le CL \}\)</span>$</p>
<p>So that the intervals for a parameter at a given CL is simply
$<span class="math notranslate nohighlight">\((\mu_{lo}, \mu_{up} ) = \left( min(\vec{\mu}_{edge}^{CL}), max(\vec{\mu}_{edge}^{CL}) \right)  \)</span>$</p>
<p>(idea another way we can do this is potentially to use <span class="math notranslate nohighlight">\(\lambda_{2D}\)</span> to get the confidence set, but then use <span class="math notranslate nohighlight">\(\lambda_{1D}(\theta)\)</span> to get the interval of <span class="math notranslate nohighlight">\(\theta\)</span> within the set.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span><span class="s1">&#39;images&#39;</span><span class="p">,</span><span class="s1">&#39;Confidence_set_any_tau_algorithm.png&#39;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_122_0.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_122_0.png" />
</div>
</div>
<p>The first step is that we need a dataset with the estimated p-value at each datapoint</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ev_t</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">train_df_MLE</span><span class="p">[[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">())</span>
<span class="n">ev_t</span><span class="o">=</span><span class="n">ev_t</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="c1"># ev_t = ev_t.T</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="p">(</span><span class="n">ev_t</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[0.4487],
        [0.4715],
        [0.4503],
        ...,
        [0.4648],
        [0.4544],
        [0.4552]], grad_fn=&lt;SigmoidBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<p>Pick out a confidence set. A confidence set is given by
$<span class="math notranslate nohighlight">\(\mathbb{P}(\lambda \le \lambda_0 \mid \theta_0) \le \tau\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># X, Y = np.meshgrid(phat_df_068[&#39;theta&#39;], phat_df_068[&#39;nu&#39;])</span>
<span class="c1"># phat_df_068 = phat_df_068[&#39;phat&#39;].to_numpy()</span>
<span class="c1"># plt.hist2d(phat_df_068[&#39;theta&#39;], phat_df_068[&#39;nu&#39;], weights=phat_df_068[&#39;phat&#39;])</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="mi">1</span> <span class="o">&lt;=</span> <span class="mi">5</span> <span class="o">&lt;=</span> <span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span> 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array(1)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_confidence_set_data_for_given_tau</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">tau</span><span class="p">):</span>
    <span class="n">tau</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="n">tau</span><span class="p">)</span>
    <span class="n">phat_df_tau</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;phat&#39;</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">tau</span><span class="p">]</span>
    
    <span class="n">theta_edge</span> <span class="o">=</span> <span class="n">phat_df_tau</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span>
    <span class="n">nu_edge</span> <span class="o">=</span> <span class="n">phat_df_tau</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span>
    <span class="n">theta_lo</span><span class="p">,</span> <span class="n">theta_up</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">theta_edge</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">theta_edge</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;at </span><span class="si">{</span><span class="n">tau</span><span class="si">}</span><span class="s1"> CL, (theta_lo, theta_up)= </span><span class="si">{</span><span class="n">theta_lo</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">theta_up</span><span class="si">}</span><span class="s1"> )&#39;</span><span class="p">)</span>
    <span class="n">nu_lo</span><span class="p">,</span> <span class="n">nu_up</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">nu_edge</span><span class="p">),</span> <span class="nb">max</span><span class="p">(</span><span class="n">nu_edge</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;at </span><span class="si">{</span><span class="n">tau</span><span class="si">}</span><span class="s1"> CL, (nu_lo, nu_up)= </span><span class="si">{</span><span class="n">nu_lo</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">nu_up</span><span class="si">}</span><span class="s1"> )&#39;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">is_between</span><span class="p">(</span><span class="n">low</span><span class="p">,</span><span class="n">high</span><span class="p">,</span><span class="n">val</span><span class="p">):</span>
        <span class="n">low</span><span class="p">,</span><span class="n">high</span><span class="p">,</span><span class="n">val</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">low</span><span class="p">),</span><span class="nb">float</span><span class="p">(</span><span class="n">high</span><span class="p">),</span><span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">low</span> <span class="o">&lt;=</span> <span class="n">val</span> <span class="o">&lt;=</span> <span class="n">high</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Z</span>
    <span class="n">Z_theta_l</span><span class="p">,</span> <span class="n">Z_nu_l</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ind</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">():</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span>
        <span class="n">Z_theta</span> <span class="o">=</span> <span class="n">is_between</span><span class="p">(</span><span class="n">theta_lo</span><span class="p">,</span> <span class="n">theta_up</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>
        <span class="n">Z_nu</span> <span class="o">=</span> <span class="n">is_between</span><span class="p">(</span><span class="n">nu_lo</span><span class="p">,</span> <span class="n">nu_up</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span>
        <span class="c1"># df.loc[ind, &#39;Z_theta&#39;] = Z_theta</span>
        <span class="c1"># df[&#39;Z_nu&#39;]=Z_nu</span>
        <span class="n">Z_theta_l</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Z_theta</span><span class="p">)</span>
    <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Z_theta&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">Z_theta_l</span>
    
    
    <span class="c1"># data = phat_df_tau.to_numpy()</span>
    <span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> 
                           <span class="s1">&#39;Z_theta_Z_nu_Confidence_Set_Data_Tau_68.csv&#39;</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">df</span>
    
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dd</span> <span class="o">=</span> <span class="n">generate_confidence_set_data_for_given_tau</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">phat_df</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.68</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">NameError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">38</span><span class="o">-</span><span class="mi">06</span><span class="n">d50fd889f1</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">dd</span> <span class="o">=</span> <span class="n">generate_confidence_set_data_for_given_tau</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">phat_df</span><span class="p">[:</span><span class="mi">1000</span><span class="p">],</span> <span class="n">tau</span><span class="o">=</span><span class="mf">0.68</span><span class="p">)</span>

<span class="ne">NameError</span>: name &#39;phat_df&#39; is not defined
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dd</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
      <th>phat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.557383</td>
      <td>11.440410</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
      <td>0.999998</td>
    </tr>
    <tr>
      <th>1</th>
      <td>11.598479</td>
      <td>4.503764</td>
      <td>5</td>
      <td>9</td>
      <td>4</td>
      <td>0.905840</td>
    </tr>
    <tr>
      <th>2</th>
      <td>11.626689</td>
      <td>11.343044</td>
      <td>4</td>
      <td>8</td>
      <td>4</td>
      <td>0.999997</td>
    </tr>
    <tr>
      <th>3</th>
      <td>17.900354</td>
      <td>0.329772</td>
      <td>-5</td>
      <td>3</td>
      <td>8</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>8.989809</td>
      <td>6.036802</td>
      <td>-1</td>
      <td>2</td>
      <td>3</td>
      <td>0.999961</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>995</th>
      <td>17.149544</td>
      <td>4.878327</td>
      <td>6</td>
      <td>9</td>
      <td>3</td>
      <td>0.999284</td>
    </tr>
    <tr>
      <th>996</th>
      <td>1.277430</td>
      <td>16.458159</td>
      <td>0</td>
      <td>5</td>
      <td>5</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>997</th>
      <td>18.961302</td>
      <td>3.279090</td>
      <td>-7</td>
      <td>1</td>
      <td>8</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>998</th>
      <td>4.034487</td>
      <td>0.953814</td>
      <td>7</td>
      <td>8</td>
      <td>1</td>
      <td>0.619799</td>
    </tr>
    <tr>
      <th>999</th>
      <td>4.995561</td>
      <td>17.122446</td>
      <td>3</td>
      <td>8</td>
      <td>5</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
<p>1000 rows × 6 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_68</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span> 
                           <span class="s1">&#39;Z_theta_Z_nu_Confidence_Set_Data_Tau_68.csv&#39;</span><span class="p">))</span>
<span class="n">df_68</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
      <th>phat</th>
      <th>Z_theta</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
      <td>1000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>499.500000</td>
      <td>10.063233</td>
      <td>10.105382</td>
      <td>0.033000</td>
      <td>5.117000</td>
      <td>5.084000</td>
      <td>0.959973</td>
      <td>0.553000</td>
    </tr>
    <tr>
      <th>std</th>
      <td>288.819436</td>
      <td>5.807983</td>
      <td>5.653278</td>
      <td>3.687751</td>
      <td>2.665035</td>
      <td>2.558415</td>
      <td>0.132278</td>
      <td>0.497432</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.064964</td>
      <td>0.002273</td>
      <td>-8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.243659</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>249.750000</td>
      <td>5.033145</td>
      <td>5.257369</td>
      <td>-3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
      <td>0.999308</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>499.500000</td>
      <td>10.033437</td>
      <td>10.281782</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>0.999998</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>749.250000</td>
      <td>14.996700</td>
      <td>15.002229</td>
      <td>3.000000</td>
      <td>8.000000</td>
      <td>7.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>999.000000</td>
      <td>19.996722</td>
      <td>19.998460</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_68</span><span class="p">[</span><span class="s1">&#39;Z_nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
<hr class="docutils" />
<hr class="docutils" />
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="only-1d-inference-on-theta-independently-of-nu">
<h1>Only 1D inference on <span class="math notranslate nohighlight">\(\theta\)</span> (independently of <span class="math notranslate nohighlight">\(\nu\)</span>)<a class="headerlink" href="#only-1d-inference-on-theta-independently-of-nu" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_hist_2d_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">):</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">nu</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span> <span class="o">&lt;</span> 
         <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    <span class="c1"># bins = binsize(Bprime)</span>

    <span class="c1"># Z-weighted histogram   (count the number of ones per bin)</span>
    <span class="c1">#theta will be on axis and nu on y axis</span>
    <span class="n">y_theta_nu_w</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span>
                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span> 
                          <span class="n">weights</span><span class="o">=</span><span class="n">Z</span><span class="p">)</span>
    
    <span class="c1"># unweighted histogram (count number of ones and zeros per bin)</span>
    <span class="n">y_theta_nu_uw</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram2d</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span>
                          <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">))</span>
    <span class="n">eps</span><span class="o">=</span><span class="mf">1e-15</span>
    <span class="n">P_theta_nu</span> <span class="o">=</span>  <span class="n">y_theta_nu_w</span> <span class="o">/</span> <span class="p">(</span><span class="n">y_theta_nu_uw</span> <span class="o">+</span> <span class="n">eps</span><span class="p">)</span>    
    <span class="c1">#P_theta_nu approximates E[Z]</span>
    <span class="k">return</span> <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">make_hist_2d_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">P_theta_nu</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">bb_theta_edges</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(100, 100)
(101,)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_P_byhist</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                      <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="p">,</span>
                 <span class="n">save_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="n">P_theta_nu</span><span class="p">,</span> <span class="n">bb_theta_edges</span><span class="p">,</span> <span class="n">bb_nu_edges</span> <span class="o">=</span> <span class="n">make_hist_2d_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                  <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                  <span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> 
                          <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                   <span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">,</span>                    
                          <span class="n">MLE</span><span class="p">)</span>
    
    <span class="n">bin_centers_theta</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_theta_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_theta_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">bin_centers_nu</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nu_edges</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nu_edges</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    
    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="n">nurange</span> <span class="o">=</span> <span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">)</span>
    
    
    <span class="c1">#Remember theta is on x and nu on y axes, so next line, each will be 2d</span>
    <span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">bin_centers_theta</span><span class="p">,</span> <span class="n">bin_centers_nu</span><span class="p">)</span>
    
    <span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span> <span class="o">=</span> <span class="n">THETA</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">NU</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">P_theta_nu</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">T</span>
    <span class="n">P_theta_nu_byhist</span> <span class="o">=</span> <span class="n">P_theta_nu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">hist2d</span><span class="p">(</span><span class="n">THETA_1d</span><span class="p">,</span> <span class="n">NU_1d</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="p">(</span><span class="n">nbinstheta</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="p">),</span> 
               <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="n">thetarange</span><span class="p">,</span> <span class="n">nurange</span><span class="p">),</span>
               <span class="n">weights</span><span class="o">=</span><span class="n">P_theta_nu_byhist</span><span class="p">,</span>
             <span class="c1"># cmap=&#39;Blues_r&#39;</span>
             <span class="p">)</span>
    
    <span class="n">CLs</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.683</span><span class="p">,</span><span class="mf">0.90</span><span class="p">,</span><span class="mf">0.95</span><span class="p">])</span>
    
    <span class="c1">#To draw contours, the intensity (the p-value) must be 2D again</span>
    <span class="n">P_theta_nu_byhist_2d</span> <span class="o">=</span> <span class="n">P_theta_nu_byhist</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">THETA</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="c1">#for contours everything has to be 2d</span>
    <span class="n">contours</span><span class="o">=</span><span class="n">ax</span><span class="o">.</span><span class="n">contour</span><span class="p">(</span><span class="n">THETA</span><span class="p">,</span> <span class="n">NU</span><span class="p">,</span> <span class="n">P_theta_nu_byhist_2d</span><span class="p">,</span>
              <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">numin</span><span class="p">,</span><span class="n">numax</span><span class="p">),</span>
              <span class="n">levels</span><span class="o">=</span><span class="n">CLs</span><span class="p">)</span>
    
<span class="c1">#     #label the contours</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">clabel</span><span class="p">(</span><span class="n">contours</span><span class="p">,</span> <span class="n">contours</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span> <span class="n">inline</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">%4.2f</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\nu$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$p_\theta$-value by $\mathbf</span><span class="si">{h}</span><span class="s1">$: $N = </span><span class="si">%s</span><span class="s1">$ , $M  = </span><span class="si">%s</span><span class="s1">$, MLE = </span><span class="si">%s</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">N</span><span class="p">),</span><span class="nb">str</span><span class="p">(</span><span class="n">M</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">)),</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="c1">#add contour color bar</span>
    <span class="n">cbar</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">contours</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">save_plot</span> <span class="o">==</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">],</span> <span class="s1">&#39;images&#39;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;2D_Hist_thetamin_</span><span class="si">{</span><span class="n">thetamin</span><span class="si">}</span><span class="s2">_thetamax_</span><span class="si">{</span><span class="n">thetamax</span><span class="si">}</span><span class="s2">_numin_</span><span class="si">{</span><span class="n">numin</span><span class="si">}</span><span class="s2">_numax_</span><span class="si">{</span><span class="n">numax</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">figwidth_by_height_ratio</span><span class="o">=</span><span class="mf">1.33</span>
<span class="n">height</span><span class="o">=</span><span class="mi">6</span>
<span class="n">width</span><span class="o">=</span><span class="n">figwidth_by_height_ratio</span><span class="o">*</span><span class="n">height</span>
<span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span><span class="n">height</span><span class="p">),</span>
                     <span class="p">)</span>

<span class="n">plot_P_byhist</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
             <span class="n">save_plot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># plot_P_byhist(ax=ax[1], </span>
<span class="c1">#              Bprime=100000,</span>
<span class="c1">#               thetamin=0, thetamax=20,</span>
<span class="c1">#               numin=0, numax=20, </span>
<span class="c1">#                       N=8, M=2,</span>
<span class="c1">#                nbinstheta=100, nbinsnu=100,                    </span>
<span class="c1">#                       MLE=False)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_143_0.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_143_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span>
                      <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">width</span><span class="p">,</span><span class="n">height</span><span class="p">)</span>
                     <span class="p">)</span>

<span class="n">plot_P_byhist</span><span class="p">(</span><span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> 
             <span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
              <span class="n">numin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">numax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                      <span class="n">N</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
               <span class="n">nbinstheta</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">nbinsnu</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>                    
                      <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_144_0.png" src="_images/3_Replacing_Data_with_Lambda_and_2D_Inference_144_0.png" />
</div>
</div>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="id1">
<h1>ML<a class="headerlink" href="#id1" title="Permalink to this headline">#</a></h1>
<p>And the whole ML logic in estimating this and making inference in 2D applies:</p>
<section id="first-load-the-training-data-we-used-previously-in-notebook-2">
<h2>First load the training data we used previously (in notebook 2)<a class="headerlink" href="#first-load-the-training-data-we-used-previously-in-notebook-2" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; returns the dataframe, can be used if the dataframe is saved in csv format</span>
<span class="sd">    of if it is already in dataframe format (e.g. generated in this notebook). &quot;&quot;&quot;</span>
    <span class="c1"># SUBSAMPLE=int(1e5)</span>
    <span class="c1"># if isinstance(df_name,str):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span><span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">),</span> 
                         <span class="c1"># nrows=SUBSAMPLE,</span>
                         <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
            <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">,</span><span class="s1">&#39;two_parameters_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">),</span> 
                 <span class="c1"># nrows=SUBSAMPLE,</span>
                 <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_df</span>
</pre></div>
</div>
</div>
</div>
<p>In notebook 2, we trained the model on continuous <span class="math notranslate nohighlight">\(\theta, \nu\)</span> :</p>
<div class="math notranslate nohighlight">
\[ X_{train} = (\theta_{\text{continuous}}, \nu_{\text{continuous}}, \hat{\theta}_{fixed}, N_{fixed}, M_{fixed} ),\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>14.224636</td>
      <td>19.888336</td>
      <td>-6</td>
      <td>3</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>4.298885</td>
      <td>1.224232</td>
      <td>3</td>
      <td>4</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>16.724410</td>
      <td>11.147011</td>
      <td>1</td>
      <td>4</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0.399752</td>
      <td>11.743650</td>
      <td>2</td>
      <td>6</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>6.909235</td>
      <td>2.207732</td>
      <td>-3</td>
      <td>4</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_df_nonMLE</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>11.282337</td>
      <td>10.868814</td>
      <td>0</td>
      <td>3</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>14.088345</td>
      <td>7.463724</td>
      <td>7</td>
      <td>9</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>13.291443</td>
      <td>10.772238</td>
      <td>2</td>
      <td>4</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>19.687959</td>
      <td>6.578690</td>
      <td>4</td>
      <td>5</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>7.525728</td>
      <td>5.680840</td>
      <td>0</td>
      <td>1</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>where some models were trained on <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (obviously fixed since <span class="math notranslate nohighlight">\(N,M\)</span> are fixed and <span class="math notranslate nohighlight">\(\hat{\theta}=N-M\)</span>) and some were not trained on <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> (for science, which produced similar results - no difference on whether <span class="math notranslate nohighlight">\(\hat{\theat}\)</span> helps the NN train better ).</p>
<p>but since <span class="math notranslate nohighlight">\(L_{prof}\)</span> is only a function of <span class="math notranslate nohighlight">\(\theta\)</span> (<span class="math notranslate nohighlight">\(\nu\)</span> was profiled out), our hypothesis testing was only testing <span class="math notranslate nohighlight">\(\theta\)</span>; it was evaluated on the following:</p>
<div class="math notranslate nohighlight">
\[ X_{\text{eval}} = (\theta_{\text{continuous}}, \nu_{\text{fixed}}, \hat{\theta}_{fixed}, N_{fixed}, M_{fixed} )\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>
    <span class="c1">#if MLE true, load the model that was trained on MLE data and vice versa</span>
    <span class="c1"># N, M = D</span>
    <span class="c1"># nbins=NBINS</span>
    <span class="c1"># thetamin,thetamax=0,20</span>
    <span class="c1">#this is to make sure its taking theta values fron the range we trained it on</span>
    <span class="n">thetamin</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">thetamax</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">thetastep</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamax</span><span class="o">-</span><span class="n">thetamin</span><span class="p">)</span> <span class="o">/</span> <span class="n">nbins</span><span class="c1">#Delta theta (bin width)</span>
    <span class="n">bb</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">+</span><span class="n">thetastep</span><span class="p">,</span> <span class="n">thetastep</span><span class="p">)</span><span class="c1">#this is just making a vector of thetas</span>
    <span class="n">X</span>     <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span><span class="c1">#at the center</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span><span class="p">,</span> <span class="n">eval_bins_example</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                                     <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eval_data_example</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.0333,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.1667,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.2333,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.3000,  3.0000, -2.0000,  1.0000,  3.0000]])
</pre></div>
</div>
</div>
</div>
<p>To make inference on <span class="math notranslate nohighlight">\(\theta\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">getwholedata</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                    <span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">,</span> 
             <span class="c1"># nrows=SUBSAMPLE,</span>
             <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
            <span class="p">)</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>
    

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span><span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;M&#39;</span><span class="p">]</span>

    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>  <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_t shape = &#39;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_x shape = &#39;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">valid</span><span class="p">:</span>
        <span class="c1">#if you want to also make a validation data set</span>
        <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">valid_data</span> <span class="o">=</span> <span class="n">valid_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>

        
    <span class="k">return</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="2_Two_Parameter_Problem_and_Pivotal_p_Value.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">2 - Two-Parameter Problem and Pivotal Likelihood-Free p-Values</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="4_Mapping_Confidence_Sets_to_Confidence_Intervals.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">4 - Mapping Confidence Sets to Confidence Intervals</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ali Al Kadhim and Harrison Prosper<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>