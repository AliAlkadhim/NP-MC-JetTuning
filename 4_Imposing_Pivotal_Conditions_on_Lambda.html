
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Imposing Pivotal Conditions on \(\lambda\) &#8212; Pivotal Likelihood-Free Inference for Particle Physics</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5 - Mapping Confidence Sets to Confidence Intervals" href="5_Mapping_Confidence_Sets_to_Confidence_Intervals.html" />
    <link rel="prev" title="3 - Replacing Observed Data with Test Statistics and, 2-Dimensional Inference in \(\theta - \nu\) Space" href="3_Replacing_Data_with_Lambda_and_2D_Inference.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
      
      
      <h1 class="site-logo" id="site-title">Pivotal Likelihood-Free Inference for Particle Physics</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to the Likelihood-Free Inference for Particle Physics Jupyter book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="1_Intro_and_One_Parameter_Problem.html">
   1 - Pivotal LFI for Count Data in Particle Physics: Background and one-parameter Problem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_Two_Parameter_Problem_and_Pivotal_p_Value.html">
   2 - Two-Parameter Problem and Pivotal Likelihood-Free p-Values
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="3_Replacing_Data_with_Lambda_and_2D_Inference.html">
   3 - Replacing Observed Data with Test Statistics and, 2-Dimensional Inference in
   <span class="math notranslate nohighlight">
    \(\theta - \nu\)
   </span>
   Space
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Imposing Pivotal Conditions on
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="5_Mapping_Confidence_Sets_to_Confidence_Intervals.html">
   5 - Mapping Confidence Sets to Confidence Intervals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="6_More_Ideas.html">
   More Discussions
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AliAlkadhim/LFI_HEP/master?urlpath=tree/JupyterBook/4_Imposing_Pivotal_Conditions_on_Lambda.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/4_Imposing_Pivotal_Conditions_on_Lambda.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4. Imposing Pivotal Conditions on
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pivotal-likelihood-free-inference-for-count-data-in-particle-physics">
     Pivotal Likelihood-Free Inference for Count Data in Particle Physics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#external-imports">
       External imports
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#import-utils">
       import utils
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-the-previous-notebook-we-saw-how-we-can-construct-a-pivotal-model-mathbf-f-in-this-notebook-we-explore-the-possibility-of-constructing-a-pivotal-test-statistic-mathbf-lambda">
   In the previous notebook, we saw how we can construct a pivotal model
   <span class="math notranslate nohighlight">
    \(\mathbf{f}\)
   </span>
   . In this notebook, we explore the possibility of constructing a pivotal test statistic
   <span class="math notranslate nohighlight">
    \(\mathbf{\lambda}\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#observed-data">
     Observed Data:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters">
     Parameters:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auxiliary-simulated-data-simulated-on-the-fly-for-each-observation">
     Auxiliary (simulated) Data (simulated on-the-fly for each observation):
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#our-algorithm">
       Our Algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#our-3rd-algorithm-using-lambda-as-an-input-to-mathbf-f-as-opposed-to-n-m">
   Our 3rd algorithm: using
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
   as an input to
   <span class="math notranslate nohighlight">
    \(\mathbf{f}\)
   </span>
   as opposed to
   <span class="math notranslate nohighlight">
    \(\{N,M\}\)
   </span>
   .
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-training-data-or-take-a-look-at-the-saved-training-data">
     Generate Training data (or take a look at the saved training data)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ann-lee-s-algorithm">
   Ann Lee’s Algorithm
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-theta-i-nu-i-n-i-m-i-z-i-data-according-to">
     Generate
     <span class="math notranslate nohighlight">
      \(\{\theta_i, \nu_i, N_i, M_i, Z_i \}\)
     </span>
     data according to:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#write-custom-data-loader">
   Write Custom Data Loader
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#going-2d">
   Going 2D
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#in-theta-nu-space-of-course">
     (in
     <span class="math notranslate nohighlight">
      \((\theta, \nu)\)
     </span>
     space, of course)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-the-histogrammed-approximations-for-the-mle-vs-non-mle-cases-for-a-single-value-of-mathbf-nu">
     Plot the histogrammed approximations for the MLE vs non-MLE cases for a single value of
     <span class="math notranslate nohighlight">
      \(\mathbf{\nu}\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-the-histogrammed-approximation-mathbf-h-for-the-mle-vs-non-mle-cases-for-multiple-values-of-mathbf-nu-indicating-the-dependence-on-the-nuissance-parameter">
     Plot the histogrammed approximation
     <span class="math notranslate nohighlight">
      \(\mathbf{h}\)
     </span>
     , for the MLE vs non-MLE cases for multiple values of
     <span class="math notranslate nohighlight">
      \(\mathbf{\nu}\)
     </span>
     , indicating the dependence on the nuissance parameter
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml">
   ML
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-model-mathbf-f-which-will-approximate-the-expectation-value-above">
     Define Model
     <span class="math notranslate nohighlight">
      \(\mathbf{f}\)
     </span>
     , which will approximate the expectation value above
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#make-a-hyperparameter-tuning-workflow">
   Make a hyperparameter Tuning Workflow
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#don-t-run-the-one-cell-below-unless-you-want-to-tune">
     Don’t run the one cell below, unless you want to tune!
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dictionary-of-the-best-hyperparameters-that-was-saved-from-our-hyperparameter-tuning-workflow-and-retrieve-the-values">
   Load the dictionary of the best hyperparameters that was saved from our hyperparameter tuning workflow, and retrieve the values
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-network-node-shapes-parameters-and-training-data">
     Define network node shapes, parameters, and training data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initiate-model-based-on-choice-of-whose-model-ali-or-harrison-and-parameters">
     Initiate model based on choice of whose model (Ali or Harrison) and parameters
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#then-train">
       Then train
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-you-can-scroll-down-to-load-up-trained-model-instead-of-training-now">
   Training: You can scroll down to load up trained model instead of training now
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-mle-model">
     Train MLE model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-non-mle-model">
     Train non-MLE model
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#make-sure-the-train-df-has-the-same-ranges-as-the-data-you-want-to-generate-for-evaluation">
       Make sure the train df has the same ranges as the data you want to generate for evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#make-on-the-fly-generated-evaluation-data">
     Make “on-the-fly” generated evaluation data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#look-at-an-example-of-a-on-the-fly-generated-evaluation-data">
       Look at an example of a “on-the-fly” generated evaluation data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-evaluate-trained-model-at-generated-data">
   Load and Evaluate Trained model at generated data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-model-at-an-example-set-of-eval-data-points-to-see-the-predicted-p-value-hat-p">
   Evaluate model at an example set of “eval_data” points to see the predicted
   <span class="math notranslate nohighlight">
    \(p\)
   </span>
   -value (
   <span class="math notranslate nohighlight">
    \(\hat{p}\)
   </span>
   )
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-they-re-good-and-if-you-havent-saved-by-now">
     SAVE TRAINED MODEL (if they’re good, and if you havent saved by now)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#this-is-how-you-load-a-trained-model">
     This is how you load a trained model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-could-also-evaluate-the-trained-model-on-the-validation-data">
     You could also evaluate the trained model on the validation data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-to-pivot">
   Learning to Pivot
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-results-image-of-the-pivotal-model-so-far">
   Load the results image of the pivotal model (so far)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#we-want-another-2x2-grid-of-plots-below-this-as-another-figure-with-mathbf-tilde-lambda-vs-lambda-np">
   we want another 2X2 grid of plots below this (as another figure) with
   <span class="math notranslate nohighlight">
    \(\mathbf{\tilde{\lambda}}\)
   </span>
   vs
   <span class="math notranslate nohighlight">
    \(\lambda_{NP}\)
   </span>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explore-the-new-pivotal-models-and-save-if-good">
   Explore the new pivotal models and save if good
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-discussions">
   More Discussions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-ideas">
   More ideas
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>4. Imposing Pivotal Conditions on \lambda</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   4. Imposing Pivotal Conditions on
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pivotal-likelihood-free-inference-for-count-data-in-particle-physics">
     Pivotal Likelihood-Free Inference for Count Data in Particle Physics
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#external-imports">
       External imports
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#import-utils">
       import utils
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#in-the-previous-notebook-we-saw-how-we-can-construct-a-pivotal-model-mathbf-f-in-this-notebook-we-explore-the-possibility-of-constructing-a-pivotal-test-statistic-mathbf-lambda">
   In the previous notebook, we saw how we can construct a pivotal model
   <span class="math notranslate nohighlight">
    \(\mathbf{f}\)
   </span>
   . In this notebook, we explore the possibility of constructing a pivotal test statistic
   <span class="math notranslate nohighlight">
    \(\mathbf{\lambda}\)
   </span>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#observed-data">
     Observed Data:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parameters">
     Parameters:
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#auxiliary-simulated-data-simulated-on-the-fly-for-each-observation">
     Auxiliary (simulated) Data (simulated on-the-fly for each observation):
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#our-algorithm">
       Our Algorithm
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#our-3rd-algorithm-using-lambda-as-an-input-to-mathbf-f-as-opposed-to-n-m">
   Our 3rd algorithm: using
   <span class="math notranslate nohighlight">
    \(\lambda\)
   </span>
   as an input to
   <span class="math notranslate nohighlight">
    \(\mathbf{f}\)
   </span>
   as opposed to
   <span class="math notranslate nohighlight">
    \(\{N,M\}\)
   </span>
   .
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-training-data-or-take-a-look-at-the-saved-training-data">
     Generate Training data (or take a look at the saved training data)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ann-lee-s-algorithm">
   Ann Lee’s Algorithm
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#generate-theta-i-nu-i-n-i-m-i-z-i-data-according-to">
     Generate
     <span class="math notranslate nohighlight">
      \(\{\theta_i, \nu_i, N_i, M_i, Z_i \}\)
     </span>
     data according to:
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#write-custom-data-loader">
   Write Custom Data Loader
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#going-2d">
   Going 2D
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#in-theta-nu-space-of-course">
     (in
     <span class="math notranslate nohighlight">
      \((\theta, \nu)\)
     </span>
     space, of course)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-the-histogrammed-approximations-for-the-mle-vs-non-mle-cases-for-a-single-value-of-mathbf-nu">
     Plot the histogrammed approximations for the MLE vs non-MLE cases for a single value of
     <span class="math notranslate nohighlight">
      \(\mathbf{\nu}\)
     </span>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#plot-the-histogrammed-approximation-mathbf-h-for-the-mle-vs-non-mle-cases-for-multiple-values-of-mathbf-nu-indicating-the-dependence-on-the-nuissance-parameter">
     Plot the histogrammed approximation
     <span class="math notranslate nohighlight">
      \(\mathbf{h}\)
     </span>
     , for the MLE vs non-MLE cases for multiple values of
     <span class="math notranslate nohighlight">
      \(\mathbf{\nu}\)
     </span>
     , indicating the dependence on the nuissance parameter
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ml">
   ML
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-model-mathbf-f-which-will-approximate-the-expectation-value-above">
     Define Model
     <span class="math notranslate nohighlight">
      \(\mathbf{f}\)
     </span>
     , which will approximate the expectation value above
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#make-a-hyperparameter-tuning-workflow">
   Make a hyperparameter Tuning Workflow
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#don-t-run-the-one-cell-below-unless-you-want-to-tune">
     Don’t run the one cell below, unless you want to tune!
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-dictionary-of-the-best-hyperparameters-that-was-saved-from-our-hyperparameter-tuning-workflow-and-retrieve-the-values">
   Load the dictionary of the best hyperparameters that was saved from our hyperparameter tuning workflow, and retrieve the values
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#define-network-node-shapes-parameters-and-training-data">
     Define network node shapes, parameters, and training data
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#initiate-model-based-on-choice-of-whose-model-ali-or-harrison-and-parameters">
     Initiate model based on choice of whose model (Ali or Harrison) and parameters
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#then-train">
       Then train
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-you-can-scroll-down-to-load-up-trained-model-instead-of-training-now">
   Training: You can scroll down to load up trained model instead of training now
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-mle-model">
     Train MLE model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#train-non-mle-model">
     Train non-MLE model
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#make-sure-the-train-df-has-the-same-ranges-as-the-data-you-want-to-generate-for-evaluation">
       Make sure the train df has the same ranges as the data you want to generate for evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#make-on-the-fly-generated-evaluation-data">
     Make “on-the-fly” generated evaluation data
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#look-at-an-example-of-a-on-the-fly-generated-evaluation-data">
       Look at an example of a “on-the-fly” generated evaluation data
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-and-evaluate-trained-model-at-generated-data">
   Load and Evaluate Trained model at generated data
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluate-model-at-an-example-set-of-eval-data-points-to-see-the-predicted-p-value-hat-p">
   Evaluate model at an example set of “eval_data” points to see the predicted
   <span class="math notranslate nohighlight">
    \(p\)
   </span>
   -value (
   <span class="math notranslate nohighlight">
    \(\hat{p}\)
   </span>
   )
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#save-trained-model-if-they-re-good-and-if-you-havent-saved-by-now">
     SAVE TRAINED MODEL (if they’re good, and if you havent saved by now)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#this-is-how-you-load-a-trained-model">
     This is how you load a trained model
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#you-could-also-evaluate-the-trained-model-on-the-validation-data">
     You could also evaluate the trained model on the validation data
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#learning-to-pivot">
   Learning to Pivot
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#load-the-results-image-of-the-pivotal-model-so-far">
   Load the results image of the pivotal model (so far)
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#we-want-another-2x2-grid-of-plots-below-this-as-another-figure-with-mathbf-tilde-lambda-vs-lambda-np">
   we want another 2X2 grid of plots below this (as another figure) with
   <span class="math notranslate nohighlight">
    \(\mathbf{\tilde{\lambda}}\)
   </span>
   vs
   <span class="math notranslate nohighlight">
    \(\lambda_{NP}\)
   </span>
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#explore-the-new-pivotal-models-and-save-if-good">
   Explore the new pivotal models and save if good
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-discussions">
   More Discussions
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#more-ideas">
   More ideas
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="imposing-pivotal-conditions-on-lambda">
<h1>4. Imposing Pivotal Conditions on <span class="math notranslate nohighlight">\(\lambda\)</span><a class="headerlink" href="#imposing-pivotal-conditions-on-lambda" title="Permalink to this headline">#</a></h1>
<section id="pivotal-likelihood-free-inference-for-count-data-in-particle-physics">
<h2>Pivotal Likelihood-Free Inference for Count Data in Particle Physics<a class="headerlink" href="#pivotal-likelihood-free-inference-for-count-data-in-particle-physics" title="Permalink to this headline">#</a></h2>
<p>Ali Al Kadhim and Harrison B. Prosper <br>
Department of Physics, Florida State University <br></p>
<section id="external-imports">
<h3>External imports<a class="headerlink" href="#external-imports" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1">#use numba&#39;s just-in-time compiler to speed things up</span>
<span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span><span class="p">;</span> <span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mp</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span><span class="p">;</span> 
<span class="c1">#reset matplotlib stle/parameters</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="nn">mpl</span>
<span class="n">mpl</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">mpl</span><span class="o">.</span><span class="n">rcParamsDefault</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-deep&#39;</span><span class="p">)</span>
<span class="n">mp</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;agg.path.chunksize&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10000</span>
<span class="n">font_legend</span> <span class="o">=</span> <span class="mi">15</span><span class="p">;</span> <span class="n">font_axes</span><span class="o">=</span><span class="mi">15</span>
<span class="c1"># %matplotlib inline</span>
<span class="kn">import</span> <span class="nn">copy</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">sys</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">display</span>
<span class="kn">from</span> <span class="nn">importlib</span> <span class="kn">import</span> <span class="n">import_module</span>

<span class="k">try</span><span class="p">:</span>
    <span class="kn">import</span> <span class="nn">optuna</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;optuna is only used for hyperparameter tuning, not critical!&#39;</span><span class="p">)</span>
    <span class="k">pass</span>
<span class="c1"># import sympy as sy</span>
<span class="c1">#sometimes jupyter doesnt initialize MathJax automatically for latex, so do this</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">wid</span><span class="p">;</span> <span class="n">wid</span><span class="o">.</span><span class="n">HTMLMath</span><span class="p">(</span><span class="s1">&#39;$\LaTeX$&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "620c0e78ed704d60ba57da5461cae5fb", "version_major": 2, "version_minor": 0}
</script></div>
</div>
</section>
<section id="import-utils">
<h3>import utils<a class="headerlink" href="#import-utils" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">LFI_PIVOT_BASE</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;LFI_PIVOT_BASE&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;BASE directoy properly set = &#39;</span><span class="p">,</span> <span class="n">LFI_PIVOT_BASE</span><span class="p">)</span>
    <span class="n">utils_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">LFI_PIVOT_BASE</span><span class="p">,</span> <span class="s1">&#39;utils&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">utils_dir</span><span class="p">)</span>
    <span class="kn">import</span> <span class="nn">utils</span>
    <span class="c1">#usually its not recommended to import everything from a module, but we know</span>
    <span class="c1">#whats in it so its fine</span>
    <span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;&quot;&quot;BASE directory not properly set. Read repo README.</span><span class="se">\</span>
<span class="s2">    If you need a function from utils, use the decorator below, or add utils to sys.path&quot;&quot;&quot;</span><span class="p">)</span>
    <span class="k">pass</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>BASE directoy properly set =  /home/ali/Desktop/Pulled_Github_Repositories/LFI_HEP
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="in-the-previous-notebook-we-saw-how-we-can-construct-a-pivotal-model-mathbf-f-in-this-notebook-we-explore-the-possibility-of-constructing-a-pivotal-test-statistic-mathbf-lambda">
<h1>In the previous notebook, we saw how we can construct a pivotal model <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>. In this notebook, we explore the possibility of constructing a pivotal test statistic <span class="math notranslate nohighlight">\(\mathbf{\lambda}\)</span><a class="headerlink" href="#in-the-previous-notebook-we-saw-how-we-can-construct-a-pivotal-model-mathbf-f-in-this-notebook-we-explore-the-possibility-of-constructing-a-pivotal-test-statistic-mathbf-lambda" title="Permalink to this headline">#</a></h1>
<section id="observed-data">
<h2>Observed Data:<a class="headerlink" href="#observed-data" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N\)</span> (observed counts for signal)</p></li>
<li><p><span class="math notranslate nohighlight">\(M\)</span> (observed counts for background)</p></li>
</ul>
</section>
<section id="parameters">
<h2>Parameters:<a class="headerlink" href="#parameters" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\theta\)</span>: parameter of interest, proportional to <span class="math notranslate nohighlight">\(\sigma\)</span> in HEP (unknown signal mean)</p></li>
<li><p><span class="math notranslate nohighlight">\(\nu\)</span>: nuissance parameter (unknown background mean)</p></li>
</ul>
</section>
<section id="auxiliary-simulated-data-simulated-on-the-fly-for-each-observation">
<h2>Auxiliary (simulated) Data (simulated on-the-fly for each observation):<a class="headerlink" href="#auxiliary-simulated-data-simulated-on-the-fly-for-each-observation" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(n\)</span>: expected signal count</p></li>
<li><p><span class="math notranslate nohighlight">\(m\)</span>: expected backround count</p></li>
</ul>
<p>The standard procedure for removal of nuissance parameters, as discussed above is Bayesian marginalization or Frequentist profiling, but in this study we adopt LFI with robust frequentest critical value estimation.</p>
<p>We generate data comprising the quadruplets <span class="math notranslate nohighlight">\(\{\theta_i, \nu_i, N_i, M_i, Z_i \}\)</span> where</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\theta &amp; \sim \textrm{uniform}(0, 20), \\
\nu &amp; \sim \textrm{uniform}(0, 20), \\
\end{align}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
n &amp; \sim \textrm{poisson}(\theta + \nu),\\
m &amp; \sim \textrm{poisson}(\nu),\\
\end{align}
\right\} \rightarrow \lambda_\text{gen}(n, m \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
N &amp; \sim \textrm{uniform}(0,10),\\
M &amp; \sim \textrm{uniform}(0, 10), \\
\end{align}
\right\} \rightarrow \lambda_D(N, M \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
Z  = \mathbb{I}
\left[ \lambda_\text{gen}(n, m \mid \theta,\nu) \leq \lambda_D(N, M \mid \theta,\nu) \right],
\]</div>
<p>where the size of each of these samples is <span class="math notranslate nohighlight">\(B'\)</span>, <span class="math notranslate nohighlight">\(\mathbb{I}\)</span> is the indicator function,
and <span class="math notranslate nohighlight">\(\lambda_{\text{NP}}\)</span> is the Neyman-Pearson test statistic, our chosen test statistic (NP could also stand, if you like, for “New Physics” or “Not Pivotal”!)</p>
<div class="math notranslate nohighlight">
\[ \lambda_{\text{NP}} \equiv - 2 \log{\frac{p(n,m|\theta, \hat{\nu}(\theta) )}{ p(n,m|\hat{\theta}, \hat{\nu}(\theta) )}} = -2 \log \frac{L_{\text{prof}} \big(\theta, \hat{\nu}(\theta) \big) }{L_{\text{prof}} \big( \hat{\theta}, \hat{\nu}(\theta) \big)}, \tag{1}\]</div>
<p>where <span class="math notranslate nohighlight">\(L_{\text{prof}} \big( n, m, \theta, \hat{\nu}(\theta) \big)\)</span> is the profiled likelihood - that is - the likelihood function when the nuissance parameters are replaced by their maximum likelihood estimates (MLE) for a given value of the parameter of interest.</p>
<p>The goal is to model the distribution of <span class="math notranslate nohighlight">\(\lambda\)</span>, and when <span class="math notranslate nohighlight">\(\hat{\theta}=\hat{\theta}_{\text{MLE}}\)</span>, i.e.</p>
<div class="math notranslate nohighlight">
\[\lambda^{\text{(MLE)}}_{\text{NP}} \equiv -2 \log \frac{L_{\text{prof}} \big(\theta, \hat{\nu}(\theta) \big) }{L_{\text{prof}} \big( \hat{\theta}_{\text{MLE}}, \hat{\nu}(\theta) \big)},\]</div>
<p>we have a nice functional form for <span class="math notranslate nohighlight">\(\lambda\)</span>, where The MLE of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is given by</p>
<div class="math notranslate nohighlight">
\[\hat{\theta}^{\text{(MLE)}}=n-m.\]</div>
<p>Low-count data can sometimes yield spurious results, where the MLE of a parameter of interest <span class="math notranslate nohighlight">\(\theta\)</span>, could yield a negative result. In the case that <span class="math notranslate nohighlight">\(\theta\)</span> is the cross section, yielding a negative result is non-physical, which leads to the ad-hoc fix: taking ignoring the MLE solution and taking <span class="math notranslate nohighlight">\(\hat{\theta}=0\)</span> when <span class="math notranslate nohighlight">\(n&lt;m\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\hat{\theta}^{\text{(non-MLE)}} =\left\{
\begin{array}{ll}
    n-m &amp; \quad  n&gt;m \\
    0 &amp; \quad n \le m
\end{array}
\right.
\end{split}\]</div>
<p>The MLE <span class="math notranslate nohighlight">\(\hat{\nu}(\theta)\)</span> is attained by solving <span class="math notranslate nohighlight">\(\frac{\partial \log{p(n,m|\theta,\nu)}}{ \partial \nu} =0\)</span>, leading to</p>
<div class="math notranslate nohighlight">
\[\log{p(n,m|\theta,\nu)} = -(\theta+\nu)+n\log{(\theta+\nu)|-\nu+m\log{\nu}} + \text{constants}\]</div>
<div class="math notranslate nohighlight">
\[\hat{\nu}(\theta)=\left(g+\sqrt{g^2 + 8 m \theta} \right)/4,\]</div>
<p>where <span class="math notranslate nohighlight">\(g \equiv n+m-2 \theta\)</span>.</p>
<p>The procedure can be summarized by the following algorithm:</p>
<section id="our-algorithm">
<h3>Our Algorithm<a class="headerlink" href="#our-algorithm" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">our_algorithm</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/NMLambda_algorithm.png&#39;</span><span class="p">);</span> <span class="n">display</span><span class="p">(</span><span class="n">our_algorithm</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_9_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_9_0.png" />
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="our-3rd-algorithm-using-lambda-as-an-input-to-mathbf-f-as-opposed-to-n-m">
<h1>Our 3rd algorithm: using <span class="math notranslate nohighlight">\(\lambda\)</span> as an input to <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> as opposed to <span class="math notranslate nohighlight">\(\{N,M\}\)</span>.<a class="headerlink" href="#our-3rd-algorithm-using-lambda-as-an-input-to-mathbf-f-as-opposed-to-n-m" title="Permalink to this headline">#</a></h1>
<p>The test statistic in Eq. <span class="math notranslate nohighlight">\((1)\)</span> is used due to its well-known behavior of it converging to ti a <span class="math notranslate nohighlight">\(\chi^2_k\)</span> variate with <span class="math notranslate nohighlight">\(k\)</span> degrees of freedom, according to Wilk’s Theorem, where <span class="math notranslate nohighlight">\(k\)</span> is the number of free parameters (parameters of interest after the nuissance parameters have been replaecd by their MLEs).</p>
<p>Clearly, our choice of using the test statistic above is motivated by the <a class="reference external" href="https://royalsocietypublishing.org/doi/epdf/10.1098/rsta.1933.0009">Neyman-Pearson Lemma</a> Instead of using different statistics for LFI as in the <a class="reference external" href="https://arxiv.org/pdf/2107.03920.pdf">Ann Lee paper</a>, we use this one since in Ann lee’s paper, for example the ACORE statistic <span class="math notranslate nohighlight">\(\Lambda\left(\mathcal{D} ; \Theta_{0}\right):=\log \frac{\sup _{\theta_{0} \in \Theta_{0}} \prod_{i=1}^{n} \mathbb{O}\left(\mathbf{X}_{i}^{\text {obs }} ; \theta_{0}\right)}{\sup _{\theta \in \Theta} \prod_{i=1}^{n} \mathbb{O}\left(\mathbf{X}_{i}^{\text {obs }} ; \theta\right)}\)</span>, since the odds <span class="math notranslate nohighlight">\(\mathbb{O}\left(\mathbf{X}_{i}^{\text {obs }}\right) \)</span>, are merely estimates of the likelihood, and not the likelihood itselt, therefore Wilk’s theorem is not guaranteed to work, even if we have a large sample size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">mkdir</span><span class="p">(</span><span class="n">dir_</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;make a directory without overwriting what&#39;s in it if it exists&quot;&quot;&quot;</span>
    <span class="c1"># assert isinstance(dir_, str)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">os</span><span class="o">.</span><span class="n">system</span><span class="p">(</span><span class="s1">&#39;mkdir -p </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">dir_</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span><span class="p">:</span>
        <span class="k">pass</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mkdir</span><span class="p">(</span><span class="s1">&#39;utils&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %writefile &#39;src/utils.py&#39;</span>

<span class="k">def</span> <span class="nf">import_base_stack</span><span class="p">():</span>
    <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span><span class="p">;</span> <span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
    <span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span><span class="p">;</span> <span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">njit</span>

<span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">DR</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammainc</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>

<span class="nd">@njit</span>
<span class="k">def</span> <span class="nf">DL</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">theta</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">sp</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">gammainc</span><span class="p">(</span><span class="n">s</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">theta</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">L_prof</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">theta</span><span class="p">):</span>
    <span class="n">k</span><span class="o">=</span><span class="mi">1</span>
    <span class="n">k1</span> <span class="o">=</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span>
    <span class="n">k2</span> <span class="o">=</span> <span class="mf">0.5</span><span class="o">/</span><span class="n">k1</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">n</span><span class="o">+</span><span class="n">m</span> <span class="o">-</span> <span class="n">k1</span><span class="o">*</span><span class="n">theta</span>
    <span class="n">nu_hat</span> <span class="o">=</span> <span class="n">k2</span><span class="o">*</span> <span class="p">(</span><span class="n">g</span><span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">g</span><span class="o">*</span><span class="n">g</span> <span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">k1</span><span class="o">*</span><span class="n">m</span><span class="o">*</span><span class="n">theta</span><span class="p">))</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">theta</span> <span class="o">+</span> <span class="n">nu_hat</span><span class="p">)</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">pmf</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">mu</span> <span class="o">=</span> <span class="n">k</span> <span class="o">*</span> <span class="n">nu_hat</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">p1</span><span class="o">*</span><span class="n">p2</span>


<span class="k">def</span> <span class="nf">theta_hat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">n</span><span class="o">-</span><span class="n">m</span>
    
    <span class="k">if</span> <span class="ow">not</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">theta_hat</span> <span class="o">=</span> <span class="n">theta_hat</span> <span class="o">*</span> <span class="p">(</span><span class="n">theta_hat</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">theta_hat</span>

<span class="c1"># @njit</span>
<span class="k">def</span> <span class="nf">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">Ln</span> <span class="o">=</span> <span class="n">L_prof</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span><span class="n">theta</span><span class="p">)</span>
    <span class="n">Ld</span> <span class="o">=</span> <span class="n">L_prof</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span><span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="p">))</span>
    <span class="n">lambda_</span>  <span class="o">=</span> <span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Ln</span><span class="o">/</span><span class="n">Ld</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">lambda_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Prior to reporting the results of our method, we validate that our method by comparing it to the well-known results of Wilk’s Theorem. That is, the test statistic <span class="math notranslate nohighlight">\(\lambda(\theta, n, m , \nu(\theta))\)</span> should be distributed as a <span class="math notranslate nohighlight">\(\chi^2_1\)</span> (a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution with a number of degrees of freedom equal to the number of free parameters left in our problem).</p>
<p>We test this theorem with our algorithm, but stopping at step 9. We then histogram the comulative distribution function (CDF) of <span class="math notranslate nohighlight">\(\lambda(\theta)\)</span> for a given (fixed) <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\nu\)</span>, and compare it to the analystical CDF of a <span class="math notranslate nohighlight">\(\chi^2_1\)</span> distribtion. The figure (below) shows that the results of our test statistic does indeed agree with what we expect from Wilk’s Theorem.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chi2_exp_size</span><span class="o">=</span><span class="mi">40000</span>

<span class="k">def</span> <span class="nf">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Sample n ~ Pois(theta+nu), </span>
<span class="sd">              m ~ Pois(nu), </span>
<span class="sd">    and compute </span>
<span class="sd">              lambda(theta, n, m)</span>
<span class="sd">              </span>
<span class="sd">    return: (n, m, lambda_), where each are np arrays of length lambda_size</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">run_sims</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Run an entire simulation, that is, generate n and m from </span>
<span class="sd">    run_sim above, and calculate lambda, for</span>
<span class="sd">    </span>
<span class="sd">    input: a tuple of (theta, nu) scalars</span>
<span class="sd">    </span>
<span class="sd">    Reurns:df, lambda_results</span>
<span class="sd">    </span>
<span class="sd">    where lambda_results is a list of tuples </span>
<span class="sd">        (n, m, lambda_, theta, nu)</span>
<span class="sd">    and df is just a dataframe of [n,m,lambda,theta,nu]</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">lambda_results</span><span class="o">=</span><span class="p">[]</span>
    <span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">p</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">theta</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">nu</span>
        <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span> <span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;n&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">m</span>
        <span class="n">df</span><span class="p">[</span><span class="s1">&#39;lambda&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">lambda_</span>
        <span class="n">lambda_results</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">))</span>
    
        <span class="nb">print</span><span class="p">(</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> (theta, nu) =  (%.f, %.f) </span><span class="se">\n</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">)</span> <span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> with associated n =  </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1">, </span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> m = </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s1">, </span><span class="se">\n</span><span class="s1"> </span><span class="se">\n</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> </span><span class="se">\t</span><span class="s1"> lambda = </span><span class="si">{</span><span class="n">lambda_</span><span class="si">}</span><span class="s1">&#39;</span>  <span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span><span class="p">,</span> <span class="n">lambda_results</span>

<span class="k">def</span> <span class="nf">plot_one</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Histogram the CDF of  lambda_t = -2log(Lp(theta)/Lp(theta_hat)), </span>
<span class="sd">    for a given (fixed) theta and nu.</span>
<span class="sd">    Also, plot the actual CDF of a chi^2 distribution with 1 free parameter </span>
<span class="sd">    (since only theta is left after we profile nu) &quot;&quot;&quot;</span>
    <span class="n">ftsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
    <span class="n">ymin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ymax</span><span class="o">=</span> <span class="mi">1</span>
    <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
    <span class="n">y_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">);</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\lambda_</span><span class="si">{NP}</span><span class="s1"> \left(\theta,\hat{\nu}(\theta) \mid n, m \right)$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;cdf$(\lambda_</span><span class="si">{NP}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="c1">##########HISTOGRAM CDF OF LAMBDA####################</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="o">*</span><span class="n">xmax</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span>
    <span class="n">color</span><span class="o">=</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">),</span>
    <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$(\lambda)$&#39;</span><span class="p">)</span>
    <span class="c1">############################################################</span>
    <span class="c1">########### HISTOGRAM CDF OF THE CHI2 OF OF X WITH 1 DOF</span>
    <span class="c1">#x is not theta, that&#39;s the whole point of Wilks thm, x is an arbitrary RV</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$(\chi^2_1)$&#39;</span><span class="p">)</span>
    <span class="c1"># annotate</span>
    <span class="n">xwid</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span><span class="o">-</span><span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
    <span class="n">ywid</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
    <span class="n">xpos</span> <span class="o">=</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">xwid</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">ypos</span> <span class="o">=</span> <span class="n">ymin</span> <span class="o">+</span> <span class="n">ywid</span><span class="o">*</span><span class="mi">2</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="n">xpos</span><span class="p">,</span> <span class="n">ypos</span><span class="p">,</span>
    <span class="sa">r</span><span class="s1">&#39;$ \theta = </span><span class="si">%d</span><span class="s1">, \nu = </span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">),</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ol class="simple">
<li><p>Generate one scalar <span class="math notranslate nohighlight">\(\theta\)</span> and one scalar <span class="math notranslate nohighlight">\(\nu\)</span></p></li>
<li><p>Generate <span class="math notranslate nohighlight">\(\lambda(\theta,\nu)\)</span> of size <span class="math notranslate nohighlight">\(N\)</span>. Observe that the distribution of this <span class="math notranslate nohighlight">\(\lambda\)</span> will approach the CDF of a <span class="math notranslate nohighlight">\(\chi^2_{dof}(x)\)</span> of an RV of one dof (since <span class="math notranslate nohighlight">\(\theta\)</span> is the only free parameter left), confirming Wilk’s theorem</p></li>
<li><p>Observe that this test statistc will be dependent on the value of <span class="math notranslate nohighlight">\(\nu\)</span> in the non-MLE case, which is not desirable since we want to be insensetive to nuissance parameters for maximal statistal power</p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#points=(theta,nu)</span>
<span class="n">points_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">points_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">points_3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">MLE</span><span class="o">=</span><span class="kc">True</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="p">,</span> <span class="n">lambda_1</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">points_1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">points_1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="p">,</span> <span class="n">lambda_2</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">points_2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">points_2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="p">,</span> <span class="n">lambda_3</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">points_3</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">points_3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plot_one</span><span class="p">(</span><span class="n">lambda_1</span><span class="p">,</span> <span class="n">points_1</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">points_1</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_one</span><span class="p">(</span><span class="n">lambda_2</span><span class="p">,</span> <span class="n">points_2</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">points_2</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_one</span><span class="p">(</span><span class="n">lambda_3</span><span class="p">,</span> <span class="n">points_3</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">points_3</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">fig</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\lambda \rightarrow \chi^2_1$; MLE=</span><span class="si">%s</span><span class="s1">; $N_</span><span class="si">{sample}</span><span class="s1">$=</span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> \
             <span class="p">(</span>  <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">chi2_exp_size</span><span class="p">))),</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">SAVE</span><span class="o">=</span><span class="kc">False</span>
<span class="k">if</span> <span class="n">SAVE</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/Wilk_agreement_MLE_</span><span class="si">%s</span><span class="s1">_N_</span><span class="si">%s</span><span class="s1">.png&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">chi2_exp_size</span><span class="p">)</span> <span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_18_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_18_0.png" />
</div>
</div>
<p>Also, higher values of <span class="math notranslate nohighlight">\(\lambda\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">observe_test_statistic_pivotality</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">lambda_size</span><span class="p">,</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Histogram the CDF of  lambda_t = -2log(Lp(theta)/Lp(theta_hat)), </span>
<span class="sd">    for a given (fixed) theta and nu.</span>
<span class="sd">    Also, plot the actual CDF of a chi^2 distribution with 1 free parameter </span>
<span class="sd">    (since only theta is left after we profile nu) &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">title_size</span><span class="o">=</span><span class="mi">15</span>
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">lambda_MLE</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>


        <span class="n">ftsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
        <span class="n">ymin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ymax</span><span class="o">=</span> <span class="mi">1</span>
        <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">y_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_MLE</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="o">*</span><span class="n">xmax</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span>
        <span class="c1"># color=(0.8,0.8,0.9),</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$\left(\lambda_</span><span class="si">{NP}</span><span class="s1">(\theta=</span><span class="si">%s</span><span class="s1">,\nu=</span><span class="si">%s</span><span class="s1"> ) \right)$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="p">)</span>
        
        <span class="c1">############################################################</span>
        <span class="c1">########### HISTOGRAM CDF OF THE CHI2 OF OF X WITH 1 DOF</span>
        <span class="c1">#x is not theta, that&#39;s the whole point of Wilks thm, x is an arbitrary RV</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                   <span class="c1"># color=&#39;blue&#39;,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$ \left(\chi^2_1(\theta=</span><span class="si">%s</span><span class="s1">) \right)$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MLE=True&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">title_size</span><span class="p">)</span>
        <span class="c1">#####################Do the same for non-MLE</span>
        
            
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">lambda_nonMLE</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>


        <span class="n">ftsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
        <span class="n">ymin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ymax</span><span class="o">=</span> <span class="mi">1</span>
        <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">y_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_nonMLE</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="o">*</span><span class="n">xmax</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span>
        <span class="c1"># color=(0.8,0.8,0.9),</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$\left(\lambda_</span><span class="si">{NP}</span><span class="s1">(\theta=</span><span class="si">%s</span><span class="s1">,\nu=</span><span class="si">%s</span><span class="s1"> ) \right)$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="p">)</span>
        
        <span class="c1">############################################################</span>
        <span class="c1">########### HISTOGRAM CDF OF THE CHI2 OF OF X WITH 1 DOF</span>
        <span class="c1">#x is not theta, that&#39;s the whole point of Wilks thm, x is an arbitrary RV</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                   <span class="c1"># color=&#39;blue&#39;,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$ \left(\chi^2_1(\theta=</span><span class="si">%s</span><span class="s1">) \right)$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MLE=False&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">title_size</span><span class="p">)</span>
        
        <span class="c1"># annotate</span>
        <span class="n">xwid</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span><span class="o">-</span><span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
        <span class="n">ywid</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
        <span class="n">xpos</span> <span class="o">=</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">xwid</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ypos</span> <span class="o">=</span> <span class="n">ymin</span> <span class="o">+</span> <span class="n">ywid</span><span class="o">*</span><span class="mi">2</span>
        
        
        
        
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\lambda_</span><span class="si">{NP}</span><span class="s1"> \left(\theta,\hat{\nu}(\theta) \mid n, m \right)$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;cdf$(\lambda_</span><span class="si">{NP}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">x_range</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">y_range</span><span class="p">)</span>
        
        
    <span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/lambda_NP_observe_pivotality.png&#39;</span><span class="p">)</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observe_test_statistic_pivotality</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="p">],</span> <span class="n">lambda_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div>
</div>
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_21_1.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_21_1.png" />
</div>
</div>
<p>We clearly see that <span class="math notranslate nohighlight">\(\lambda_{NP}\)</span> is not pivotal, i.e. its distribution is dependent on the nuissance parameter <span class="math notranslate nohighlight">\(\nu\)</span>, which reflects loss of information about <span class="math notranslate nohighlight">\(\theta\)</span>. We also see that <span class="math notranslate nohighlight">\(\chi^2_1\)</span> is in fact a pivotal quantity, since it takes the exact same distribution for any given value of <span class="math notranslate nohighlight">\(\nu\)</span>.</p>
<p>As shall be discussed later in this notebook, one way of calculating <span class="math notranslate nohighlight">\(p\)</span>-value for <span class="math notranslate nohighlight">\(\theta\)</span> corresponding to an observed <span class="math notranslate nohighlight">\(\{N,M\}\)</span> pair (which will still be dependent on <span class="math notranslate nohighlight">\(\nu\)</span>) is by calculating the test statistic at the <span class="math notranslate nohighlight">\(\{N,M\}\)</span> pair and calculating
$$</p>
<div class="amsmath math notranslate nohighlight" id="equation-b8a4218f-701c-42f0-ad9d-eba3e8ddfe3f">
<span class="eqno">(10)<a class="headerlink" href="#equation-b8a4218f-701c-42f0-ad9d-eba3e8ddfe3f" title="Permalink to this equation">#</a></span>\[\begin{align}
p_\theta (\nu) &amp;=\int_{\lambda_D}^\infty f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid H_{null} = \{\theta,\nu \} \big) \ d \lambda_{gen} \\
 &amp;= 1- \text{Prob} \big(\lambda_{gen}(n,m;\theta,\nu) \le \lambda_D(N,M;\theta,\nu) \big), \tag{2}
\end{align}\]</div>
<div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}where $f$ is the PDF of $\lambda$. We see from above that the statistic $\lambda$ is an approximate sampling distribution of the $\chi^2$ PDF, proving [Wilk's theorem](https://www.jstor.org/stable/2957648?seq=1#metadata_info_tab_contents), and hence the $p$-value could also be caluclated by\\
$$p_\theta (\nu)=\int_{\chi^2}^\infty f(z; k) dz\end{aligned}\end{align} \]</div>
<p>where <span class="math notranslate nohighlight">\(k\)</span> is the number of degrees of freedom (free parameters) which is 1 in the 2-parameter problem , and <span class="math notranslate nohighlight">\(f(z;k)\)</span> is the <span class="math notranslate nohighlight">\(\chi^2\)</span> PDF. This p-value can then easily be computed (e.g. yielding <span class="math notranslate nohighlight">\(p=1-\alpha ( 1- F_{\chi^2} [\theta, \nu])\)</span>, where <span class="math notranslate nohighlight">\( F_{\chi^2}\)</span> is the comulative <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution function (as a function of <span class="math notranslate nohighlight">\(\theta\)</span> and <span class="math notranslate nohighlight">\(\nu\)</span>).</p>
<p>Please note that the test statistic, even for count data in particle physics, can take a different form, depending on what hypothesis one is trying to test. For more on this see <a class="reference external" href="https://arxiv.org/pdf/1007.1727.pdf">Asymptotic formulae for likelihood-based tests of new physics</a>.</p>
<p>We will be esitmaing this <span class="math notranslate nohighlight">\(p\)</span>-value with our LFI framework. If <span class="math notranslate nohighlight">\(\lambda=\lambda_{MLE}\)</span>, then according to Eq (2) the p-value is given by:</p>
<div class="math notranslate nohighlight">
\[
p^{\text{MLE}}_\theta (\nu) = 1- \text{Prob} \left( - 2 \log \frac{L_{\text{prof}} \big(n, m, \theta, \hat{\nu}(\theta) \big) }{L_{\text{prof}} \big( n, m, \hat{\theta}_{\text{MLE}}, \hat{\nu}(\theta) \big)} \le 
- 2 \log \frac{L_{\text{prof}} \big(N, M, \theta, \hat{\nu}(\theta) \big) }{L_{\text{prof}} \big( N, M, \hat{\theta}_{\text{MLE}}, \hat{\nu}(\theta) \big)}  \right)
\]</div>
<p>And this can be checked directly since it has a functinoal form, and since it approaches a <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution</p>
<div class="math notranslate nohighlight">
\[
p^{\text{MLE}}_\theta (\nu) \rightarrow 1-\alpha \left( 1- F_{\chi^2} [\theta, \nu] \right)
\]</div>
<p>where <span class="math notranslate nohighlight">\( F_{\chi^2}\)</span> is the comulative <span class="math notranslate nohighlight">\(\chi^2\)</span> distribution function. <span class="math notranslate nohighlight">\(p^{\text{MLE}}_\theta (\nu) \)</span> is approximated in two ways: first by histogramming the quantity (2) (we call this <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>), and second by plotting the <span class="math notranslate nohighlight">\(\chi^2\)</span> CDF directly for comparison.</p>
<p>The rest of the work aims at estimating the quantity <span class="math notranslate nohighlight">\(p^{\text{MLE}}_\theta (\nu)\)</span> using our LFI framework, where the estimate is denoted by <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>. After validating that our procedure works for the MLE case, we proceed to estimate <span class="math notranslate nohighlight">\(p^{\text{MLE}}_\theta (\nu) \)</span> for non-MLE case, and provide a procedure for which it can be calculate independently of nuissance parameter <span class="math notranslate nohighlight">\(\nu\)</span>.</p>
<p>Generate 6 pairs (tuples) of <span class="math notranslate nohighlight">\((\theta, \nu)\)</span> values</p>
<section id="generate-training-data-or-take-a-look-at-the-saved-training-data">
<h2>Generate Training data (or take a look at the saved training data)<a class="headerlink" href="#generate-training-data-or-take-a-look-at-the-saved-training-data" title="Permalink to this headline">#</a></h2>
<p>We then generate training data where the number of training examples is <span class="math notranslate nohighlight">\(B'\)</span> according to Alg. 2 of Anne Lee et al. (shown below). The training data now has <span class="math notranslate nohighlight">\(\{\theta, \nu, N, M \} \)</span> as training features and <span class="math notranslate nohighlight">\(Z\)</span> as the target. We then use Pytorch to build MLP regression model with average quadratic loss to estimate the distribution of <span class="math notranslate nohighlight">\(Z\)</span>, <span class="math notranslate nohighlight">\(E[Z|\theta,\nu]\)</span>, which according to Alg. 2 is the p-value.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="ann-lee-s-algorithm">
<h1><a class="reference external" href="https://arxiv.org/pdf/2107.03920.pdf">Ann Lee</a>’s Algorithm<a class="headerlink" href="#ann-lee-s-algorithm" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">algorithm2</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/Algorithm2.jpg&#39;</span><span class="p">);</span> <span class="n">display</span><span class="p">(</span><span class="n">algorithm2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_27_0.jpg" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_27_0.jpg" />
</div>
</div>
<p>As we know, the p-value is the probability under the null hypothesis <span class="math notranslate nohighlight">\(H_{null}\)</span> (which is in this case parameterized by <span class="math notranslate nohighlight">\(\theta\)</span>) of finding data of equal or greater <em>incompatibility</em> with the predictions of <span class="math notranslate nohighlight">\(H_{null}\)</span>. Therefore, in our case, the p-value under the null hypothesis (defined by <span class="math notranslate nohighlight">\(\theta\)</span>) is given by</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
p_\theta (\nu) &amp;=\int_{\lambda_D}^\infty f \big(\lambda_{gen}(n,m \mid \theta,\nu) \mid H_{null} \big) \ d \lambda_{gen} \\
 &amp;= 1- \text{Prob} \big(\lambda_{gen}(n,m;\theta,\nu) \le \lambda_D(N,M;\theta,\nu) \big), \tag{2}
\end{align}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(f\)</span> is the PDF of <span class="math notranslate nohighlight">\(\lambda\)</span>. In the strict frequentist approach, <span class="math notranslate nohighlight">\(\theta\)</span> is rejected only if the <span class="math notranslate nohighlight">\(p\)</span>-value is less than the significance level of a hypothesis test <span class="math notranslate nohighlight">\(\alpha\)</span> (i.e. accepeted if <span class="math notranslate nohighlight">\(p_\theta (\nu) \le \alpha\)</span>)</p>
<p>In our study we approximate this integral as the histogram of <span class="math notranslate nohighlight">\(\theta\)</span> weighted by <span class="math notranslate nohighlight">\(Z\)</span> divided by the histogram of <span class="math notranslate nohighlight">\(\theta\)</span>, and denote this histogram as <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>. We compare this exact p-value with the outcome of our MLP, <span class="math notranslate nohighlight">\(\mathbf{f}=\hat{p}(\theta, \nu, N,M)\)</span> for the case where <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is taken as the MLE in Fig. below we see almost perfect match.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>499999.500000</td>
      <td>0.870163</td>
      <td>10.000631</td>
      <td>9.998143</td>
      <td>0.001890</td>
      <td>4.999536</td>
      <td>4.997646</td>
    </tr>
    <tr>
      <th>std</th>
      <td>288675.278933</td>
      <td>0.336124</td>
      <td>5.770812</td>
      <td>5.775031</td>
      <td>3.654818</td>
      <td>2.582486</td>
      <td>2.582186</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000003</td>
      <td>0.000029</td>
      <td>-8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>249999.750000</td>
      <td>1.000000</td>
      <td>5.003307</td>
      <td>4.993816</td>
      <td>-3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>499999.500000</td>
      <td>1.000000</td>
      <td>10.001563</td>
      <td>9.995425</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>749999.250000</td>
      <td>1.000000</td>
      <td>15.001295</td>
      <td>15.001992</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>999999.000000</td>
      <td>1.000000</td>
      <td>19.999993</td>
      <td>19.999995</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">bins_</span> <span class="o">=</span> <span class="s1">&#39;auto&#39;</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$Z$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;N&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$N$&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">4</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">],</span> <span class="n">bins</span><span class="o">=</span><span class="n">bins_</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$M$&#39;</span><span class="p">)</span>

<span class="p">[</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">();</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_30_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_30_0.png" />
</div>
</div>
<section id="generate-theta-i-nu-i-n-i-m-i-z-i-data-according-to">
<h2>Generate <span class="math notranslate nohighlight">\(\{\theta_i, \nu_i, N_i, M_i, Z_i \}\)</span>  data according to:<a class="headerlink" href="#generate-theta-i-nu-i-n-i-m-i-z-i-data-according-to" title="Permalink to this headline">#</a></h2>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\theta &amp; \sim \textrm{uniform}(0, 20), \\
\nu &amp; \sim \textrm{uniform}(0, 20), \\
\end{align}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
n &amp; \sim \textrm{poisson}(\theta + \nu),\\
m &amp; \sim \textrm{poisson}(\nu),\\
\end{align}
\right\} \rightarrow \lambda_\text{gen}(n, m \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
\left\{
\begin{align}
N &amp; \sim \textrm{uniform}(0,10),\\
M &amp; \sim \textrm{uniform}(0, 10), \\
\end{align}
\right\} \rightarrow \lambda_D(N, M \mid \theta,\nu)
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
Z  = \mathbb{I}
\left[ \lambda_\text{gen}(n, m \mid \theta,\nu) \leq \lambda_D(N, M \mid \theta,\nu) \right].
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thetaMin</span><span class="p">,</span> <span class="n">thetaMax</span> <span class="o">=</span>  <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">numin</span><span class="p">,</span> <span class="n">numax</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">20</span>
<span class="n">Nmin</span><span class="p">,</span> <span class="n">Nmax</span> <span class="o">=</span>  <span class="mi">1</span><span class="p">,</span><span class="mi">10</span>
<span class="n">Mmin</span><span class="p">,</span> <span class="n">Mmax</span> <span class="o">=</span>  <span class="mi">1</span> <span class="p">,</span> <span class="mi">10</span>

<span class="k">def</span> <span class="nf">generate_training_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">save_data</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Generate the training data, that is, features=[theta, nu, N, M], targets=Z&quot;&quot;&quot;</span>
    <span class="c1">#sample theta and nu from uniform(0,20)</span>
    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetaMin</span><span class="p">,</span> <span class="n">thetaMax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1"># nu = st.uniform.rvs(nuMin, nuMax, size=Bprime)</span>
    <span class="n">nu</span><span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">numin</span><span class="p">,</span> <span class="n">numax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#n,m ~ F_{\theta,\nu}, ie our simulator. sample n from a Poisson with mean theta+nu </span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#sample m from a poisson with mean nu</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="c1">#sample our observed counts (N,M), which take the place of D</span>
    <span class="n">N</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">Nmin</span><span class="p">,</span> <span class="n">Nmax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">M</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">Mmin</span><span class="p">,</span> <span class="n">Mmax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">theta_hat_</span> <span class="o">=</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="n">SUBSAMPLE</span><span class="o">=</span><span class="mi">10</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;n=&#39;</span><span class="p">,</span> <span class="n">n</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;m=&#39;</span><span class="p">,</span> <span class="n">m</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;N=&#39;</span><span class="p">,</span> <span class="n">N</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;M=&#39;</span><span class="p">,</span> <span class="n">M</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="n">lambda_gen</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_gen= &#39;</span><span class="p">,</span> <span class="n">lambda_gen</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_D= &#39;</span><span class="p">,</span> <span class="n">lambda_D</span><span class="p">[:</span><span class="n">SUBSAMPLE</span><span class="p">])</span>
    <span class="c1">#if lambda_gen &lt;= lambda_D: Z=1, else Z=0</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_gen</span> <span class="o">&lt;=</span> <span class="n">lambda_D</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    
    <span class="n">data_2_param</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;Z&#39;</span> <span class="p">:</span> <span class="n">Z</span><span class="p">,</span> <span class="s1">&#39;theta&#39;</span> <span class="p">:</span> <span class="n">theta</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">:</span> <span class="n">nu</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">:</span> <span class="n">theta_hat_</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">:</span><span class="n">N</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">:</span><span class="n">M</span><span class="p">}</span>

    <span class="n">data_2_param</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data_2_param</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">save_data</span><span class="p">:</span>
        <span class="n">data_2_param</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">_</span><span class="si">%s</span><span class="s1">k_Examples_MLE_</span><span class="si">%s</span><span class="s1">.csv&#39;</span> <span class="o">%</span>\
                            <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">thetaMin</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">thetaMax</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">Bprime</span><span class="o">/</span><span class="mi">1000</span><span class="p">)),</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">))</span> <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">data_2_param</span><span class="o">.</span><span class="n">describe</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">data_2_param</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train_data_MLE_True = generate_training_data(Bprime=1000000, MLE=True, save_data=True)</span>
<span class="n">Train_data_MLE_False</span> <span class="o">=</span> <span class="n">generate_training_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000000</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">save_data</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>n= [14 10 32 10 21 22  7 19 24 17]
m= [16  7  7  2 17 12  2 11  2  9]
N= [2 3 4 6 4 1 2 3 8 1]
M= [2 4 2 1 4 8 9 3 1 2]
lambda_gen=  [1.2517422  0.46310694 0.98040981 0.34266725 1.64404084 0.17199006
 0.00541878 0.01108895 2.04429099 0.39646077]
lambda_D=  [ 3.64003569  5.17349279 19.87300615  0.14335275 11.49655925 22.16162778
  7.68013867  7.97220792  4.93881845  6.53211532]


                    Z           theta              nu       theta_hat  \
count  1000000.000000  1000000.000000  1000000.000000  1000000.000000   
mean         0.870748       10.002000       10.003980        1.483516   
std          0.335479        5.771159        5.772888        2.116762   
min          0.000000        0.000009        0.000026        0.000000   
25%          1.000000        5.002570        5.003612        0.000000   
50%          1.000000       10.009839       10.011399        0.000000   
75%          1.000000       14.995431       15.000630        3.000000   
max          1.000000       19.999991       19.999975        8.000000   

                    N               M  
count  1000000.000000  1000000.000000  
mean         5.001212        4.999616  
std          2.582294        2.582844  
min          1.000000        1.000000  
25%          3.000000        3.000000  
50%          5.000000        5.000000  
75%          7.000000        7.000000  
max          9.000000        9.000000  
</pre></div>
</div>
</div>
</div>
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="write-custom-data-loader">
<h1>Write Custom Data Loader<a class="headerlink" href="#write-custom-data-loader" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %writefile data/dataloader.py</span>

<span class="k">def</span> <span class="nf">split_t_x</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
    <span class="c1"># change from pandas dataframe format to a numpy </span>
    <span class="c1"># array of the specified types</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">target</span><span class="p">])</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">source</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># the numpy function choice(length, number)</span>
    <span class="c1"># selects at random &quot;batch_size&quot; integers from </span>
    <span class="c1"># the range [0, length-1] corresponding to the</span>
    <span class="c1"># row indices.</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="n">batch_x</span>


<span class="k">def</span> <span class="nf">get_data_sets</span><span class="p">(</span><span class="n">simulate_data</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;write custom data generator because who wants to read pytorch&#39;s DataLoader source code</span>
<span class="sd">    (and its sometimes slow for some reason)&quot;&quot;&quot;</span>
    <span class="c1"># if simulate_data:</span>
    <span class="c1">#     Train_data_MLE_True = generate_training_data(Bprime=100000, MLE=True, save_data=False)</span>
        
    <span class="c1"># if SUBSAMPLE:</span>
    <span class="c1">#     data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;, SUBSAMPLE=10000)#This is MLE DATA!</span>
    <span class="c1"># else:</span>
    <span class="c1">#     data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;)</span>
    <span class="c1"># data=load_df(&#39;data/TWO_PARAMETERS_TRAINING_DATA_1M.csv&#39;)</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> 
                 <span class="c1"># nrows=SUBSAMPLE,</span>
                 <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> 
                                         <span class="n">test_size</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>
    <span class="c1"># train_data, valid_data = train_test_split(train_data, test_size=0.2)</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="c1"># valid_data = valid_data.reset_index(drop=True)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;M&#39;</span><span class="p">]</span>
    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="c1"># valid_t, valid_x = split_t_x(valid_data, target=target, source=source)</span>
    <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>  <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">training_set_features</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">def</span> <span class="nf">evaluation_set_features</span><span class="p">():</span>
        <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span><span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>


    <span class="k">def</span> <span class="nf">training_set_targets</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">train_t</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">def</span> <span class="nf">evaluation_set_targets</span><span class="p">():</span>
            <span class="c1">#start with an infinite loop, so that you can keep calling next (i.e. set = train_set(); set.next() ) until you run out of training examples</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1">#get a random batch of the defined size</span>
            <span class="n">batch_x</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">test_t</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
            <span class="c1">#print(&#39;batch_x&#39;, batch_x)</span>
            <span class="c1">#index of one of the items in our examples</span>
            <span class="k">yield</span> <span class="n">batch_x</span>

    <span class="k">return</span> <span class="n">training_set_features</span><span class="p">,</span> <span class="n">training_set_targets</span><span class="p">,</span> <span class="n">evaluation_set_features</span><span class="p">,</span> <span class="n">evaluation_set_targets</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_set_features</span><span class="p">,</span> <span class="n">training_set_targets</span><span class="p">,</span> <span class="n">evaluation_set_features</span><span class="p">,</span> <span class="n">evaluation_set_targets</span> <span class="o">=</span> <span class="n">get_data_sets</span><span class="p">(</span><span class="n">simulate_data</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>

<span class="n">first_features_batch</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">training_set_features</span><span class="p">())</span>
<span class="n">sample_x</span> <span class="o">=</span><span class="n">first_features_batch</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;first features batch </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">first_features_batch</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">first features batch shape </span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">first_features_batch</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>first features batch 
 [[17.58674834 14.92601811 -8.          1.          9.        ]
 [ 5.83877824  0.49051158 -8.          1.          9.        ]
 [18.35629668  0.1884787  -2.          2.          4.        ]
 [ 4.09878055  2.40324673  4.          6.          2.        ]
 [19.90471632 17.43647751  4.          8.          4.        ]]

first features batch shape 
 (300, 5)
</pre></div>
</div>
</div>
</div>
<p>Plot the histogrammed function the histogrammed function <span class="math notranslate nohighlight">\(h(\tilde{\theta}, \nu, N, M) = h(\theta_{min}, \theta_{max}, \nu, N, M)\)</span> where <span class="math notranslate nohighlight">\(\tilde{\theta}\)</span> means that it is simulated (inside the function).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                <span class="n">nbins</span><span class="p">,</span>
             <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span> <span class="o">&lt;</span> 
         <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="c1"># bins = binsize(Bprime)</span>

    <span class="c1"># weighted histogram   (count the number of ones per bin)</span>
    <span class="n">y1</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> 
                          <span class="n">bins</span><span class="o">=</span><span class="n">nbins</span><span class="p">,</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="n">thetarange</span><span class="p">,</span> 
                          <span class="n">weights</span><span class="o">=</span><span class="n">Z</span><span class="p">)</span>
    
    <span class="c1"># unweighted histogram (count number of ones and zeros per bin)</span>
    <span class="n">yt</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> 
                         <span class="n">bins</span><span class="o">=</span><span class="n">nbins</span><span class="p">,</span> 
                         <span class="nb">range</span><span class="o">=</span><span class="n">thetarange</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span>  <span class="n">y1</span> <span class="o">/</span> <span class="n">yt</span>    
    
    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">bb</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="going-2d">
<h1>Going 2D<a class="headerlink" href="#going-2d" title="Permalink to this headline">#</a></h1>
<section id="in-theta-nu-space-of-course">
<h2>(in <span class="math notranslate nohighlight">\((\theta, \nu)\)</span> space, of course)<a class="headerlink" href="#in-theta-nu-space-of-course" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_2d_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                <span class="n">nbins</span><span class="p">,</span>
             <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>

    <span class="n">theta</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">uniform</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span> <span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">Bprime</span><span class="p">)</span>
    
    <span class="n">Z</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span> <span class="o">&lt;</span> 
         <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>

    <span class="n">thetarange</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">)</span>
    <span class="c1"># bins = binsize(Bprime)</span>

    <span class="c1"># weighted histogram   (count the number of ones per bin)</span>
    <span class="n">y1</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> 
                          <span class="n">bins</span><span class="o">=</span><span class="n">nbins</span><span class="p">,</span> 
                          <span class="nb">range</span><span class="o">=</span><span class="n">thetarange</span><span class="p">,</span> 
                          <span class="n">weights</span><span class="o">=</span><span class="n">Z</span><span class="p">)</span>
    
    <span class="c1"># unweighted histogram (count number of ones and zeros per bin)</span>
    <span class="n">yt</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> 
                         <span class="n">bins</span><span class="o">=</span><span class="n">nbins</span><span class="p">,</span> 
                         <span class="nb">range</span><span class="o">=</span><span class="n">thetarange</span><span class="p">)</span>

    <span class="n">y</span> <span class="o">=</span>  <span class="n">y1</span> <span class="o">/</span> <span class="n">yt</span>    
    
    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">bb</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">h</span><span class="p">,</span> <span class="n">h_bins</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> 
                           <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
                           <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">h</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.33333333, 0.22222222, 0.14285714, 0.        , 0.57142857,
       0.25      , 0.4       , 0.        , 0.        , 0.25      ,
       0.33333333, 0.75      , 0.8       , 0.5       , 0.66666667,
       1.        , 0.5       , 1.        , 0.83333333, 0.5       ,
       0.8       , 1.        , 0.6       , 1.        , 0.83333333,
       0.8       , 1.        , 0.75      , 0.75      , 0.66666667,
       1.        , 0.8       , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 0.66666667, 0.83333333,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 0.875     ,
       1.        , 1.        , 1.        , 1.        , 0.8       ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
              nan, 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        ,        nan, 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ,
       1.        , 1.        , 1.        , 1.        , 1.        ])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_one_hist</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">ax</span><span class="p">):</span>
    <span class="n">counts</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
            <span class="n">nbins</span><span class="p">,</span>
             <span class="n">MLE</span><span class="p">)</span>
    <span class="n">bin_centers</span> <span class="o">=</span> <span class="p">(</span><span class="n">bins</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bins</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_centers</span><span class="p">,</span> <span class="n">counts</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span> <span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ Example&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$E(Z|\theta,\nu)$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_axes</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">();</span><span class="n">ax</span><span class="o">=</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">()</span>

<span class="c1">#Example:</span>
<span class="n">plot_one_hist</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_44_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_44_0.png" />
</div>
</div>
</section>
<section id="plot-the-histogrammed-approximations-for-the-mle-vs-non-mle-cases-for-a-single-value-of-mathbf-nu">
<h2>Plot the histogrammed approximations for the MLE vs non-MLE cases for a single value of <span class="math notranslate nohighlight">\(\mathbf{\nu}\)</span><a class="headerlink" href="#plot-the-histogrammed-approximations-for-the-mle-vs-non-mle-cases-for-a-single-value-of-mathbf-nu" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data_one_nu</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> 
              <span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">)):</span>
    
    <span class="c1"># make room for 6 sub-plots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                           <span class="n">figsize</span><span class="o">=</span><span class="n">fgsize</span><span class="p">)</span>
    
    <span class="c1"># padding</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
    
    <span class="c1"># use flatten() to convert a numpy array of </span>
    <span class="c1"># shape (nrows, ncols) to a 1-d array. </span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>
        
        <span class="n">y</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\theta$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$E(Z|\theta, \nu)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$, MLE&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        <span class="c1">#h is histogram approximation</span>

        <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">bb_nonMLE</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="n">x_nonMLE</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nonMLE</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nonMLE</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_nonMLE</span><span class="p">,</span> <span class="n">y_nonMLE</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$, non-MLE&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
        
        
        <span class="k">if</span> <span class="n">func</span><span class="p">:</span>
            <span class="n">p</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;f&#39;</span><span class="p">)</span>
            <span class="c1">#f is model approximation</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">5.1</span><span class="p">,</span> <span class="mf">0.42</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$N, M = </span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                   <span class="c1"># fontsize=FONTSIZE</span>
                  <span class="p">)</span> 

        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">5.1</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\nu = </span><span class="si">%5.1f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">nu</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                   <span class="c1"># fontsize=FONTSIZE</span>
                  <span class="p">)</span> 

        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
        
    <span class="c1"># hide unused sub-plots</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="p">[</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">M</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>
<span class="n">plot_data_one_nu</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_47_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_47_0.png" />
</div>
</div>
</section>
<section id="plot-the-histogrammed-approximation-mathbf-h-for-the-mle-vs-non-mle-cases-for-multiple-values-of-mathbf-nu-indicating-the-dependence-on-the-nuissance-parameter">
<h2>Plot the histogrammed approximation <span class="math notranslate nohighlight">\(\mathbf{h}\)</span>, for the MLE vs non-MLE cases for multiple values of <span class="math notranslate nohighlight">\(\mathbf{\nu}\)</span>, indicating the dependence on the nuissance parameter<a class="headerlink" href="#plot-the-histogrammed-approximation-mathbf-h-for-the-mle-vs-non-mle-cases-for-multiple-values-of-mathbf-nu-indicating-the-dependence-on-the-nuissance-parameter" title="Permalink to this headline">#</a></h2>
<hr class="docutils" />
</section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="ml">
<h1>ML<a class="headerlink" href="#ml" title="Permalink to this headline">#</a></h1>
<p>It is important to always remember the following formula:</p>
<div class="math notranslate nohighlight">
\[ \int \frac{\partial L}{\partial f} \ p(y|x) \ dy =0\]</div>
<p>Where <span class="math notranslate nohighlight">\(L\)</span>, <span class="math notranslate nohighlight">\(f\)</span> are the loss function and the model (neural network/classifier/regressor, etc), and <span class="math notranslate nohighlight">\(p(y|x)\)</span> the PDF of targets <span class="math notranslate nohighlight">\(y\)</span> that we want to estimate, given features <span class="math notranslate nohighlight">\(x\)</span>.</p>
<p>In this notebook we will estimate both <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> and <span class="math notranslate nohighlight">\(\mathbf{\tilde{\lambda}}\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">getwholedata</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                    <span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">,</span> 
             <span class="c1"># nrows=SUBSAMPLE,</span>
             <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
            <span class="p">)</span>
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>
    

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span>
    <span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span><span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;M&#39;</span><span class="p">]</span>

    <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>  <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span>  <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_t shape = &#39;</span><span class="p">,</span> <span class="n">train_t</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train_x shape = &#39;</span><span class="p">,</span> <span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
    
    <span class="k">if</span> <span class="n">valid</span><span class="p">:</span>
        <span class="c1">#if you want to also make a validation data set</span>
        <span class="n">train_data</span><span class="p">,</span> <span class="n">valid_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
        <span class="n">valid_data</span> <span class="o">=</span> <span class="n">valid_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">valid_t</span><span class="p">,</span> <span class="n">valid_x</span> <span class="o">=</span> <span class="n">split_t_x</span><span class="p">(</span><span class="n">valid_data</span><span class="p">,</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">)</span>

        
    <span class="k">return</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span>


<span class="c1"># n_iterations=50</span>
</pre></div>
</div>
</div>
</div>
<section id="define-model-mathbf-f-which-will-approximate-the-expectation-value-above">
<h2>Define Model <span class="math notranslate nohighlight">\(\mathbf{f}\)</span>, which will approximate the expectation value above<a class="headerlink" href="#define-model-mathbf-f-which-will-approximate-the-expectation-value-above" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_inputs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_nodes</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>

        <span class="c1"># call constructor of base (or super, or parent) class</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="c1"># create input layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layer0</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">n_inputs</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer0</span><span class="p">)</span>

        <span class="c1"># create &quot;hidden&quot; layers</span>
        <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_layers</span><span class="p">):</span>
            <span class="n">cmd</span> <span class="o">=</span> <span class="s1">&#39;self.layer</span><span class="si">%d</span><span class="s1"> = nn.Linear(</span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> \
            <span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>
            <span class="n">exec</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
            <span class="n">cmd</span> <span class="o">=</span> <span class="s1">&#39;self.layers.append(self.layer</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">l</span>
            <span class="n">exec</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
          
        <span class="c1"># create output layer</span>
        <span class="n">cmd</span> <span class="o">=</span> <span class="s1">&#39;self.layer</span><span class="si">%d</span><span class="s1"> = nn.Linear(</span><span class="si">%d</span><span class="s1">, 1)&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">n_layers</span><span class="p">,</span> <span class="n">n_nodes</span><span class="p">)</span>
        <span class="n">exec</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
        <span class="n">cmd</span> <span class="o">=</span> <span class="s1">&#39;self.layers.append(self.layer</span><span class="si">%d</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">n_layers</span>
        <span class="n">exec</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>

    <span class="c1"># define (required) method to compute output of network</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">](</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">y</span>

<span class="n">model_</span> <span class="o">=</span> <span class="n">Model</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Model(
  (layer0): Linear(in_features=4, out_features=20, bias=True)
  (layer1): Linear(in_features=20, out_features=20, bias=True)
  (layer2): Linear(in_features=20, out_features=20, bias=True)
  (layer3): Linear(in_features=20, out_features=20, bias=True)
  (layer4): Linear(in_features=20, out_features=20, bias=True)
  (layer5): Linear(in_features=20, out_features=1, bias=True)
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">average_quadratic_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">average_loss</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
    <span class="c1"># f and t must be of the same shape</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">get_features_training_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
    <span class="c1"># the numpy function choice(length, number)</span>
    <span class="c1"># selects at random &quot;batch_size&quot; integers from </span>
    <span class="c1"># the range [0, length-1] corresponding to the</span>
    <span class="c1"># row indices.</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="n">batch_t</span> <span class="o">=</span> <span class="n">t</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span>
          <span class="n">batch_size</span><span class="p">,</span> 
          <span class="n">n_iterations</span><span class="p">,</span> <span class="n">traces</span><span class="p">,</span> 
          <span class="n">step</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    
    <span class="c1"># to keep track of average losses</span>
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    

    
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration vs average loss&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="s2">&quot;</span> <span class="o">%</span> \
          <span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">,</span> <span class="s1">&#39;train-set&#39;</span><span class="p">,</span> <span class="s1">&#39;valid-set&#39;</span><span class="p">))</span>
    
    <span class="c1"># training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = get_data_sets(simulate_data=False, batchsize=batch_size)</span>
    
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>

        <span class="c1"># set mode to training so that training specific </span>
        <span class="c1"># operations such as dropout are enabled.</span>

        
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="c1"># get a random sample (a batch) of data (as numpy arrays)</span>
        
        <span class="c1">#Harrison-like Loader</span>
        <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_features_training_batch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1">#Or Ali&#39;s Loader</span>
        <span class="c1"># batch_x, batch_t = next(training_set_features()), next(training_set_targets())</span>
        <span class="c1"># batch_x_eval, batch_t_eval = next(evaluation_set_features()), next(evaluation_set_targets())</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients </span>
            <span class="c1"># wrt. x and t</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>      


        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
   
        <span class="c1"># compute a noisy approximation to the average loss</span>
        <span class="n">empirical_risk</span> <span class="o">=</span> <span class="n">avloss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># use automatic differentiation to compute a </span>
        <span class="c1"># noisy approximation of the local gradient</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>       <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>   <span class="c1"># compute gradients</span>
        
        <span class="c1"># finally, advance one step in the direction of steepest </span>
        <span class="c1"># descent, using the noisy local gradient. </span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># move one step</span>
        
        <span class="k">if</span> <span class="n">ii</span> <span class="o">%</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            
            
            <span class="c1">#using Harrison-like loader</span>
            <span class="n">acc_t</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">train_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">train_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span> 
            <span class="n">acc_v</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">test_x</span><span class="p">[:</span><span class="n">n</span><span class="p">],</span> <span class="n">test_t</span><span class="p">[:</span><span class="n">n</span><span class="p">])</span>
            
            <span class="c1">#using Ali&#39;s loader</span>
            <span class="c1"># acc_t = validate(model, avloss, batch_x, batch_t) </span>
            <span class="c1"># acc_v = validate(model, avloss, batch_x_eval, batch_t_eval)</span>
            

            <span class="n">yy_t</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_t</span><span class="p">)</span>
            <span class="n">yy_v</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v</span><span class="p">)</span>
            
            <span class="c1"># compute running average for validation data</span>
            <span class="n">len_yy_v</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span>
            <span class="k">if</span>   <span class="n">len_yy_v</span> <span class="o">&lt;</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="p">)</span>
            <span class="k">elif</span> <span class="n">len_yy_v</span> <span class="o">==</span> <span class="n">window</span><span class="p">:</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span> <span class="nb">sum</span><span class="p">(</span><span class="n">yy_v</span><span class="p">)</span> <span class="o">/</span> <span class="n">window</span> <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">acc_v_avg</span>  <span class="o">=</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">window</span>
                <span class="n">acc_v_avg</span> <span class="o">+=</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="n">window</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">yy_v_avg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc_v_avg</span> <span class="o">/</span> <span class="n">window</span><span class="p">)</span>
                        
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">xx</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                      <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">xx</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">step</span><span class="p">)</span>
                    
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\r</span><span class="si">%10d</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="se">\t</span><span class="si">%10.6f</span><span class="s2">&quot;</span> <span class="o">%</span> \
                          <span class="p">(</span><span class="n">xx</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_t</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">yy_v_avg</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> 
                      <span class="n">end</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">)</span>
            
    <span class="nb">print</span><span class="p">()</span>      
    <span class="k">return</span> <span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_average_loss</span><span class="p">(</span><span class="n">traces</span><span class="p">,</span> <span class="n">ftsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span><span class="n">save_loss_plots</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="n">yy_v_avg</span> <span class="o">=</span> <span class="n">traces</span>
    
    <span class="c1"># create an empty figure</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mf">4.5</span><span class="p">))</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    
    <span class="c1"># add a subplot to it</span>
    <span class="n">nrows</span><span class="p">,</span> <span class="n">ncols</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span>
    <span class="n">ax</span>  <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">nrows</span><span class="p">,</span><span class="n">ncols</span><span class="p">,</span><span class="n">index</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Average loss&quot;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_t</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Training&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy_v</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Validation&#39;</span><span class="p">)</span>
    <span class="c1">#ax.plot(xx, yy_v_avg, &#39;g&#39;, lw=2, label=&#39;Running average&#39;)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Iterations&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;average loss&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yscale</span><span class="p">(</span><span class="s1">&#39;log&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">save_loss_plots</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/loss_curves/IQN_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="n">T</span><span class="o">+</span><span class="s1">&#39;_Consecutive_2.png&#39;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">loss curve saved in images/loss_curves/IQN_&#39;</span><span class="o">+</span><span class="n">N</span><span class="o">+</span><span class="n">target</span><span class="o">+</span><span class="s1">&#39;_Consecutive.png&#39;</span><span class="p">)</span>
    <span class="c1"># if show_loss_plots:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Define my regularized regression model. Since the values are on the same scales, it is not necessary to include batchnormalization or to normalize the data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">RegularizedRegressionModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1">#inherit from the super class</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nfeatures</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">,</span> <span class="n">nlayers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="c1">#inital layer has to have size of input features as its input layer</span>
                <span class="c1">#its output layer can have any size but it must match the size of the input layer of the next linear layer</span>
                <span class="c1">#here we choose its output layer as the hidden size (fully connected)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">nfeatures</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1">#batch normalization</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="c1">#ReLU activation </span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1">#if this is not the first layer (we dont have layers)</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>
                <span class="c1"># layers.append(nn.BatchNorm1d(hidden_size))</span>
                <span class="c1">#Dropout seems to worsen model performance</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">))</span>
                <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
                <span class="c1">#output layer:</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">ntargets</span><span class="p">))</span> 

        <span class="c1"># ONLY IF ITS A CLASSIFICATION, ADD SIGMOID</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">())</span>
            <span class="c1">#we have defined sequential model using the layers in oulist </span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="make-a-hyperparameter-tuning-workflow">
<h1>Make a hyperparameter Tuning Workflow<a class="headerlink" href="#make-a-hyperparameter-tuning-workflow" title="Permalink to this headline">#</a></h1>
<p>Use Optuna ( <a class="reference external" href="https://arxiv.org/pdf/1907.10902.pdf">axriv:1907.10902</a> ) for hyperparameter tuning. The search space for the hyperparameters that I’m tuning is defined in the params dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s2">&quot;nlayers&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;nlayers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">),</span>      
      <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">130</span><span class="p">),</span>
      <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span>
      <span class="s2">&quot;optimizer_name&quot;</span> <span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="s2">&quot;RMSprop&quot;</span><span class="p">]),</span>
      <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
      <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

    <span class="p">}</span>
</pre></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Engine</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;loss, training and evaluation&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
                 <span class="c1">#, device):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="c1">#self.device= device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span>
        
    <span class="c1">#the loss function returns the loss function. It is a static method so it doesn&#39;t need self</span>
    <span class="c1"># @staticmethod</span>
    <span class="c1"># def loss_fun(targets, outputs):</span>
    <span class="c1">#   tau = torch.rand(outputs.shape)</span>
    <span class="c1">#   return torch.mean(torch.where(targets &gt;= outputs, </span>
    <span class="c1">#                                   tau * (targets - outputs), </span>
    <span class="c1">#                                   (1 - tau)*(outputs - targets)))</span>

<span class="c1">#     This loss combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss as, </span>
<span class="c1">#     by combining the operations into one layer</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the training function: takes the training dataloader&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_features_training_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">average_quadratic_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
    
    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;the training function: takes the training dataloader&quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">final_loss</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
            <span class="n">batch_x</span><span class="p">,</span> <span class="n">batch_t</span> <span class="o">=</span> <span class="n">get_features_training_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span>  <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span><span class="c1">#x and t are train_x and train_t</span>

            <span class="c1"># with torch.no_grad():            </span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">targets</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">batch_t</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
            <span class="n">final_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">final_loss</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>



<span class="n">EPOCHS</span><span class="o">=</span><span class="mi">1</span>
<span class="k">def</span> <span class="nf">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;For tuning the parameters&quot;&quot;&quot;</span>

    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
              <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
                <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">nlayers</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                <span class="n">hidden_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span>
                <span class="n">dropout</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="c1"># print(model)</span>
    

    <span class="n">learning_rate</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span>
    
    <span class="c1"># optimizer = torch.optim.Adam(model.parameters(), lr=params[&quot;learning_rate&quot;]) </span>
    
    <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
    
    <span class="n">eng</span><span class="o">=</span><span class="n">Engine</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">best_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>
    <span class="n">early_stopping_iter</span><span class="o">=</span><span class="mi">10</span>
    <span class="n">early_stopping_coutner</span><span class="o">=</span><span class="mi">0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">EPOCHS</span><span class="p">):</span>
        <span class="n">train_loss</span> <span class="o">=</span> <span class="n">eng</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_t</span><span class="p">)</span>
        <span class="n">valid_loss</span><span class="o">=</span><span class="n">eng</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">epoch</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">{</span><span class="n">train_loss</span><span class="si">}</span><span class="s2"> </span><span class="se">\t</span><span class="s2"> </span><span class="si">{</span><span class="n">valid_loss</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">valid_loss</span><span class="o">&lt;</span><span class="n">best_loss</span><span class="p">:</span>
            <span class="n">best_loss</span><span class="o">=</span><span class="n">valid_loss</span>
            <span class="k">if</span> <span class="n">save_model</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span> <span class="s2">&quot;model_m.bin&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">early_stopping_coutner</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">early_stopping_coutner</span> <span class="o">&gt;</span> <span class="n">early_stopping_iter</span><span class="p">:</span>
            <span class="k">break</span>
    <span class="k">return</span> <span class="n">best_loss</span>

<span class="c1"># run_train()</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
      <span class="s2">&quot;nlayers&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;nlayers&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">13</span><span class="p">),</span>      
      <span class="s2">&quot;hidden_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">130</span><span class="p">),</span>
      <span class="s2">&quot;dropout&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;dropout&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span><span class="mf">0.5</span><span class="p">),</span>
      <span class="s2">&quot;optimizer_name&quot;</span> <span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;Adam&quot;</span><span class="p">,</span> <span class="s2">&quot;RMSprop&quot;</span><span class="p">]),</span>
      <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
      <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">)</span>

    <span class="p">}</span>
    <span class="c1"># all_losses=[]</span>

    <span class="n">temp_loss</span> <span class="o">=</span> <span class="n">run_train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span><span class="n">save_model</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="c1"># all_losses.append(temp_loss)</span>
    <span class="k">return</span> <span class="n">temp_loss</span>

<span class="k">def</span> <span class="nf">tune_hyperparameters</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Getting best hyperparameters&#39;</span><span class="p">)</span>
    <span class="n">study</span><span class="o">=</span><span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="s2">&quot;minimize&quot;</span><span class="p">)</span>
    <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">best_trial</span> <span class="o">=</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trial</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;best model parameters&#39;</span><span class="p">,</span> <span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

    <span class="n">best_params</span><span class="o">=</span><span class="n">best_trial</span><span class="o">.</span><span class="n">params</span><span class="c1">#this is a dictionary</span>
    <span class="n">filename</span><span class="o">=</span><span class="s1">&#39;best_params/best_params_Test_Trials.csv&#39;</span>
    <span class="n">param_df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                            <span class="s1">&#39;n_layers&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;nlayers&quot;</span><span class="p">],</span> 
                            <span class="s1">&#39;hidden_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">],</span> 
                            <span class="s1">&#39;dropout&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">],</span>
                            <span class="s1">&#39;optimizer_name&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">],</span>
                            <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span> 
                            <span class="s1">&#39;batch_size&#39;</span><span class="p">:</span><span class="n">best_params</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="p">},</span>
                                    <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="p">)</span>

    <span class="n">param_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">filename</span><span class="p">)</span>   
</pre></div>
</div>
</div>
</div>
<section id="don-t-run-the-one-cell-below-unless-you-want-to-tune">
<h2>Don’t run the one cell below, unless you want to tune!<a class="headerlink" href="#don-t-run-the-one-cell-below-unless-you-want-to-tune" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tune_hyperparameters</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-the-dictionary-of-the-best-hyperparameters-that-was-saved-from-our-hyperparameter-tuning-workflow-and-retrieve-the-values">
<h1>Load the dictionary of the best hyperparameters that was saved from our hyperparameter tuning workflow, and retrieve the values<a class="headerlink" href="#load-the-dictionary-of-the-best-hyperparameters-that-was-saved-from-our-hyperparameter-tuning-workflow-and-retrieve-the-values" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BEST_PARAMS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;best_params/best_params_Test_Trials.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Unnamed: 0  n_layers  hidden_size  dropout optimizer_name  learning_rate  \
0           0         4           11  0.13208        RMSprop       0.006398   

   batch_size  
0        1000  
</pre></div>
</div>
</div>
</div>
<section id="define-network-node-shapes-parameters-and-training-data">
<h2>Define network node shapes, parameters, and training data<a class="headerlink" href="#define-network-node-shapes-parameters-and-training-data" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># BATCHSIZE=batch_size</span>
<span class="c1"># training_set_features, training_set_targets, evaluation_set_features, evaluation_set_targets = \</span>
<span class="c1"># get_data_sets(simulate_data=False, batchsize=BATCHSIZE)</span>

<span class="c1"># sample_x=next(training_set_features())#this is just to get the dimenstions of one batch</span>
<span class="c1"># sample_y=next(training_set_targets())</span>
<span class="c1"># #(batchsize,5) for mass</span>
<span class="c1"># print(&#39;sample x shape&#39;, sample_x.shape)</span>
<span class="c1"># print(&#39;sample t shape&#39;, sample_y.shape)</span>

<span class="c1"># n_features = sample_x.shape[1]</span>
<span class="c1"># print(&#39;\n&#39;)</span>



<span class="c1"># model =  RegularizedRegressionModel(</span>
<span class="c1">#     nfeatures=sample_x.shape[1], </span>
<span class="c1">#     ntargets=1,</span>
<span class="c1">#     nlayers=n_layers, </span>
<span class="c1">#     hidden_size=hidden_size, </span>
<span class="c1">#     dropout=dropout</span>
<span class="c1">#     )</span>

<span class="c1"># print(model)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="initiate-model-based-on-choice-of-whose-model-ali-or-harrison-and-parameters">
<h2>Initiate model based on choice of whose model (Ali or Harrison) and parameters<a class="headerlink" href="#initiate-model-based-on-choice-of-whose-model-ali-or-harrison-and-parameters" title="Permalink to this headline">#</a></h2>
<section id="then-train">
<h3>Then train<a class="headerlink" href="#then-train" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">initiate_whose_model</span><span class="p">(</span><span class="n">Ali_or_Harrison</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    <span class="n">whose_model</span><span class="o">=</span><span class="s1">&#39;Ali&#39;</span>

    <span class="k">if</span> <span class="n">whose_model</span><span class="o">==</span><span class="s1">&#39;Harrison&#39;</span><span class="p">:</span>
        <span class="n">n_layers</span><span class="o">=</span><span class="mi">5</span>
        <span class="n">hidden_size</span><span class="o">=</span><span class="mi">5</span>
        <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span>
        <span class="n">learning_rate</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span>
        <span class="n">optimizer</span>     <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">))</span> 
        <span class="n">model</span><span class="o">=</span><span class="n">Model</span><span class="p">()</span>
    <span class="k">elif</span> <span class="n">whose_model</span><span class="o">==</span><span class="s1">&#39;Ali&#39;</span><span class="p">:</span>
        <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
        <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
        <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
        <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
        <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
            <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
            <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
            <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
            <span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="p">)(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        
    <span class="k">return</span> <span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">optimizer</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="training-you-can-scroll-down-to-load-up-trained-model-instead-of-training-now">
<h1>Training: You can scroll down to load up trained model instead of training now<a class="headerlink" href="#training-you-can-scroll-down-to-load-up-trained-model-instead-of-training-now" title="Permalink to this headline">#</a></h1>
<section id="train-mle-model">
<h2>Train MLE model<a class="headerlink" href="#train-mle-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#initiate MLE model </span>
<span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_MLE</span><span class="p">,</span> <span class="n">optimizer_MLE</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_MLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_MLE</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">200</span>


<span class="n">n_iterations</span><span class="o">=</span><span class="mi">100000</span>
<span class="c1">#train</span>
<span class="n">traces_MLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_MLE</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_MLE</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RMSprop (
Parameter Group 0
    alpha: 0.99
    centered: False
    eps: 1e-08
    lr: 0.0063975512794992
    momentum: 0
    weight_decay: 0
)



RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
train_t shape =  (800000,) 

train_x shape =  (800000, 5) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.107258	  0.107904
     99800	  0.060430	  0.060400	  0.061000
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># n_iterations=10000</span>
<span class="c1"># BATCHSIZE=500</span>
<span class="c1"># traces= train(model=model, optimizer=optimizer, avloss=average_quadratic_loss,</span>
<span class="c1">#           batch_size=BATCHSIZE, </span>
<span class="c1">#           n_iterations=n_iterations, traces=traces, </span>
<span class="c1">#           step=traces_step, window=100)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_average_loss</span><span class="p">(</span><span class="n">traces_MLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_70_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_70_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="n">MLE</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_MLE</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">model_nonMLE</span>
    <span class="n">PATH</span><span class="o">=</span><span class="s1">&#39;models/MLE_</span><span class="si">%s</span><span class="s1">_Regressor_</span><span class="si">%s</span><span class="s1">K_training_iter.pt&#39;</span> <span class="o">%</span> <span class="p">(</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">with_theta_hat</span><span class="o">=</span><span class="kc">True</span>
    <span class="k">if</span> <span class="n">with_theta_hat</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span><span class="s1">&#39;models/MLE_</span><span class="si">%s</span><span class="s1">_Regressor_</span><span class="si">%s</span><span class="s1">K_training_iter_with_theta_hat.pt&#39;</span> <span class="o">%</span> <span class="p">(</span> <span class="nb">str</span><span class="p">(</span><span class="n">MLE</span><span class="p">),</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">/</span><span class="mi">1000</span><span class="p">)</span> <span class="p">)</span>
    
    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>  <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="train-non-mle-model">
<h2>Train non-MLE model<a class="headerlink" href="#train-non-mle-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#also initiate non-MLE model</span>
<span class="n">n_layers</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">optimizer_name</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">model_nonMLE</span><span class="p">,</span> <span class="n">optimizer_nonMLE</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_nonMLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">400</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimizer_MLE</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_MLE</span><span class="p">)</span>

<span class="n">n_iterations</span><span class="o">=</span><span class="mi">100000</span>
<span class="n">traces_nonMLE</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model_nonMLE</span><span class="p">,</span> 
              <span class="n">optimizer</span><span class="o">=</span><span class="n">optimizer_nonMLE</span><span class="p">,</span> 
              <span class="n">avloss</span><span class="o">=</span><span class="n">average_quadratic_loss</span><span class="p">,</span>
              <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> 
              <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
              <span class="n">traces</span><span class="o">=</span><span class="n">traces_nonMLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="n">traces_step</span><span class="p">,</span> 
              <span class="n">window</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span>
                <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plot_average_loss</span><span class="p">(</span><span class="n">traces_nonMLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train_t shape =  (800000,) 

train_x shape =  (800000, 5) 

Iteration vs average loss
 iteration	 train-set	 valid-set
         0	  0.151603	  0.151636
     99600	  0.063669	  0.063138	  0.063138
</pre></div>
</div>
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_74_1.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_74_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">save_model</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<section id="make-sure-the-train-df-has-the-same-ranges-as-the-data-you-want-to-generate-for-evaluation">
<h3>Make sure the train df has the same ranges as the data you want to generate for evaluation<a class="headerlink" href="#make-sure-the-train-df-has-the-same-ranges-as-the-data-you-want-to-generate-for-evaluation" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; returns the dataframe, can be used if the dataframe is saved in csv format</span>
<span class="sd">    of if it is already in dataframe format (e.g. generated in this notebook). &quot;&quot;&quot;</span>
    <span class="c1"># SUBSAMPLE=int(1e5)</span>
    <span class="c1"># if isinstance(df_name,str):</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> 
                         <span class="c1"># nrows=SUBSAMPLE,</span>
                         <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">,</span> 
                 <span class="c1"># nrows=SUBSAMPLE,</span>
                 <span class="n">usecols</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Z&#39;</span><span class="p">,</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
                <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_df</span>

<span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_MLE</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.870163</td>
      <td>10.000631</td>
      <td>9.998143</td>
      <td>0.001890</td>
      <td>4.999536</td>
      <td>4.997646</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.336124</td>
      <td>5.770812</td>
      <td>5.775031</td>
      <td>3.654818</td>
      <td>2.582486</td>
      <td>2.582186</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000003</td>
      <td>0.000029</td>
      <td>-8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>5.003307</td>
      <td>4.993816</td>
      <td>-3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>10.001563</td>
      <td>9.995425</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>15.001295</td>
      <td>15.001992</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>19.999993</td>
      <td>19.999995</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">train_df_nonMLE</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.870748</td>
      <td>10.002000</td>
      <td>10.003980</td>
      <td>1.483516</td>
      <td>5.001212</td>
      <td>4.999616</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.335479</td>
      <td>5.771159</td>
      <td>5.772888</td>
      <td>2.116762</td>
      <td>2.582294</td>
      <td>2.582844</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000009</td>
      <td>0.000026</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.000000</td>
      <td>5.002570</td>
      <td>5.003612</td>
      <td>0.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.000000</td>
      <td>10.009839</td>
      <td>10.011399</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>14.995431</td>
      <td>15.000630</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>19.999991</td>
      <td>19.999975</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
</section>
<section id="make-on-the-fly-generated-evaluation-data">
<h2>Make “on-the-fly” generated evaluation data<a class="headerlink" href="#make-on-the-fly-generated-evaluation-data" title="Permalink to this headline">#</a></h2>
<p>Note that this is one advantage of LFI, where one can always generate more synthetic data (for training as well as evaluation), whereas in traditinoal ML, the raining and evaluation data sets are fixed. Here, we generate binned <span class="math notranslate nohighlight">\(\theta\)</span> with the same ranges as those of the training set, and constants for <span class="math notranslate nohighlight">\(\{ \nu, N, M \}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>
    <span class="c1">#if MLE true, load the model that was trained on MLE data and vice versa</span>
    <span class="c1"># N, M = D</span>
    <span class="c1"># nbins=NBINS</span>
    <span class="c1"># thetamin,thetamax=0,20</span>
    <span class="n">thetamin</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">thetamax</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">thetastep</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamax</span><span class="o">-</span><span class="n">thetamin</span><span class="p">)</span> <span class="o">/</span> <span class="n">nbins</span>
    <span class="n">bb</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">+</span><span class="n">thetastep</span><span class="p">,</span> <span class="n">thetastep</span><span class="p">)</span><span class="c1">#this is just making a vector of thetas</span>
    <span class="n">X</span>     <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<section id="look-at-an-example-of-a-on-the-fly-generated-evaluation-data">
<h3>Look at an example of a “on-the-fly” generated evaluation data<a class="headerlink" href="#look-at-an-example-of-a-on-the-fly-generated-evaluation-data" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span><span class="p">,</span> <span class="n">eval_bins_example</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span><span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">eval_data_example</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.0333,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.1000,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.1667,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.2333,  3.0000, -2.0000,  1.0000,  3.0000],
        [ 0.3000,  3.0000, -2.0000,  1.0000,  3.0000]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_data_example</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">eval_bins_example</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(torch.Size([301, 5]), (301,))
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-and-evaluate-trained-model-at-generated-data">
<h1>Load and Evaluate Trained model at generated data<a class="headerlink" href="#load-and-evaluate-trained-model-at-generated-data" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">usemodel</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>
    
    <span class="c1">#Generate evaluation data at those fixed nu, N, M values</span>
    <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span><span class="n">train_df</span><span class="p">,</span><span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">nbins</span><span class="p">)</span><span class="c1">#eval data is indipendent of MLE, since its just constants witha theta variable</span>

    <span class="c1"># if MLE==True:</span>
    <span class="c1">#     model=model</span>
    <span class="c1">#else load the model trained on non-MLE data</span>
    <span class="c1"># PATH=&#39;models/MLE_TRUE_Regressor_200.0K_training_iter.pt&#39;</span>
    
    <span class="c1">#LOAD TRAINED MODEL</span>
    <span class="n">with_theta_hat</span><span class="o">=</span><span class="kc">False</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_TRUE_Regressor_200.0K_training_iter.pt&#39;</span>
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_True_Regressor_100.0K_training_iter_with_theta_hat.pt&#39;</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_False_Regressor_200.0K_training_iter.pt&#39;</span>
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_False_Regressor_100.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="c1">#EVALUATE AT AT EVAL_DATA</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">eval_bins</span>
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluate-model-at-an-example-set-of-eval-data-points-to-see-the-predicted-p-value-hat-p">
<h1>Evaluate model at an example set of “eval_data” points to see the predicted <span class="math notranslate nohighlight">\(p\)</span>-value (<span class="math notranslate nohighlight">\(\hat{p}\)</span>)<a class="headerlink" href="#evaluate-model-at-an-example-set-of-eval-data-points-to-see-the-predicted-p-value-hat-p" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phat_MLE</span><span class="p">,</span> <span class="n">phatbins_MLE</span> <span class="o">=</span> <span class="n">usemodel</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">train_df</span><span class="o">=</span><span class="n">train_df</span><span class="p">,</span><span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">phat_MLE</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
[[0.26882723]
 [0.29309997]
 [0.32397294]
 [0.34872386]
 [0.37133864]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">phatbins_MLE</span><span class="p">,</span> <span class="n">phat_MLE</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ MLE Example&#39;</span><span class="p">);</span> 
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_88_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_88_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">phat_nonMLE</span><span class="p">,</span> <span class="n">phatbins_nonMLE</span> <span class="o">=</span> <span class="n">usemodel</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span><span class="n">train_df</span><span class="o">=</span><span class="n">train_df</span><span class="p">,</span><span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">200</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">phat_nonMLE</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">phatbins_nonMLE</span><span class="p">,</span> <span class="n">phat_nonMLE</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ non-MLE Example&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
[[0.45620778]
 [0.47124666]
 [0.4863379 ]
 [0.5014541 ]
 [0.5165771 ]]
</pre></div>
</div>
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_89_1.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_89_1.png" />
</div>
</div>
<section id="save-trained-model-if-they-re-good-and-if-you-havent-saved-by-now">
<h2>SAVE TRAINED MODEL (if they’re good, and if you havent saved by now)<a class="headerlink" href="#save-trained-model-if-they-re-good-and-if-you-havent-saved-by-now" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># save_model(MLE=True)</span>
<span class="c1"># save_model(MLE=False)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="this-is-how-you-load-a-trained-model">
<h2>This is how you load a trained model<a class="headerlink" href="#this-is-how-you-load-a-trained-model" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#load</span>
<span class="n">PATH</span><span class="o">=</span><span class="s1">&#39;models/MLE_TRUE_Regressor_20.0K_training_iter.pt&#39;</span>
<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
<span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
<span class="c1">#OR</span>
<span class="c1">#model=torch.load(PATH)#BUT HERE IT WILL BE A DICT (CANT BE EVALUATED RIGHT AWAY) DISCOURAGED!</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=4, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
</section>
<section id="you-could-also-evaluate-the-trained-model-on-the-validation-data">
<h2>You could also evaluate the trained model on the validation data<a class="headerlink" href="#you-could-also-evaluate-the-trained-model-on-the-validation-data" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># nbins=100</span>
<span class="c1"># thetamin=train_df[&#39;theta&#39;].min()</span>
<span class="c1"># thetamax=train_df[&#39;theta&#39;].max()</span>
<span class="c1"># thetastep = (thetamax-thetamin) / nbins</span>
<span class="c1"># bb    = np.arange(thetamin, thetamax+thetastep, thetastep)#this is just making a vector of thetas</span>
<span class="c1"># X     = (bb[1:] + bb[:-1])/2</span>
<span class="n">eval_data</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">valid_x</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">phat</span><span class="o">=</span><span class="n">model</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">phat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.8695913],
       [0.8695913],
       [0.8695913],
       ...,
       [0.8695913],
       [0.8695913],
       [0.8695913]], dtype=float32)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sample_x</span><span class="o">=</span><span class="n">train_df_MLE</span>
<span class="k">def</span> <span class="nf">plot_data_one_nu_with_model</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> 
                     <span class="n">NBINS</span><span class="p">,</span>
              <span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">save_image</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="c1"># make room for 6 sub-plots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                           <span class="n">figsize</span><span class="o">=</span><span class="n">fgsize</span><span class="p">)</span>
    
    <span class="c1"># padding</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.20</span><span class="p">)</span>
    
    <span class="c1"># use flatten() to convert a numpy array of </span>
    <span class="c1"># shape (nrows, ncols) to a 1-d array. </span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">D</span><span class="p">):</span>
        
        <span class="n">y</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">-</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.03</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{\theta}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{E(Z|\theta, \nu)}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
        <span class="c1">#h is histogram approximation</span>

        <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">bb_nonMLE</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="n">x_nonMLE</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nonMLE</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nonMLE</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_nonMLE</span><span class="p">,</span> <span class="n">y_nonMLE</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
        
        
        <span class="k">if</span> <span class="n">func</span><span class="p">:</span>
            <span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            
            <span class="n">f_MLE</span><span class="p">,</span> <span class="n">f_bins_MLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_MLE</span><span class="p">,</span> <span class="n">f_MLE</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
            <span class="c1">#f is model approximation</span>
            
            <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">f_bins_nonMLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_nonMLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_nonMLE</span><span class="p">,</span> <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
            
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">3.1</span><span class="p">,</span> <span class="mf">0.42</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$N, M = </span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                   <span class="c1"># fontsize=FONTSIZE</span>
                  <span class="p">)</span> 

        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mf">3.1</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\nu = </span><span class="si">%5.1f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">nu</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                   <span class="c1"># fontsize=FONTSIZE</span>
                  <span class="p">)</span> 

        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
        
    <span class="c1"># hide unused sub-plots</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">ax</span><span class="p">)):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">set_visible</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">save_image</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/h_MLE_nonMLE_f_MLE_f_nonMLE_one_nu</span><span class="si">%s</span><span class="s1">.png&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Compare the histogrammed function <span class="math notranslate nohighlight">\(h(\theta, \nu, N, M)\)</span> to the ML prediction functino <span class="math notranslate nohighlight">\(f(\theta, \nu, N, M)\)</span> (which is trained to regress <span class="math notranslate nohighlight">\(Z\)</span>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_D</span><span class="p">(</span><span class="n">train_df</span><span class="p">):</span>
    <span class="n">Nmin</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;N&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">Nmax</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;N&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">Mmin</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">Mmax</span> <span class="o">=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">D</span> <span class="o">=</span> <span class="p">[</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span> <span class="k">for</span> <span class="n">N</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Nmin</span><span class="p">,</span> <span class="n">Nmax</span><span class="p">)</span> <span class="k">for</span> <span class="n">M</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">Mmin</span><span class="p">,</span> <span class="n">Mmax</span><span class="p">)]</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">D</span><span class="p">)[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="n">make_D</span><span class="p">(</span><span class="n">train_df</span><span class="p">);</span> <span class="n">D</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1, 1],
       [2, 3],
       [2, 8],
       [3, 5],
       [6, 1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_data_one_nu_with_model</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">thetamin</span><span class="o">=</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="n">thetamax</span><span class="p">,</span> 
                 <span class="n">nu</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">NBINS</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">func</span><span class="o">=</span><span class="n">usemodel</span><span class="p">,</span> <span class="n">save_image</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_100_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_100_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data_many_nus_with_model</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span>
                     <span class="n">NBINS</span><span class="p">,</span>
              <span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">save_image</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="c1"># make room for 6 sub-plots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">figsize</span><span class="o">=</span><span class="n">fgsize</span><span class="p">)</span>
    
    <span class="n">outside</span><span class="o">=</span><span class="s1">&#39;&#39;</span>
    <span class="n">ALPHA</span><span class="o">=</span><span class="mf">0.8</span>
    <span class="n">TITLE_SIZE</span><span class="o">=</span><span class="n">font_legend</span><span class="o">+</span><span class="mi">1</span>
    
    <span class="c1"># padding</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="c1">#horizontal distance</span>
    
    <span class="c1"># use flatten() to convert a numpy array of </span>
    <span class="c1"># shape (nrows, ncols) to a 1-d array. </span>
    
    <span class="k">for</span> <span class="n">nu</span> <span class="ow">in</span> <span class="n">nu_list</span><span class="p">:</span>
        
        <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">D</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    

        <span class="k">if</span> <span class="n">nu</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
            <span class="n">outside</span> <span class="o">=</span> <span class="n">outside</span> <span class="o">+</span> <span class="sa">r</span><span class="s1">&#39; ($&gt;$ train data)&#39;</span>
        
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        <span class="c1">#h is histogram approximation</span>

        <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">bb_nonMLE</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="n">x_nonMLE</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nonMLE</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nonMLE</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_nonMLE</span><span class="p">,</span> <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">)</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">func</span><span class="p">:</span>
            <span class="c1">#load the correct dataframe</span>
            <span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            
            <span class="n">f_MLE</span><span class="p">,</span> <span class="n">f_bins_MLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f_MLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
            <span class="c1">#f is model approximation</span>
            
            <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">f_bins_nonMLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_nonMLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_nonMLE</span><span class="p">,</span> <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">-</span><span class="mi">7</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.03</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{\theta}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{E(Z|\theta, \nu)}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$N, M = </span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                           <span class="c1"># fontsize=FONTSIZE</span>
                          <span class="p">)</span> 
                
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>

                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>  

                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_linewidth</span><span class="p">(</span><span class="s1">&#39;1&#39;</span><span class="p">)</span>  
        <span class="c1"># ax[j].text(3.1, 0.30, r&#39;$\nu = %5.1f$&#39; % nu, fontsize=font_legend-3</span>
        <span class="c1">#            # fontsize=FONTSIZE</span>
        <span class="c1">#           ) </span>

        
        
    <span class="c1"># hide unused sub-plots</span>
<span class="c1">#     for k in range(j+1, len(ax)):</span>
<span class="c1">#         ax[k].set_visible(False)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">save_image</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/h_MLE_nonMLE_f_MLE_f_nonMLE_many_nus.png&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">D</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span>
<span class="n">nu_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="n">plot_data_many_nus_with_model</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">100000</span><span class="p">,</span> <span class="n">thetamin</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">nu_list</span><span class="o">=</span><span class="n">nu_list</span><span class="p">,</span> <span class="n">D</span><span class="o">=</span><span class="n">D</span><span class="p">,</span>
                     <span class="n">NBINS</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
              <span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">func</span><span class="o">=</span><span class="n">usemodel</span><span class="p">,</span>
              <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span> <span class="n">save_image</span><span class="o">=</span><span class="kc">False</span>
                             <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_102_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_102_0.png" />
</div>
</div>
<hr class="docutils" />
<hr class="docutils" />
<p>What we observe here is that when <span class="math notranslate nohighlight">\(\hat{\theta}=\hat{\theta}_{\text{MLE}}\)</span>,our model simply reproduces the analytical result (<span class="math notranslate nohighlight">\(\mathbf{h}\)</span>), and when <span class="math notranslate nohighlight">\(\hat{\theta}=\hat{\theta}_{\text{non-MLE}}\)</span> our model arrives at a <span class="math notranslate nohighlight">\(\lambda\)</span> that has minimal sensitivity to <span class="math notranslate nohighlight">\(\nu\)</span>.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="learning-to-pivot">
<h1>Learning to Pivot<a class="headerlink" href="#learning-to-pivot" title="Permalink to this headline">#</a></h1>
<p>We use the phrase “learning to pivot” because it is a perfect phrase for what we want to do, inspired by <a class="reference external" href="https://arxiv.org/pdf/1611.01046.pdf">Cranmer et. al’s paper</a>, although we do it completely differently. We observe in the plots above that in the case of MLE, <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> has very little sensitivity to <span class="math notranslate nohighlight">\(\nu\)</span>, as expected, whereas in the non-MLE case, <span class="math notranslate nohighlight">\(\mathbf{h}\)</span> has a strong dependence on <span class="math notranslate nohighlight">\(\nu\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(\nu\)</span> is not known precisely from first principles, it is good that we see that our models <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> have given predictions that agree with the histogrammed predictions even in regions outside the region of values of the nuissance parameters used in the training. This is because systematic uncertainties are usually present when the training data is not representative of the real data. Therefore, statisticians have always been interested in forming robust inference techniques that are independent based on <em>pivots</em> - quantities whose distributions are independent of nuissance parameters.</p>
<p>The desired outcome is that we want to enforce <span class="math notranslate nohighlight">\(\mathbf{f}(\theta)\)</span> to be pivotal - i.e. for its distribution to be independent of <span class="math notranslate nohighlight">\(\nu\)</span>. In other words we would like a function <span class="math notranslate nohighlight">\(\lambda(\theta,\nu, N,M)\)</span> such that the expectation <span class="math notranslate nohighlight">\(E \big[ y=Z|x=\{\theta, \nu, N, M\} \big]\)</span> is independent of nuissance parameter <span class="math notranslate nohighlight">\(\nu\)</span>. One example is that we can impose this condition by</p>
<div class="math notranslate nohighlight">
\[\frac{\partial E \left[ Z \mid \theta,\nu,N,M \right] }{\partial \nu} =0\]</div>
<p>in our loss function for all <span class="math notranslate nohighlight">\(\theta, N,M\)</span>. This means our loss function will become</p>
<div class="math notranslate nohighlight">
\[L(z, \mathbf{f}) =  \big( z - \mathbf{f}(\theta, \nu, N, M) \big) ^2 - \frac{\kappa}{2} \ \left\| \frac{\partial \ \mathbf{f}(\theta,\nu,N,M)}{\partial \ \nu} \right\|^2\]</div>
<p>Where <span class="math notranslate nohighlight">\(\kappa\)</span> will be a constant and tunable hyperparameter. The operation to square the derivaive is because the derivative will be a vector (an array), so squaring it (or taking the dot product) will reduce it to a single scalar value.</p>
<p>Note that technically this will be the gradient not the derivative, since <span class="math notranslate nohighlight">\(\vec{\nu}\)</span> will be a vector and so we have to take the gradient of a vector with respect to the scalar <span class="math notranslate nohighlight">\(\vec{\mathbf{f}}\)</span></p>
<div class="math notranslate nohighlight">
\[L(\vec{z}, \vec{\mathbf{f}} ) =  \big( \vec{z} - \vec{\mathbf{f}}(\vec{\theta}, \vec{\nu}, \vec{N}, \vec{M}) \big) ^2 - \frac{\kappa}{2} \ \left\| \vec{\nabla}_{\vec{\nu}} \ \mathbf{f}(\vec{\theta},\vec{\nu},\vec{N},\vec{M}) \ \right\|^2\]</div>
<p>In our case <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(\nu\)</span> are leaf nodes and so their gradients will not be accumulated, and <span class="math notranslate nohighlight">\(f\)</span> is not a leaf node. We have to <code class="docutils literal notranslate"><span class="pre">retain_grad()</span></code> for non-leaf nodes, and <code class="docutils literal notranslate"><span class="pre">retain_graph()</span></code> for the model during the backward propagation, and then zero out the gradients that got accumulated</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Unnamed: 0</th>
      <th>Z</th>
      <th>theta</th>
      <th>nu</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>1</td>
      <td>3.805055</td>
      <td>9.797354</td>
      <td>5</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>15.074683</td>
      <td>0.951402</td>
      <td>8</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>1</td>
      <td>10.848134</td>
      <td>19.538657</td>
      <td>7</td>
      <td>7</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>1</td>
      <td>4.156004</td>
      <td>14.831727</td>
      <td>2</td>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>1</td>
      <td>8.898916</td>
      <td>12.550971</td>
      <td>6</td>
      <td>9</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_t</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_t</span><span class="p">,</span>  <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train_t shape =  (800000,) 

train_x shape =  (800000, 5) 

[[ 0.38995527 12.99773017  0.          3.          7.        ]
 [10.59882699  7.89974857  0.          3.          9.        ]
 [ 0.82995922  9.60260357  0.          5.          7.        ]
 ...
 [13.71780439  7.49373071  2.          4.          2.        ]
 [ 2.61903574  5.13160989  2.          6.          4.        ]
 [10.15214404 12.72985859  0.          3.          9.        ]]
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\nu\)</span> is the second column in the features data</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_layers_pivot</span><span class="p">,</span> <span class="n">hidden_size_pivot</span><span class="p">,</span> <span class="n">dropout_pivot</span><span class="p">,</span> <span class="n">optimizer_name_pivot</span><span class="p">,</span> <span class="n">learning_rate_pivot</span><span class="p">,</span> <span class="n">batch_size_pivot</span><span class="p">,</span> <span class="n">model_nonMLE_pivot</span><span class="p">,</span> <span class="n">optimizer_nonMLE_pivot</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_nonMLE_pivot</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RegularizedRegressionModel(
  (model): Sequential(
    (0): Linear(in_features=5, out_features=11, bias=True)
    (1): Dropout(p=0.1320798105984151, inplace=False)
    (2): ReLU()
    (3): Linear(in_features=11, out_features=11, bias=True)
    (4): Dropout(p=0.1320798105984151, inplace=False)
    (5): ReLU()
    (6): Linear(in_features=11, out_features=11, bias=True)
    (7): Dropout(p=0.1320798105984151, inplace=False)
    (8): ReLU()
    (9): Linear(in_features=11, out_features=11, bias=True)
    (10): Dropout(p=0.1320798105984151, inplace=False)
    (11): ReLU()
    (12): Linear(in_features=11, out_features=1, bias=True)
    (13): Sigmoid()
  )
)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">RMS</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>
    
<span class="k">def</span> <span class="nf">average_quadratic_loss_pivot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">):</span>
    <span class="n">kappa</span><span class="o">=</span><span class="mf">1.5</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">kappa</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">RMS</span><span class="p">(</span><span class="n">df_dnu</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_layers_pivot</span><span class="p">,</span> <span class="n">hidden_size_pivot</span><span class="p">,</span> <span class="n">dropout_pivot</span><span class="p">,</span> <span class="n">optimizer_name_pivot</span><span class="p">,</span> <span class="n">learning_rate_pivot</span><span class="p">,</span> <span class="n">batch_size_pivot</span><span class="p">,</span> <span class="n">model_nonMLE_pivot</span><span class="p">,</span> <span class="n">optimizer_nonMLE_pivot</span> <span class="o">=</span> <span class="n">initiate_whose_model</span><span class="p">(</span><span class="s1">&#39;Ali&#39;</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="c1"># print(model_nonMLE_pivot)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">feature_cols</span><span class="p">)</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_one_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>

    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="n">batch_x</span>

<span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span>
<span class="n">sample_x</span> <span class="o">=</span> <span class="n">get_one_batch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[ 9.66235418  2.51304019 -5.          2.          7.        ] (100, 5)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#scratch</span>
<span class="n">x</span><span class="o">=</span><span class="n">sample_x</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">nu</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>

<span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>

<span class="n">lambda_gen</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="math notranslate nohighlight">
\[
\lambda_{NP} \equiv -2 \log \frac{L_{prof}(\theta)}{L_{prof}(\hat{\theta})}
\]</div>
<p>NP for “Neyman-Pearson”, or “New Physics”, or “Not Pivotal”</p>
<div class="amsmath math notranslate nohighlight" id="equation-ca1ef52a-ced0-4e7d-af8f-04f39a0ee21f">
<span class="eqno">(11)<a class="headerlink" href="#equation-ca1ef52a-ced0-4e7d-af8f-04f39a0ee21f" title="Permalink to this equation">#</a></span>\[\begin{equation}
    L_{\tilde{\lambda}_{pivot}} = (\lambda_D - \tilde{\lambda}_{pivot})^2 - \frac{\psi}{2} \left\| \frac{\partial \tilde{\lambda}_{pivot} }{\partial \nu} \right\|^2
\end{equation}\]</div>
<div class="amsmath math notranslate nohighlight" id="equation-8f42e479-9ba0-47ef-9c95-c94fedb379ae">
<span class="eqno">(12)<a class="headerlink" href="#equation-8f42e479-9ba0-47ef-9c95-c94fedb379ae" title="Permalink to this equation">#</a></span>\[\begin{equation}
    L_{f_{pivot}} = (\tilde{Z} - f_{pivot})^2 - \frac{\kappa}{2} \left\| \frac{\partial f_{pivot} }{\partial \nu} \right\|^2
\end{equation}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">f_pivot_and_lambda_pivot_alg</span> <span class="o">=</span> <span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/f_pivot_and_lambda_pivot_algorithm.png&#39;</span><span class="p">);</span> <span class="n">display</span><span class="p">(</span><span class="n">f_pivot_and_lambda_pivot_alg</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_115_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_115_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
<span class="n">train_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> <span class="n">usecols</span><span class="o">=</span><span class="n">feature_cols</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">train_df</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">train_df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>theta</th>
      <th>nu</th>
      <th>theta_hat</th>
      <th>N</th>
      <th>M</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
      <td>1000000.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>10.000631</td>
      <td>9.998143</td>
      <td>0.001890</td>
      <td>4.999536</td>
      <td>4.997646</td>
    </tr>
    <tr>
      <th>std</th>
      <td>5.770812</td>
      <td>5.775031</td>
      <td>3.654818</td>
      <td>2.582486</td>
      <td>2.582186</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000003</td>
      <td>0.000029</td>
      <td>-8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.003307</td>
      <td>4.993816</td>
      <td>-3.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>10.001563</td>
      <td>9.995425</td>
      <td>0.000000</td>
      <td>5.000000</td>
      <td>5.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>15.001295</td>
      <td>15.001992</td>
      <td>3.000000</td>
      <td>7.000000</td>
      <td>7.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>19.999993</td>
      <td>19.999995</td>
      <td>8.000000</td>
      <td>9.000000</td>
      <td>9.000000</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BEST_PARAMS</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;best_params/best_params_Test_Trials.csv&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>   Unnamed: 0  n_layers  hidden_size  dropout optimizer_name  learning_rate  \
0           0         4           11  0.13208        RMSprop       0.006398   

   batch_size  
0        1000  
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#it is not recommended to import everything from a module</span>
<span class="c1"># but we do it here since we know exactly whats in it and what&#39;s here</span>
<span class="kn">from</span> <span class="nn">utils.utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">utils.utils</span> <span class="k">as</span> <span class="nn">utils</span>

<span class="k">def</span> <span class="nf">getwholedata_f_and_lambda</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="n">feature_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span> <span class="s1">&#39;nu&#39;</span><span class="p">,</span> <span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span> <span class="s1">&#39;N&#39;</span><span class="p">,</span> <span class="s1">&#39;M&#39;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_True.csv&#39;</span><span class="p">,</span> 
                     <span class="c1"># nrows=SUBSAMPLE,</span>
                     <span class="n">usecols</span><span class="o">=</span><span class="n">feature_cols</span>
                    <span class="p">)</span>
        
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/two_parameters_theta_0_20_1000k_Examples_MLE_False.csv&#39;</span><span class="p">,</span> 
             <span class="c1"># nrows=SUBSAMPLE,</span>
             <span class="n">usecols</span><span class="o">=</span><span class="n">feature_cols</span>
            <span class="p">)</span>
        
    <span class="n">train_data</span><span class="p">,</span> <span class="n">test_data</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="c1">#split the train data (0.8 of whole set) again into 0.8*0.8=0.64 of whole set</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">test_data</span>  <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">target</span><span class="o">=</span><span class="s1">&#39;Z&#39;</span><span class="p">;</span> <span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">,</span><span class="s1">&#39;nu&#39;</span><span class="p">,</span><span class="s1">&#39;theta_hat&#39;</span><span class="p">,</span><span class="s1">&#39;N&#39;</span><span class="p">,</span><span class="s1">&#39;M&#39;</span><span class="p">]</span><span class="c1"># these are not needed here</span>
    <span class="n">train_x</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="n">test_x</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="c1">#dont return the torch tensors! we want to do operations on them while training</span>
        
    <span class="k">return</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span>

<span class="k">def</span> <span class="nf">get_one_batch</span><span class="p">(</span><span class="n">x</span><span class="p">,</span>  <span class="n">batch_size</span><span class="p">):</span>
    <span class="n">rows</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">batch_size</span><span class="p">)</span>
    <span class="n">batch_x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="n">rows</span><span class="p">]</span>
    <span class="c1"># batch_x.T[-1] = np.random.uniform(0, 1, batch_size)</span>
    <span class="k">return</span> <span class="n">batch_x</span>

<span class="k">def</span> <span class="nf">RMS</span><span class="p">(</span><span class="n">v</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">v</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span><span class="o">**</span><span class="mf">0.5</span>
    
<span class="k">def</span> <span class="nf">average_quadratic_loss_f_pivot</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">):</span>
    <span class="n">kappa</span><span class="o">=</span><span class="mf">1.5</span>
    <span class="c1">#here t will be Z_tilde, f is model_f(x)</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">f</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">kappa</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">RMS</span><span class="p">(</span><span class="n">df_dnu</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">average_quadratic_loss_tildelambda_pivot</span><span class="p">(</span><span class="n">lambdatilde</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dlmbdatilde_dnu</span><span class="p">):</span>
    <span class="n">psi</span><span class="o">=</span><span class="mi">2</span>
    <span class="c1">#here t will be lambda_D(N,M), lambda_tilde is model_lambda(x)</span>
    <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">lambdatilde</span> <span class="o">-</span> <span class="n">t</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span> <span class="o">-</span> <span class="n">psi</span><span class="o">/</span><span class="mi">2</span> <span class="o">*</span> <span class="n">RMS</span><span class="p">(</span><span class="n">dlambdatilde_dnu</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">validate_f</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1">#avloss has signature average_quadratic_loss_f_pivot(f, t, df_dnu)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">validate_lambda_tilde</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">avloss</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">dlambdatilde_dnu</span><span class="p">):</span>
    <span class="c1"># make sure we set evaluation mode so that any training specific</span>
    <span class="c1"># operations are disabled.</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># evaluation mode</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span> <span class="c1"># no need to compute gradients wrt. x and t</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">targets</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># remember to reshape!</span>
        <span class="n">o</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="c1">#this is lambda tilde</span>
        <span class="c1">#avloss has signaure average_quadratic_loss_tildelambda_pivot(lambdatilde, t, dlmbdatilde_dnu)</span>
    <span class="k">return</span> <span class="n">avloss</span><span class="p">(</span><span class="n">o</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">dlambdatilde_dnu</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">train_pivotal_model_and_lambda</span><span class="p">(</span><span class="n">model_f</span><span class="p">,</span> <span class="n">model_lambda</span><span class="p">,</span> 
                                   <span class="n">optimizer_f</span><span class="p">,</span> <span class="n">optimizer_lambda</span><span class="p">,</span> 
                                   <span class="n">avloss_f</span><span class="p">,</span> <span class="n">avloss_lambda</span><span class="p">,</span>
                                    <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_iterations</span><span class="p">,</span> 
                                   <span class="n">traces_f</span><span class="p">,</span> <span class="n">traces_lambda</span><span class="p">,</span> 
                                      <span class="n">step</span><span class="p">,</span> <span class="n">window</span><span class="p">,</span> <span class="n">MLE</span><span class="p">):</span>
    
    <span class="c1"># to keep track of average losses</span>
    <span class="n">xx_F</span><span class="p">,</span> <span class="n">yy_t_F</span><span class="p">,</span> <span class="n">yy_v_F</span><span class="p">,</span> <span class="n">yy_v_avg_F</span> <span class="o">=</span> <span class="n">traces_f</span>
    <span class="n">xx_lambda</span><span class="p">,</span> <span class="n">yy_t_lambda</span><span class="p">,</span> <span class="n">yy_v_lambda</span><span class="p">,</span> <span class="n">yy_v_avg_lambda</span> <span class="o">=</span> <span class="n">traces_lambda</span>
    
    
    <span class="k">if</span> <span class="n">MLE</span><span class="p">:</span>
        <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata_f_and_lambda</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">train_x</span><span class="p">,</span> <span class="n">test_x</span> <span class="o">=</span> <span class="n">getwholedata_f_and_lambda</span><span class="p">(</span><span class="n">MLE_or_nonMLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">valid</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    
    <span class="c1">#Remember train_x will have columns [&#39;theta&#39;,&#39;nu&#39;,&#39;theta_hat&#39;,&#39;N&#39;,&#39;M&#39;]</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Iteration vs average loss&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="se">\t</span><span class="si">%10s</span><span class="s2">&quot;</span> <span class="o">%</span> \
          <span class="p">(</span><span class="s1">&#39;iteration&#39;</span><span class="p">,</span> <span class="s1">&#39;train-set&#39;</span><span class="p">,</span> <span class="s1">&#39;valid-set&#39;</span><span class="p">))</span>    
    <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
        <span class="c1"># model.eval()</span>
        <span class="c1">#Harrison-like Loader</span>
        <span class="n">batch_x_train</span> <span class="o">=</span> <span class="n">get_one_batch</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span>  <span class="n">batch_size</span><span class="p">)</span>
        
        <span class="c1">#Or Ali&#39;s Loader</span>
        <span class="c1"># batch_x, batch_t = next(training_set_features()), next(training_set_targets())</span>
        <span class="c1"># batch_x_eval, batch_t_eval = next(evaluation_set_features()), next(evaluation_set_targets())</span>
        <span class="c1"># x = torch.from_numpy(batch_x).float()</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">batch_x_train</span>
        <span class="c1"># print(&#39;x is leaf: &#39;, x.is_leaf)</span>
        <span class="c1"># x.retain_grad()</span>
        <span class="c1"># print(&#39;x is leaf after retain: &#39;, x.is_leaf)</span>
        <span class="c1"># x.requires_grad_(True)</span>
        <span class="c1"># x.retain_grad()</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">nu</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span> <span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
        
        <span class="n">lambda_gen</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
        
        <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span>
        
        <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="p">)</span>
        <span class="n">Z_tilde</span> <span class="o">=</span> <span class="p">(</span><span class="n">lambda_gen</span> <span class="o">&lt;</span> <span class="n">lambda_D</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
        
        
        
        <span class="c1">######## take grade of model_f wrt nu</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">model_f</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">model_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1">#multiply the model by its ransverse, remember we can only take gradients of scalars</span>
        <span class="c1">#and f will be a vector before this</span>
        <span class="n">f</span> <span class="o">=</span> <span class="n">f</span> <span class="o">@</span> <span class="n">f</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="c1"># f = torch.tensor(f, requires_grad=True)</span>
        <span class="c1"># print(&#39;f shape: &#39;, f.shape)</span>
        <span class="c1"># print(&#39;f is leaf: &#39;, f.is_leaf)</span>
        
        <span class="c1">###################### Get lambda tilde</span>
        <span class="n">model_lambda</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
        <span class="n">lambda_tilde</span> <span class="o">=</span> <span class="n">model_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_D</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1"># take amplitude of lambda_tilde</span>
        
        <span class="n">lambda_tilde</span> <span class="o">=</span> <span class="n">lambda_tilde</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">lambda_tilde</span> <span class="o">=</span> <span class="n">lambda_tilde</span> <span class="o">@</span> <span class="n">lambda_tilde</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
        <span class="c1"># f_2 = f**2</span>
        <span class="c1"># print(&#39;f2 shape&#39;, f_2.shape)</span>
        <span class="c1"># nu = torch.autograd.Variable( x[:,1], requires_grad=True)</span>
        
        <span class="c1"># nu=torch.autograd.Variable(x[:,1], requires_grad=True)</span>
        <span class="c1"># nu=torch.tensor(x[:,1], requires_grad=True)</span>
        <span class="c1"># print(type(nu))</span>
        <span class="c1"># nu.retain_grad()</span>
        <span class="c1"># print(&#39;nu shape: &#39;, nu.shape)</span>
        <span class="c1"># print(&#39;nu is leaf: &#39;, nu.is_leaf)</span>
        <span class="c1"># print(&#39;nu type&#39;, type(nu))</span>
        
        
        <span class="c1"># WE NEED TO RETAIN_GRAD ON NON-LEAF NODES </span>
        <span class="n">f</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span>
        <span class="n">f</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">gradient</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">f</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">df_dx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
        <span class="c1"># print(&#39;df_dnu =&#39;, df_dnu)</span>
        <span class="c1"># print(&#39;df_dx =&#39;, df_dx)</span>
        <span class="c1"># print(&#39;df_dx shape :&#39;, df_dx.shape)</span>
        <span class="n">df_dnu</span> <span class="o">=</span> <span class="n">df_dx</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
        <span class="c1"># x.grad.zero_()</span>
        <span class="c1"># print(&#39;df_dnu shape: &#39;, df_dnu.shape)</span>
        <span class="c1">#################### Lambda_tilde gradient ##############################</span>
        <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">lambda_tilde</span><span class="o">.</span><span class="n">retain_grad</span><span class="p">()</span>
        <span class="n">lambda_tilde</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">gradient</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">lambda_tilde</span><span class="p">),</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">dlambda_tilde_dx</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">grad</span>
        <span class="n">dlambda_tilde_dnu</span> <span class="o">=</span> <span class="n">dlambda_tilde_dx</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="c1">#clear the gradient after you take it</span>
        <span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="c1"># break        </span>
        <span class="c1"># with torch.no_grad():</span>
        <span class="c1">#     x = torch.from_numpy(batch_x).float()</span>
        <span class="c1">#     t = torch.from_numpy(batch_t).float()   </span>
        
        <span class="c1">################################################################################</span>
        <span class="n">lambda_D</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">lambda_D</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1">#lambda_D will be the target for model_lambda</span>
        <span class="n">Z_tilde</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Z_tilde</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="c1">#Z_tilde will be the target for model_fget for model_f</span>
        
        <span class="c1">#target for f</span>
        <span class="n">t_f</span> <span class="o">=</span> <span class="n">Z_tilde</span>
        <span class="n">t_lambda_tilde</span> <span class="o">=</span> <span class="n">lambda_D</span>
        
        <span class="n">model_f</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">outputs_f</span> <span class="o">=</span> <span class="n">model_f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t_f</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># compute a noisy approximation to the average loss</span>
        <span class="n">empirical_risk_f</span> <span class="o">=</span> <span class="n">avloss_f</span><span class="p">(</span><span class="n">outputs_f</span><span class="p">,</span> <span class="n">t_f</span><span class="p">,</span> <span class="n">df_dnu</span><span class="p">)</span>
        
        <span class="c1"># use automatic differentiation to compute a </span>
        <span class="c1"># noisy approximation of the local gradient</span>
        <span class="n">optimizer_f</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>       <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk_f</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>   <span class="c1"># compute gradients</span>
        <span class="c1"># finally, advance one step in the direction of steepest </span>
        <span class="c1"># descent, using the noisy local gradient. </span>
        <span class="n">optimizer_f</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># move one step</span>
        
        
        <span class="n">model_lambda</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">outputs_lambda_tilde</span> <span class="o">=</span> <span class="n">model_lambda</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t_lambda_tilde</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="c1"># compute a noisy approximation to the average loss</span>
        <span class="n">empirical_risk_lambda_tilde</span> <span class="o">=</span> <span class="n">avloss_f</span><span class="p">(</span><span class="n">outputs_lambda_tilde</span><span class="p">,</span> <span class="n">t_lambda_tilde</span><span class="p">,</span> <span class="n">dlambda_tilde_dnu</span><span class="p">)</span>
        <span class="c1"># use automatic differentiation to compute a </span>
        <span class="c1"># noisy approximation of the local gradient</span>
        <span class="n">optimizer_lambda</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>       <span class="c1"># clear previous gradients</span>
        <span class="n">empirical_risk_lambda_tilde</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>   <span class="c1"># compute gradients</span>
        <span class="c1"># finally, advance one step in the direction of steepest </span>
        <span class="c1"># descent, using the noisy local gradient. </span>
        <span class="n">optimizer_lambda</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>            <span class="c1"># move one step</span>
        
        
<span class="c1">#         if ii % step == 0:</span>
            
<span class="c1">#             # this is an example of an x tensor</span>
<span class="c1">#             # [17.3352, 10.7722,  6.0000,  8.0000],</span>
<span class="c1">#             #[16.7822, 13.3260,  8.0000,  4.0000],</span>
<span class="c1">#             #using Harrison-like loader</span>
<span class="c1">#             batch_x_test = get_one_batch(test_x,  batch_size)</span>
<span class="c1">#             #validate_f has signature validate_f(model, avloss, inputs, targets, df_dnu)</span>
<span class="c1">#             acc_t_f = validate_f(model_f, avloss_f, train_x[:n], train_t[:n], df_dnu)</span>
<span class="c1">#             acc_v = validate(model, avloss, test_x[:n], test_t[:n], df_dnu)</span>
            <span class="c1">#using Ali&#39;s loader</span>
            <span class="c1"># acc_t = validate(model, avloss, batch_x, batch_t) </span>
            <span class="c1"># acc_v = validate(model, avloss, batch_x_eval, batch_t_eval)</span>
            
<span class="c1">#             yy_t_F.append(acc_t)</span>
<span class="c1">#             yy_v_F.append(acc_v)</span>
            
<span class="c1">#             # compute running average for validation data</span>
<span class="c1">#             len_yy_v_F = len(yy_v_F)</span>
<span class="c1">#             if   len_yy_v_F &lt; window:</span>
<span class="c1">#                 yy_v_avg_F.append( yy_v_F[-1] )</span>
<span class="c1">#             elif len_yy_v_F == window:</span>
<span class="c1">#                 yy_v_avg_F.append( sum(yy_v_F) / window )</span>
<span class="c1">#             else:</span>
<span class="c1">#                 acc_v_avg  = yy_v_avg_F[-1] * window</span>
<span class="c1">#                 acc_v_avg += yy_v_F[-1] - yy_v_F[-window-1]</span>
<span class="c1">#                 yy_v_avg_F.append(acc_v_avg / window)</span>
                        
<span class="c1">#             if len(xx_F) &lt; 1:</span>
<span class="c1">#                 xx_F.append(0)</span>
<span class="c1">#                 print(&quot;%10d\t%10.6f\t%10.6f&quot; % \</span>
<span class="c1">#                       (xx_F[-1], yy_t_F[-1], yy_v_F[-1]))</span>
<span class="c1">#             else:</span>
<span class="c1">#                 xx_F.append(xx_F[-1] + step)</span>
                    
<span class="c1">#                 print(&quot;\r%10d\t%10.6f\t%10.6f\t%10.6f&quot; % \</span>
<span class="c1">#                           (xx_F[-1], yy_t_F[-1], yy_v_F[-1], yy_v_avg_F[-1]), </span>
<span class="c1">#                       end=&#39;&#39;)</span>
            
    <span class="nb">print</span><span class="p">()</span>      
    <span class="k">return</span> <span class="p">(</span><span class="n">xx_F</span><span class="p">,</span> <span class="n">yy_t_F</span><span class="p">,</span> <span class="n">yy_v_F</span><span class="p">,</span> <span class="n">yy_v_avg_F</span><span class="p">),</span> <span class="p">(</span><span class="n">xx_lambda</span><span class="p">,</span> <span class="n">yy_t_lambda</span><span class="p">,</span> <span class="n">yy_v_lambda</span><span class="p">,</span> <span class="n">yy_v_avg_lambda</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span>

<span class="n">sample_x</span> <span class="o">=</span> <span class="n">get_one_batch</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
<span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
<span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
<span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>


<span class="n">model_f</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">optimizer_f</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="p">)(</span><span class="n">model_f</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>


<span class="n">model_lambda</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
    <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
    <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
    <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
    <span class="p">)</span>
<span class="n">optimizer_lambda</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">optimizer_name</span><span class="p">)</span> <span class="p">)(</span><span class="n">model_f</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[13.8819839   8.24899307  6.          8.          2.        ] (1000, 5)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">BATCHSIZE</span><span class="o">=</span><span class="n">batch_size</span>
<span class="n">traces_f_pivot_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>
<span class="n">traces_lambda_tilde_pivot_MLE</span> <span class="o">=</span> <span class="p">([],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[])</span>

<span class="n">traces_step</span> <span class="o">=</span> <span class="mi">400</span>

<span class="c1">#This is the signature of </span>
<span class="c1"># train_pivotal_model_and_lambda(model_f, model_lambda, </span>
<span class="c1">#                                    optimizer_f, optimizer_lambda, </span>
<span class="c1">#                                    avloss_f, avloss_lambda,</span>
<span class="c1">#                                     batch_size, n_iterations, </span>
<span class="c1">#                                    traces_f, traces_lambda, </span>
<span class="c1">#                                       step, window, MLE)</span>

<span class="n">n_iterations</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">2e4</span><span class="p">)</span>
<span class="n">MLE</span><span class="o">=</span><span class="kc">True</span>

<span class="n">traces_f_pivot_MLE</span><span class="p">,</span> <span class="n">traces_lambda_tilde_pivot_MLE</span><span class="o">=</span> <span class="n">train_pivotal_model_and_lambda</span><span class="p">(</span><span class="n">model_f</span><span class="o">=</span><span class="n">model_f</span><span class="p">,</span> 
                <span class="n">model_lambda</span><span class="o">=</span><span class="n">model_lambda</span><span class="p">,</span> 
               <span class="n">optimizer_f</span><span class="o">=</span><span class="n">optimizer_f</span><span class="p">,</span> 
                <span class="n">optimizer_lambda</span><span class="o">=</span><span class="n">optimizer_lambda</span><span class="p">,</span> 
           <span class="n">avloss_f</span><span class="o">=</span><span class="n">average_quadratic_loss_f_pivot</span><span class="p">,</span> 
            <span class="n">avloss_lambda</span><span class="o">=</span><span class="n">average_quadratic_loss_tildelambda_pivot</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">BATCHSIZE</span><span class="p">,</span> <span class="n">n_iterations</span><span class="o">=</span><span class="n">n_iterations</span><span class="p">,</span> 
           <span class="n">traces_f</span><span class="o">=</span><span class="n">traces_f_pivot_MLE</span><span class="p">,</span> 
            <span class="n">traces_lambda</span><span class="o">=</span><span class="n">traces_lambda_tilde_pivot_MLE</span><span class="p">,</span> 
              <span class="n">step</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration vs average loss
 iteration	 train-set	 valid-set
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>
    <span class="c1">#if MLE true, load the model that was trained on MLE data and vice versa</span>
    <span class="c1"># N, M = D</span>
    <span class="c1"># nbins=NBINS</span>
    <span class="c1"># thetamin,thetamax=0,20</span>
    <span class="n">thetamin</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
    <span class="n">thetamax</span><span class="o">=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">thetastep</span> <span class="o">=</span> <span class="p">(</span><span class="n">thetamax</span><span class="o">-</span><span class="n">thetamin</span><span class="p">)</span> <span class="o">/</span> <span class="n">nbins</span>
    <span class="n">bb</span>    <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">+</span><span class="n">thetastep</span><span class="p">,</span> <span class="n">thetastep</span><span class="p">)</span><span class="c1">#this is just making a vector of thetas</span>
    <span class="n">X</span>     <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
    <span class="n">tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([[</span><span class="n">x</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">tensor</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

<span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                                     <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span>
                                     <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                                     <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">100</span>
                                    <span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eval data&#39;</span><span class="p">,</span> <span class="n">eval_data</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;eval data shape&#39;</span><span class="p">,</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">theta</span><span class="o">=</span><span class="n">eval_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;theta shape&#39;</span><span class="p">,</span> <span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">model_lambda</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">lambda_tilde_pivot</span> <span class="o">=</span> <span class="n">model_lambda</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;lambda_tilde shape&#39;</span><span class="p">,</span> <span class="n">lambda_tilde_pivot</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">lambda_tilde</span><span class="p">,</span> <span class="n">lambda_tilde_bins</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">lambda_tilde_pivot</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">normed</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">d_lambda_tilde</span> <span class="o">=</span> <span class="n">lambda_tilde_bins</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">lambda_tilde_bins</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">lambda_tilde_CDF</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">lambda_tilde</span><span class="p">)</span> <span class="o">*</span> <span class="n">d_lambda_tilde</span>
<span class="c1"># plt.scatter(lambda_tilde, lambda_tilde_CDF)</span>
<span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_tilde</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\tilde{\lambda}$&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;CDF($\tilde{\lambda}$)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>eval data tensor([[ 0.1000,  3.0000, -5.0000,  2.0000,  7.0000],
        [ 0.3000,  3.0000, -5.0000,  2.0000,  7.0000],
        [ 0.5000,  3.0000, -5.0000,  2.0000,  7.0000],
        [ 0.7000,  3.0000, -5.0000,  2.0000,  7.0000],
        [ 0.9000,  3.0000, -5.0000,  2.0000,  7.0000]])
eval data shape torch.Size([100, 5])
theta shape (100,)
lambda_tilde shape (100,)
</pre></div>
</div>
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_122_2.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_122_2.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">points_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">theta</span><span class="p">,</span> <span class="n">nu</span> <span class="o">=</span> <span class="n">points_1</span>
<span class="n">lambda_size</span><span class="o">=</span><span class="mi">1000</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">make_eval_data_at_fixed_theta_nu</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nbins</span><span class="p">):</span>

    <span class="c1">#Make sure that the desired theta is within the training data range</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">theta</span> <span class="o">&gt;=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="ow">and</span> <span class="n">theta</span> <span class="o">&lt;=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;theta&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="c1">#Make sure that the desired nu is within the training data range</span>
    <span class="k">assert</span> <span class="p">(</span><span class="n">nu</span> <span class="o">&gt;=</span> <span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="ow">and</span> <span class="n">nu</span> <span class="o">&lt;=</span><span class="n">train_df</span><span class="p">[</span><span class="s1">&#39;nu&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">())</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">])</span>
<span class="c1">#     thetastep = (thetamax-thetamin) / nbins</span>
<span class="c1">#     bb    = np.arange(thetamin, thetamax+thetastep, thetastep)#this is just making a vector of thetas</span>
<span class="c1">#     X     = (bb[1:] + bb[:-1])/2</span>
<span class="c1">#     tensor = torch.Tensor([[x, nu, theta_hat(N, M, MLE=True), N, M] for x in X])</span>
    <span class="c1">#return tensor, X.ravel()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">make_eval_data_at_fixed_theta_nu</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">TypeError</span><span class="g g-Whitespace">                                 </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_532246</span><span class="o">/</span><span class="mf">642254824.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="ne">----&gt; </span><span class="mi">1</span> <span class="n">make_eval_data_at_fixed_theta_nu</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="nn">/tmp/ipykernel_532246/3016917439.py</span> in <span class="ni">make_eval_data_at_fixed_theta_nu</span><span class="nt">(theta, nu, Bprime, train_df, nbins)</span>
<span class="g g-Whitespace">     </span><span class="mi">13</span>     <span class="n">n</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">theta</span><span class="o">+</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">14</span>     <span class="n">m</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">poisson</span><span class="o">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">lambda_size</span><span class="p">)</span>
<span class="ne">---&gt; </span><span class="mi">15</span>     <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">theta_hat</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">])</span>
<span class="g g-Whitespace">     </span><span class="mi">16</span> <span class="c1">#     thetastep = (thetamax-thetamin) / nbins</span>
<span class="g g-Whitespace">     </span><span class="mi">17</span> <span class="c1">#     bb    = np.arange(thetamin, thetamax+thetastep, thetastep)#this is just making a vector of thetas</span>

<span class="ne">TypeError</span>: only size-1 arrays can be converted to Python scalars
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#points=(theta,nu)</span>
<span class="n">points_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">points_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">points_3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">MLE</span><span class="o">=</span><span class="kc">True</span>
<span class="k">def</span> <span class="nf">run_sim_lambda_tilde</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">MLE</span><span class="p">,</span> <span class="n">lambda_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">       Evaluate lambda_tilde at fixed theta, nu</span>
<span class="sd">       </span>
<span class="sd">    return: (n, m, lambda_), where each are np arrays of length lambda_size</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># n = st.poisson.rvs(theta+nu, size=lambda_size)</span>
    <span class="c1"># m = st.poisson.rvs(nu, size=lambda_size)</span>
    <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">nu</span><span class="p">,</span> <span class="n">Bprime</span><span class="o">=</span><span class="mi">10000</span><span class="p">,</span>
                                     <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span> 
                                     <span class="n">N</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span><span class="n">M</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="mi">100</span>
                                    <span class="p">)</span>
    
    
    <span class="n">lambda_</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="n">MLE</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">lambda_</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_tilde_pivot</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\tilde{\lambda}$ at fixed $\nu, N, M$ &#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_126_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_126_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># eval_data = eval_data.numpy()</span>
<span class="n">theta_</span><span class="o">=</span><span class="n">eval_data</span><span class="p">[:,</span><span class="mi">0</span><span class="p">];</span> 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nu_</span> <span class="o">=</span> <span class="n">eval_data</span><span class="p">[:,</span><span class="mi">1</span><span class="p">];</span> 
<span class="n">theta_hat_</span> <span class="o">=</span> <span class="n">eval_data</span><span class="p">[:,</span><span class="mi">2</span><span class="p">]</span>
<span class="n">N_</span><span class="o">=</span><span class="n">eval_data</span><span class="p">[:,</span><span class="mi">3</span><span class="p">]</span> 
<span class="n">M_</span> <span class="o">=</span> <span class="n">eval_data</span><span class="p">[:,</span><span class="mi">4</span><span class="p">]</span>
<span class="n">act_lambda</span> <span class="o">=</span> <span class="n">lambda_test</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">theta_</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">N_</span><span class="p">,</span> <span class="n">m</span><span class="o">=</span><span class="n">M_</span><span class="p">,</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">act_lambda</span><span class="p">,</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">);</span><span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;actual $\lambda$ at fixed $\nu, N, M$&#39;</span><span class="p">);</span> <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_128_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_128_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">PATH</span><span class="o">=</span><span class="s1">&#39;models/PIVOT_MLE_False_Regressor_</span><span class="si">%s</span><span class="s1">K_training_iter_Kappa_1_5_tuned_with_thetahat.pt&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">n_iterations</span><span class="o">/</span><span class="mi">1000</span><span class="p">))</span>
<span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">model_nonMLE_pivot</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>  <span class="n">PATH</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">usemodel_with_pivot</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="p">,</span> <span class="n">nbins</span><span class="p">,</span> <span class="n">observe_pivot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="c1">#Generate evaluation data at those fixed nu, N, M values</span>
    <span class="n">eval_data</span><span class="p">,</span> <span class="n">eval_bins</span> <span class="o">=</span><span class="n">make_eval_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span><span class="n">train_df</span><span class="p">,</span><span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span><span class="n">M</span><span class="p">,</span> <span class="n">nbins</span><span class="p">)</span><span class="c1">#eval data is indipendent of MLE, since its just constants witha theta variable</span>
    <span class="c1"># if MLE==True:</span>
    <span class="c1">#     model=model</span>
    <span class="c1">#else load the model trained on non-MLE data</span>
    <span class="c1"># PATH=&#39;models/MLE_TRUE_Regressor_200.0K_training_iter.pt&#39;</span>
    
    <span class="c1">#LOAD TRAINED MODEL</span>
    <span class="k">if</span> <span class="n">MLE_or_pivot</span><span class="o">==</span><span class="s1">&#39;MLE&#39;</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_True_Regressor_100.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="k">elif</span> <span class="n">MLE_or_pivot</span><span class="o">==</span><span class="s1">&#39;nonMLE&#39;</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span> <span class="s1">&#39;models/MLE_False_Regressor_100.0K_training_iter_with_theta_hat.pt&#39;</span>
    <span class="c1">#both MLE and nonMLE models trained with theta_hat as an additional feature</span>
    <span class="k">elif</span> <span class="n">MLE_or_pivot</span><span class="o">==</span><span class="s1">&#39;PIVOT&#39;</span><span class="p">:</span>
        <span class="n">PATH</span><span class="o">=</span><span class="s1">&#39;models/PIVOT_MLE_False_Regressor_200.0K_training_iter_Kappa_2_tuned_byhand.pt&#39;</span>
        <span class="c1"># PATH=&#39;models/PIVOT_MLE_False_Regressor_200K_training_iter_Kappa_1_5_tuned_with_thetahat.pt&#39;</span>
    <span class="n">n_layers</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;n_layers&quot;</span><span class="p">])</span> 
    <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;hidden_size&quot;</span><span class="p">])</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;dropout&quot;</span><span class="p">])</span>
    <span class="n">optimizer_name</span> <span class="o">=</span> <span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">()[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">learning_rate</span> <span class="o">=</span>  <span class="nb">float</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">])</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">BEST_PARAMS</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">])</span>
    <span class="n">model</span> <span class="o">=</span>  <span class="n">RegularizedRegressionModel</span><span class="p">(</span>
        <span class="n">nfeatures</span><span class="o">=</span><span class="n">sample_x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
        <span class="n">ntargets</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">nlayers</span><span class="o">=</span><span class="n">n_layers</span><span class="p">,</span> 
        <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> 
        <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span>
        <span class="p">)</span>
    <span class="c1">#EVALUATE AT AT EVAL_DATA</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">PATH</span><span class="p">)</span> <span class="p">)</span>
    <span class="k">if</span> <span class="n">observe_pivot</span><span class="p">:</span>
        <span class="c1">#this boolean is if you just want to observe the current pivotal model which is not saved</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model_nonMLE_pivot</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">eval_data</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">eval_bins</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_average_loss</span><span class="p">(</span><span class="n">traces_nonMLE_pivot</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_data_many_nus_with_model_pivot</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span> <span class="n">nu_list</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span>
                     <span class="n">NBINS</span><span class="p">,</span>
              <span class="n">FONTSIZE</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span>
              <span class="n">func</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">fgsize</span><span class="o">=</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">22</span><span class="p">),</span> <span class="n">save_image</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    
    <span class="c1"># make room for 6 sub-plots</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                           <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
                           <span class="n">figsize</span><span class="o">=</span><span class="n">fgsize</span><span class="p">)</span>
    
    <span class="n">outside</span><span class="o">=</span><span class="s1">&#39;&#39;</span>
    <span class="n">ALPHA</span><span class="o">=</span><span class="mf">0.8</span>
    <span class="n">TITLE_SIZE</span><span class="o">=</span><span class="n">font_legend</span><span class="o">+</span><span class="mi">1</span>
    
    <span class="c1"># padding</span>
    <span class="c1"># plt.subplots_adjust(hspace=3)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="c1">#horizontal distance</span>
    
    <span class="c1"># use flatten() to convert a numpy array of </span>
    <span class="c1"># shape (nrows, ncols) to a 1-d array. </span>
    
    <span class="k">for</span> <span class="n">nu</span> <span class="ow">in</span> <span class="n">nu_list</span><span class="p">:</span>
        
        <span class="n">N</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="n">D</span>
        <span class="n">y</span><span class="p">,</span> <span class="n">bb</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    

        <span class="k">if</span> <span class="n">nu</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">:</span>
            <span class="n">outside</span> <span class="o">=</span>  <span class="sa">r</span><span class="s1">&#39; ($&gt;$ train data)&#39;</span>
            
        
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        <span class="c1">#h is histogram approximation</span>

        <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">bb_nonMLE</span> <span class="o">=</span> <span class="n">make_hist_data</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span>
                              <span class="n">thetamin</span><span class="p">,</span> <span class="n">thetamax</span><span class="p">,</span>
                              <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span>
                              <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span>
                              <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        
        
        <span class="n">x_nonMLE</span> <span class="o">=</span> <span class="p">(</span><span class="n">bb_nonMLE</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">+</span><span class="n">bb_nonMLE</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">/</span><span class="mi">2</span>

        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_nonMLE</span><span class="p">,</span> <span class="n">y_nonMLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">)</span> <span class="p">,</span><span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{h}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">func</span><span class="p">:</span>
            <span class="c1">#load the correct dataframe</span>
            <span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">train_df_nonMLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            
            
            <span class="n">OBSERVE_PIVOT</span><span class="o">=</span><span class="kc">False</span>
            <span class="c1">#plot MLE models</span>
            <span class="n">f_MLE</span><span class="p">,</span> <span class="n">f_bins_MLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="o">=</span><span class="s1">&#39;MLE&#39;</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span><span class="n">observe_pivot</span><span class="o">=</span><span class="n">OBSERVE_PIVOT</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_MLE</span><span class="p">,</span> <span class="n">f_MLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
            <span class="c1">#f is model approximation</span>
            
            <span class="c1">#plot non-MLE models</span>
            <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">f_bins_nonMLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_nonMLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="o">=</span><span class="s1">&#39;nonMLE&#39;</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span> <span class="n">observe_pivot</span><span class="o">=</span><span class="n">OBSERVE_PIVOT</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_nonMLE</span><span class="p">,</span> <span class="n">f_nonMLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf</span><span class="si">{f}</span><span class="s1">$ non-MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
            
            
            <span class="n">OBSERVE_PIVOT</span><span class="o">=</span><span class="kc">False</span>
            <span class="c1">#plot pivotal  MLE models</span>
            <span class="n">f_pivot_MLE</span><span class="p">,</span> <span class="n">f_bins_pivot_MLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_MLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="o">=</span><span class="s1">&#39;PIVOT&#39;</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span> <span class="n">observe_pivot</span><span class="o">=</span><span class="n">OBSERVE_PIVOT</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_pivot_MLE</span><span class="p">,</span> <span class="n">f_pivot_MLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{f-pivot}$ MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
            
            <span class="c1">#plot pivotal non-MLE models</span>
            <span class="n">f_pivot_nonMLE</span><span class="p">,</span> <span class="n">f_bins_pivot_nonMLE</span> <span class="o">=</span> <span class="n">func</span><span class="p">(</span><span class="n">Bprime</span><span class="p">,</span> <span class="n">train_df_nonMLE</span><span class="p">,</span> <span class="n">nu</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="o">=</span><span class="s1">&#39;PIVOT&#39;</span><span class="p">,</span> <span class="n">nbins</span><span class="o">=</span><span class="n">NBINS</span><span class="p">,</span> <span class="n">observe_pivot</span><span class="o">=</span><span class="n">OBSERVE_PIVOT</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">f_bins_pivot_nonMLE</span><span class="p">,</span> <span class="n">f_pivot_nonMLE</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$\nu= </span><span class="si">%s</span><span class="s1">$ </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">nu</span><span class="p">),</span> <span class="n">outside</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">ALPHA</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{f-pivot}$ non-MLE&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">TITLE_SIZE</span><span class="p">)</span>
        
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">thetamin</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">thetamax</span><span class="o">-</span><span class="mi">7</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">1.03</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{\theta}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\mathbf{E(Z|\theta, \nu)}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">FONTSIZE</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.38</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$N, M = </span><span class="si">%d</span><span class="s1">, </span><span class="si">%d</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span>
                           <span class="c1"># fontsize=FONTSIZE</span>
                          <span class="p">)</span> 
                
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">)</span>

                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;center right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">font_legend</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_edgecolor</span><span class="p">(</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>  

                <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="n">patch</span><span class="o">.</span><span class="n">set_linewidth</span><span class="p">(</span><span class="s1">&#39;1&#39;</span><span class="p">)</span>  
        <span class="c1"># ax[j].text(3.1, 0.30, r&#39;$\nu = %5.1f$&#39; % nu, fontsize=font_legend-3</span>
        <span class="c1">#            # fontsize=FONTSIZE</span>
        <span class="c1">#           ) </span>

        
        
    <span class="c1"># hide unused sub-plots</span>
<span class="c1">#     for k in range(j+1, len(ax)):</span>
<span class="c1">#         ax[k].set_visible(False)</span>
    
    <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">save_image</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/h_MLE_nonMLE_f_MLE_f_nonMLE_many_nus_PIVOT_TUNED_byhand_kappa2.png&#39;</span><span class="p">)</span>
           <span class="c1">#kappa=2  and loss = torch.mean((f - t)**2) - kappa/2 * RMS(df_dnu) and MLE=False</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_df_MLE</span> <span class="o">=</span> <span class="n">load_train_df</span><span class="p">(</span><span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">f_MLE</span><span class="p">,</span> <span class="n">f_bins_MLE</span> <span class="o">=</span> <span class="n">usemodel_with_pivot</span><span class="p">(</span><span class="n">Bprime</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">train_df</span><span class="o">=</span><span class="n">train_df_MLE</span><span class="p">,</span> 
                                        <span class="n">nu</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">MLE_or_pivot</span><span class="o">=</span><span class="s1">&#39;MLE&#39;</span><span class="p">,</span> 
                                        <span class="n">nbins</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span><span class="n">observe_pivot</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f_MLE</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f_bins_MLE</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(301,)
(301,)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="load-the-results-image-of-the-pivotal-model-so-far">
<h1>Load the results image of the pivotal model (so far)<a class="headerlink" href="#load-the-results-image-of-the-pivotal-model-so-far" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">Image</span><span class="p">(</span><span class="s1">&#39;images/h_MLE_nonMLE_f_MLE_f_nonMLE_many_nus_PIVOT_TUNED_byhand_kappa2.png&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_136_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_136_0.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="we-want-another-2x2-grid-of-plots-below-this-as-another-figure-with-mathbf-tilde-lambda-vs-lambda-np">
<h1>we want another 2X2 grid of plots below this (as another figure) with <span class="math notranslate nohighlight">\(\mathbf{\tilde{\lambda}}\)</span> vs <span class="math notranslate nohighlight">\(\lambda_{NP}\)</span><a class="headerlink" href="#we-want-another-2x2-grid-of-plots-below-this-as-another-figure-with-mathbf-tilde-lambda-vs-lambda-np" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">observe_test_statistic_pivotality_with_lambda_tilde</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">lambda_size</span><span class="p">,</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Histogram the CDF of  lambda_t = -2log(Lp(theta)/Lp(theta_hat)), </span>
<span class="sd">    for a given (fixed) theta and nu.</span>
<span class="sd">    Also, plot the actual CDF of a chi^2 distribution with 1 free parameter </span>
<span class="sd">    (since only theta is left after we profile nu) &quot;&quot;&quot;</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span> <span class="n">sharey</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
    <span class="n">title_size</span><span class="o">=</span><span class="mi">15</span>
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">lambda_MLE</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>


        <span class="n">ftsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
        <span class="n">ymin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ymax</span><span class="o">=</span> <span class="mi">1</span>
        <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">y_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_MLE</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="o">*</span><span class="n">xmax</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span>
        <span class="c1"># color=(0.8,0.8,0.9),</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$\left(\lambda_</span><span class="si">{NP}</span><span class="s1">(\theta=</span><span class="si">%s</span><span class="s1">,\nu=</span><span class="si">%s</span><span class="s1"> ) \right)$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="p">)</span>
        
        <span class="c1">############################################################</span>
        <span class="c1">########### HISTOGRAM CDF OF THE CHI2 OF OF X WITH 1 DOF</span>
        <span class="c1">#x is not theta, that&#39;s the whole point of Wilks thm, x is an arbitrary RV</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                   <span class="c1"># color=&#39;blue&#39;,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$ \left(\chi^2_1(\theta=</span><span class="si">%s</span><span class="s1">) \right)$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MLE=True&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">title_size</span><span class="p">)</span>
        <span class="c1">#####################Do the same for non-MLE</span>
        
            
    <span class="k">for</span> <span class="n">point</span> <span class="ow">in</span> <span class="n">points</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">lambda_nonMLE</span> <span class="o">=</span> <span class="n">run_sim</span><span class="p">(</span><span class="n">theta</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">nu</span><span class="o">=</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MLE</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">lambda_size</span><span class="o">=</span><span class="n">chi2_exp_size</span><span class="p">)</span>


        <span class="n">ftsize</span> <span class="o">=</span> <span class="mi">16</span><span class="p">;</span> <span class="n">xmin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">xmax</span><span class="o">=</span> <span class="mi">10</span>
        <span class="n">ymin</span><span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">ymax</span><span class="o">=</span> <span class="mi">1</span>
        <span class="n">x_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
        <span class="n">y_range</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymin</span><span class="p">,</span> <span class="n">ymax</span><span class="p">)</span>
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">lambda_nonMLE</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="o">*</span><span class="n">xmax</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="n">x_range</span><span class="p">,</span>
        <span class="c1"># color=(0.8,0.8,0.9),</span>
                   <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">histtype</span><span class="o">=</span><span class="s1">&#39;stepfilled&#39;</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> 
        <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$\left(\lambda_</span><span class="si">{NP}</span><span class="s1">(\theta=</span><span class="si">%s</span><span class="s1">,\nu=</span><span class="si">%s</span><span class="s1"> ) \right)$&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span> <span class="p">)</span>
        
        <span class="c1">############################################################</span>
        <span class="c1">########### HISTOGRAM CDF OF THE CHI2 OF OF X WITH 1 DOF</span>
        <span class="c1">#x is not theta, that&#39;s the whole point of Wilks thm, x is an arbitrary RV</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">chi2</span><span class="o">.</span><span class="n">cdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> 
                   <span class="c1"># color=&#39;blue&#39;,</span>
                    <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> 
                   <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;CDF$ \left(\chi^2_1(\theta=</span><span class="si">%s</span><span class="s1">) \right)$&#39;</span> <span class="o">%</span> <span class="nb">str</span><span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        
        
        <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MLE=False&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">title_size</span><span class="p">)</span>
        
        <span class="c1"># annotate</span>
        <span class="n">xwid</span> <span class="o">=</span> <span class="p">(</span><span class="n">xmax</span><span class="o">-</span><span class="n">xmin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
        <span class="n">ywid</span> <span class="o">=</span> <span class="p">(</span><span class="n">ymax</span><span class="o">-</span><span class="n">ymin</span><span class="p">)</span><span class="o">/</span><span class="mi">12</span>
        <span class="n">xpos</span> <span class="o">=</span> <span class="n">xmin</span> <span class="o">+</span> <span class="n">xwid</span><span class="o">/</span><span class="mi">2</span>
        <span class="n">ypos</span> <span class="o">=</span> <span class="n">ymin</span> <span class="o">+</span> <span class="n">ywid</span><span class="o">*</span><span class="mi">2</span>
        
        
        
        
        
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\lambda_</span><span class="si">{NP}</span><span class="s1"> \left(\theta,\hat{\nu}(\theta) \mid n, m \right)$&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;CDF$(\lambda_</span><span class="si">{NP}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">ftsize</span><span class="o">+</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">9</span><span class="p">)</span>
        
        
    <span class="k">if</span> <span class="n">savefig</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s1">&#39;images/lambda_NP_observe_pivotality.png&#39;</span><span class="p">)</span>
        
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">observe_test_statistic_pivotality</span><span class="p">(</span><span class="n">points</span><span class="o">=</span><span class="p">[(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">10</span><span class="p">),</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span> <span class="p">],</span> <span class="n">lambda_size</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="mf">1e5</span><span class="p">),</span> <span class="n">savefig</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/4_Imposing_Pivotal_Conditions_on_Lambda_139_0.png" src="_images/4_Imposing_Pivotal_Conditions_on_Lambda_139_0.png" />
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="explore-the-new-pivotal-models-and-save-if-good">
<h1>Explore the new pivotal models and save if good<a class="headerlink" href="#explore-the-new-pivotal-models-and-save-if-good" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># D = (2,4)</span>
<span class="c1"># nu_list = [1,10, 20, 30, 300]</span>
<span class="c1"># plot_data_many_nus_with_model_pivot(Bprime=100000, thetamin=0, thetamax=20, nu_list=nu_list, D=D,</span>
<span class="c1">#                      NBINS=300,</span>
<span class="c1">#               FONTSIZE=15,</span>
<span class="c1">#               func=usemodel_with_pivot,</span>
<span class="c1">#               fgsize=(15, 9), save_image=False</span>
<span class="c1">#                              )</span>
</pre></div>
</div>
</div>
</div>
<p><span class="math notranslate nohighlight">\(\mathbf{f}\)</span> MLE and <span class="math notranslate nohighlight">\(\mathbf{f}\)</span> non-MLE show little dependence on whether or not they were trained with <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> as an additional feature.</p>
<p><span class="math notranslate nohighlight">\(\mathbf{f}-\text{pivot}\)</span> MLE and <span class="math notranslate nohighlight">\(\mathbf{f}-\text{pivot}\)</span> non-MLE perform better when they are <em>not</em> trained with  <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> as an additional feature (but still trained with everything else with the correct MLE/nonMLE values)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># PATH=&#39;models/PIVOT_MLE_False_Regressor_%sK_training_iter_Kappa_2_tuned_byhand.pt&#39; % str(n_iterations/1000)</span>
<span class="c1"># torch.save(model_nonMLE_pivot.state_dict(),  PATH)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># phat_PIVOT, phatbins_PIVOT = usemodel_with_pivot(Bprime=1000,train_df=train_df,nu=3, N=2, </span>
<span class="c1">#                                                  M=3, MLE_or_pivot=&#39;PIVOT&#39;, nbins=200, observe_pivot=False)</span>
<span class="c1"># print(phat_PIVOT[:5])</span>
<span class="c1"># plt.plot(phatbins_PIVOT, phat_PIVOT, label=r&#39;$\mathbf{f}$ PIVOT Example&#39;); plt.legend(loc=&#39;center&#39;); plt.show()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># n_layers_pivot, hidden_size_pivot, dropout_pivot, optimizer_name_pivot, learning_rate_pivot, batch_size_pivot, model_nonMLE_pivot, optimizer_nonMLE_pivot = initiate_whose_model(&#39;Ali&#39;, MLE=False)</span>
<span class="c1"># print(model_nonMLE_pivot)</span>
</pre></div>
</div>
</div>
</div>
<hr class="docutils" />
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="more-discussions">
<h1>More Discussions<a class="headerlink" href="#more-discussions" title="Permalink to this headline">#</a></h1>
<p>One simple example which is paradoxical is the following: suppose we have our usual likelihood
$<span class="math notranslate nohighlight">\(L(\theta, \nu)= \frac{e^{-(\theta+\nu)} (\theta+\nu)^N }{N !} \ \frac{e^{-\nu} \nu^M}{M !} \tag{20} \)</span><span class="math notranslate nohighlight">\( and we observe \)</span>N=M=0<span class="math notranslate nohighlight">\( so that the likelihood becomes \)</span> L(\theta, \nu)= e^{-(\theta+\nu)} e^{-\nu} <span class="math notranslate nohighlight">\(. Suppose that now we wish to make an inference on \)</span>\theta<span class="math notranslate nohighlight">\(. It should make sense that if we know for a fact that there is no background events (since \)</span>M=0$), that the likelihood should not depend on the mean background (since there is no backround to begin with). <a class="reference external" href="https://arxiv.org/pdf/physics/9711021v2.pdf">Feldman and Cousins</a> were aware of this issue and assigned the problem to be the incorrect interpretation of the intervals as Bayesian intervals.</p>
<p>A very closely related problem is the existence of a signal and background densities, say both depending on POI <span class="math notranslate nohighlight">\(\theta\)</span>, and the likelihood will be given by</p>
<div class="math notranslate nohighlight">
\[ L(\theta) = \prod_{i=1}^{N_{obs}} \theta S(x_i) + (1-\theta) B(x_i)\]</div>
<p>where the likelihood <span class="math notranslate nohighlight">\(L(\theta)\)</span> is the probability for obtaining the observation <span class="math notranslate nohighlight">\(x\)</span> from either a signal or background distribution, where <span class="math notranslate nohighlight">\(\theta\)</span> is an unknown proportion of signal (since real events come as a mixture of signal and background), and we would like to infer about the value of this parameter of interest. In the presense of nuissance parameter <span class="math notranslate nohighlight">\(\nu\)</span> the likelihood becomes</p>
<div class="math notranslate nohighlight">
\[ L(\theta,\nu) = \prod_{i=1}^{N_{obs}} \theta S(x_i|\nu) + (1-\theta) B(x_i|\nu)\]</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="more-ideas">
<h1>More ideas<a class="headerlink" href="#more-ideas" title="Permalink to this headline">#</a></h1>
<ol class="simple">
<li><p>More real world physics scenrios</p>
<ul class="simple">
<li><p>We can test this technique in a real case physics LFI scenario by generating pythia data on the fly for signal and background with unknown nuissance parameter and making inferences on the POI</p></li>
</ul>
</li>
<li><p>Likelihood regions and confidence intervals from confidence sets of two or more parameters</p></li>
<li><p>Using more test statistics, motivated by <a class="reference external" href="https://arxiv.org/pdf/1007.1727.pdf">Asymptotic formulae for likelihood-based tests of new physics</a></p></li>
</ol>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="3_Replacing_Data_with_Lambda_and_2D_Inference.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">3 - Replacing Observed Data with Test Statistics and, 2-Dimensional Inference in <span class="math notranslate nohighlight">\(\theta - \nu\)</span> Space</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="5_Mapping_Confidence_Sets_to_Confidence_Intervals.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">5 - Mapping Confidence Sets to Confidence Intervals</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Ali Al Kadhim and Harrison Prosper<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>